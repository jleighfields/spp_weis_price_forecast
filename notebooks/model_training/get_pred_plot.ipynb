{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95ef0bdb-45a2-4734-821b-c6dece9ab18c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "pip install darts\n",
    "# pip install \"u8darts[torch]\"\n",
    "# conda install -c conda-forge -c pytorch u8darts-all%pip install \"mlflow-skinny[databricks]>=2.4.1\"\n",
    "# %pip install \"mlflow-skinny[databricks]>=2.4.1\"\n",
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f77e111-48f9-49bf-b340-73f345f8832b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from darts import TimeSeries, concatenate\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.models import TFTModel\n",
    "from darts.metrics import mape, smape, mae, ope, rmse\n",
    "from darts.utils.statistics import check_seasonality, plot_acf\n",
    "from darts.datasets import AirPassengersDataset, IceCreamHeaterDataset\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from darts.utils.likelihood_models import QuantileRegression, GumbelLikelihood, GaussianLikelihood\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.utils.timeseries_generation import (\n",
    "    gaussian_timeseries,\n",
    "    linear_timeseries,\n",
    "    sine_timeseries,\n",
    ")\n",
    "from darts.models import (\n",
    "    TFTModel,\n",
    "    LinearRegressionModel,\n",
    "    LightGBMModel,\n",
    "    RNNModel,\n",
    "    TCNModel,\n",
    "    TransformerModel,\n",
    "    NBEATSModel,\n",
    "    BlockRNNModel,\n",
    "    VARIMA,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "from torchmetrics import MeanAbsolutePercentageError\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "\n",
    "# define log\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3a2c409-0923-4993-8a52-ed885e9b5c37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7193060-bb06-48cf-91ba-6fa2cae7a13d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bb2dbed-1d3e-4e19-87be-8151e566cda9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b260bab5-6e24-4f6c-819b-96867ff90302",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import src.data_engineering.data_engineering as de\n",
    "# import src.feature_engineering.feature_engineering as fe\n",
    "from src.data_engineering import data_engineering as de\n",
    "from src.utils import plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "769fe038-7a50-4b8b-8eb0-372244b48601",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Spark connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85a355de-7660-4bb3-8789-87948800c08c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if 'spark' not in locals():\n",
    "    from databricks.connect import DatabricksSession\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    \n",
    "    spark = DatabricksSession.builder.remote(\n",
    "      host       = f\"https://{os.environ['DATABRICKS_HOST']}\",\n",
    "      token      = os.environ['SPP_WEIS'],\n",
    "      cluster_id = os.environ['CLUSTER_ID']\n",
    "    ).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39b8a7e4-a32c-483e-b417-28bce69c846f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# get data from spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "facd06ea-42fc-4b00-a130-6953134b85ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "refresh_data = 'lmp_df.parquet' not in os.listdir()\n",
    "# refresh_data = True\n",
    "refresh_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8edd14c-9054-443d-af7d-ca757e85e10d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## lmp\n",
    "if refresh_data:\n",
    "    t0 = time.time()\n",
    "    # query = '''\n",
    "    # SELECT \n",
    "    #   GMTIntervalEnd_HE as GMTIntervalEnd,\n",
    "    #   PNODE_Name,\n",
    "    #   avg(LMP) as LMP_HOURLY\n",
    "    # FROM sandbox_data_science.spp_weis.lmp\n",
    "    # GROUP BY GMTIntervalEnd_HE, PNODE_Name\n",
    "    # '''\n",
    "\n",
    "    query = 'SELECT * FROM sandbox_data_science.spp_weis.lmp_hourly'\n",
    "    res = spark.sql(query).collect()\n",
    "    df = spark.createDataFrame(res).toPandas()\n",
    "    df.to_parquet('lmp_df.parquet')\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(f'elapsed time: {timedelta(seconds=t1-t0)}')\n",
    "    display(df.head())\n",
    "\n",
    "# groupby query takes: 0:01:44.339718\n",
    "# query aggregated table takes: 0:01:15.970348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f0e6d66-a7b0-4525-a93c-952cee98ae33",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## mtrf\n",
    "if refresh_data:\n",
    "    t0 = time.time()\n",
    "    \n",
    "    query = 'SELECT * FROM sandbox_data_science.spp_weis.mtrf'\n",
    "    res = spark.sql(query).collect()\n",
    "    df = spark.createDataFrame(res).toPandas()\n",
    "    df.to_parquet('mtrf_df.parquet')\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(f'elapsed time: {timedelta(seconds=t1-t0)}')\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a953c5a1-6b78-499f-aa5e-e0742d4eaa8c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## mtlf\n",
    "if refresh_data:\n",
    "    t0 = time.time()\n",
    "    \n",
    "    query = 'SELECT * FROM sandbox_data_science.spp_weis.mtlf'\n",
    "    res = spark.sql(query).collect()\n",
    "    df = spark.createDataFrame(res).toPandas()\n",
    "    df.to_parquet('mtlf_df.parquet')\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(f'elapsed time: {timedelta(seconds=t1-t0)}')\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efe84437-f726-4282-a522-a8e69d598674",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Load dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80032709-ef03-4d4e-8463-9cf8acd27b77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "price_df = pd.read_parquet('lmp_df.parquet')\n",
    "mtlf_df = pd.read_parquet('mtlf_df.parquet').sort_values('GMTIntervalEnd')\n",
    "mtrf_df = pd.read_parquet('mtrf_df.parquet').sort_values('GMTIntervalEnd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74464c68-0b26-4511-877d-3aa4d50d0f40",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "411e8a60-0b16-47a1-88fd-94f54fece00c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ########################################\n",
    "# # fill missing values\n",
    "# ########################################\n",
    "# def fill_missed_values(df):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     df = df.fillna(method='ffill')\n",
    "#     df = df.fillna(method='bfill')\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # lmp\n",
    "# ########################################\n",
    "# def get_psco_price_df(price_df):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     psco_idx = price_df[\"PNODE_Name\"].str.contains(\"PSCO\", case=False)\n",
    "#     psco_price_df_long = price_df[psco_idx]\n",
    "#     psco_price_df = psco_price_df_long.pivot_table(\n",
    "#                             index='GMTIntervalEnd',\n",
    "#                             columns='PNODE_Name',\n",
    "#                             values='LMP_HOURLY',\n",
    "#                             margins=False,\n",
    "#                         ).reset_index()\n",
    "\n",
    "#     psco_price_df.columns.name=None\n",
    "\n",
    "#     ls_nodes_name = list(psco_price_df.columns[1:])\n",
    "\n",
    "#     # return psco_price_df_long to create an overall scaler for psco lmps\n",
    "#     return fill_missed_values(psco_price_df), ls_nodes_name, psco_price_df_long\n",
    "\n",
    "\n",
    "# def create_psco_price_series(psco_price_df, node_name_ls):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     psco_price_series = TimeSeries.from_dataframe(\n",
    "#             psco_price_df, \n",
    "#             time_col='GMTIntervalEnd', \n",
    "#             value_cols=node_name_ls, \n",
    "#             fill_missing_dates=True, \n",
    "#             freq='H', \n",
    "#             fillna_value=0, \n",
    "#             static_covariates=None, \n",
    "#             hierarchy=None\n",
    "#         ).astype(np.float32)\n",
    "\n",
    "#     return psco_price_series\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # mtlf\n",
    "# ########################################\n",
    "# def create_mtlf_series(mtlf_df):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     mtlf_df = fill_missed_values(mtlf_df)\n",
    "#     mtlf_series = TimeSeries.from_dataframe(mtlf_df, time_col='GMTIntervalEnd', value_cols='MTLF', fill_missing_dates=True, freq='H', fillna_value=0, static_covariates=None, hierarchy=None).astype(np.float32)\n",
    "#     avg_act_series = TimeSeries.from_dataframe(mtlf_df, time_col='GMTIntervalEnd', value_cols='Averaged_Actual', fill_missing_dates=True, freq='H', fillna_value=0, static_covariates=None, hierarchy=None).astype(np.float32)\n",
    "    \n",
    "#     return mtlf_series, avg_act_series\n",
    "          \n",
    "\n",
    "# ########################################\n",
    "# # mtrf\n",
    "# ########################################  \n",
    "# # Add renewable/load ratio feature to mtrf dataframe\n",
    "# def add_enrgy_ratio_to_mtrf(mtlf_df, mtrf_df):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     mtrf_df = mtrf_df[['GMTIntervalEnd', 'Wind_Forecast_MW', 'Solar_Forecast_MW']].set_index('GMTIntervalEnd').asfreq('H').sort_index()\n",
    "#     mtrf_df = mtrf_df.join(mtlf_df[['GMTIntervalEnd','MTLF']].set_index('GMTIntervalEnd').asfreq('H').sort_index(), on='GMTIntervalEnd', how='outer').sort_values('GMTIntervalEnd').reset_index(drop=True)\n",
    "#     mtrf_df['Ratio'] = (mtrf_df['Wind_Forecast_MW'] + mtrf_df['Solar_Forecast_MW']) / mtrf_df['MTLF']\n",
    "#     mtrf_df.drop('MTLF', axis=1, inplace=True) \n",
    "\n",
    "#     return fill_missed_values(mtrf_df)\n",
    "\n",
    "# def create_mtrf_series(mtrf_ratio_df):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     mtrf_series= TimeSeries.from_dataframe(mtrf_ratio_df, time_col='GMTIntervalEnd', value_cols=['Wind_Forecast_MW','Solar_Forecast_MW', 'Ratio'], fill_missing_dates=True, freq='H', fillna_value=0, static_covariates=None, hierarchy=None).astype(np.float32)\n",
    "    \n",
    "#     return mtrf_series     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47977262-0c35-41fd-b9c7-a68a3a30afa2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lmp\n",
    "psco_lmp_df, list_nodes_name, psco_price_df_long = de.get_psco_price_df(price_df)\n",
    "lmp_series = de.create_psco_price_series(psco_lmp_df, list_nodes_name)\n",
    "\n",
    "# mtlf series\n",
    "mtlf_series, avg_act_series = de.create_mtlf_series(mtlf_df)\n",
    "\n",
    "# mtrf series\n",
    "mtrf_ratio_df = de.add_enrgy_ratio_to_mtrf(mtlf_df, mtrf_df)\n",
    "mtrf_series = de.create_mtrf_series(mtrf_ratio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a497045f-cd08-4e79-9d45-dc6d24de358c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9970e50-790b-4966-87ba-81d297bf3125",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Preprocess series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4fd9f4b-f027-44d2-a24b-d45d63a28c84",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def scale_series(series_train, series_val, series_all, global_fit=False):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     # use global fit to do a single scaling\n",
    "#     # this will allow us to do global forecasting\n",
    "#     # for lmps\n",
    "#     if global_fit:\n",
    "#         scaler = series_train.pd_dataframe().abs().max().mean()\n",
    "#     else:\n",
    "#         scaler = series_train.pd_dataframe().abs().max()\n",
    "\n",
    "#     series_train_transformed = TimeSeries.from_dataframe(series_train.pd_dataframe()/scaler)\n",
    "#     series_val_transformed = TimeSeries.from_dataframe(series_val.pd_dataframe()/scaler)\n",
    "#     series_transformed = TimeSeries.from_dataframe(series_all.pd_dataframe()/scaler)\n",
    "\n",
    "#     return [series_train_transformed, series_val_transformed, series_transformed, scaler]\n",
    "\n",
    "# def lmp_series_drop_horizon(lmp_series, start_time, forecast_horizon):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     start_time_lmp = start_time\n",
    "#     end_time_lmp = lmp_series.end_time() - pd.Timedelta(f'{forecast_horizon+1}H')\n",
    "#     lmp_series = lmp_series.drop_before(start_time_lmp)\n",
    "#     lmp_series = lmp_series.drop_after(end_time_lmp)\n",
    "#     return lmp_series\n",
    "\n",
    "# def get_train_cutoff(lmp_series):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     #keep last 30 days (720 data points + horizon(72 hours)) of target series for validation. \n",
    "#     training_cutoff = lmp_series[:-792].end_time()\n",
    "#     return training_cutoff\n",
    "\n",
    "# def get_lmp_train_test_series(lmp_series_drop_horizon, training_cutoff, forecast_horizon, input_chunk_length):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     lmp_series_train = lmp_series_drop_horizon.drop_after(training_cutoff - pd.Timedelta(f'{forecast_horizon+1}H')) # for future covariates\n",
    "#     lmp_series_val = lmp_series_drop_horizon.drop_before(training_cutoff + pd.Timedelta(f'{input_chunk_length+1}H'))\n",
    "#     lmp_series_all = lmp_series_drop_horizon\n",
    "\n",
    "#     return [lmp_series_train, lmp_series_val, lmp_series_all]\n",
    "\n",
    "\n",
    "# ############## mtlf #####################\n",
    "# def get_mtlf_train_test_series(mtlf_series, start_time, training_cutoff):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     # drop times before the starting time\n",
    "#     mtlf_series = mtlf_series.drop_before(start_time)\n",
    "\n",
    "#     # Split\n",
    "#     mtlf_series_train = mtlf_series.drop_after(training_cutoff)\n",
    "#     mtlf_series_val = mtlf_series.drop_before(training_cutoff)\n",
    "\n",
    "#     return [mtlf_series_train, mtlf_series_val, mtlf_series]\n",
    "\n",
    "\n",
    "# # def scale_mtlf_series(mtlf_series_train, mtlf_series_val, mtlf_series):\n",
    "# #     \"\"\"\n",
    "# #     \"\"\"\n",
    "# #     transformer_mtlf = Scaler()\n",
    "# #     mtlf_series_train_transformed = transformer_mtlf.fit_transform(mtlf_series_train)\n",
    "# #     mtlf_series_val_transformed = transformer_mtlf.transform(mtlf_series_val)\n",
    "# #     mtlf_series_transformed = transformer_mtlf.transform(mtlf_series)\n",
    "\n",
    "# #     return [mtlf_series_train_transformed, mtlf_series_val_transformed, mtlf_series_transformed]\n",
    "\n",
    "# ############# avg_actual #################\n",
    "# def get_avg_act_train_test_series(avg_act_series, start_time, training_cutoff):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     avg_act_series = avg_act_series.drop_before(start_time)\n",
    "\n",
    "#     # Split\n",
    "#     avg_act_series_train = avg_act_series.drop_after(training_cutoff)\n",
    "#     avg_act_series_val = avg_act_series.drop_before(training_cutoff)\n",
    "\n",
    "#     return [avg_act_series_train, avg_act_series_val, avg_act_series]\n",
    "\n",
    "\n",
    "# ############## mtrf #####################\n",
    "# def get_mtrf_train_test_series(mtrf_series, start_time, training_cutoff):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     mtrf_series = mtrf_series.drop_before(start_time)\n",
    "\n",
    "#     # Split\n",
    "#     mtrf_series_train = mtrf_series.drop_after(training_cutoff)\n",
    "#     mtrf_series_val = mtrf_series.drop_before(training_cutoff)\n",
    "\n",
    "#     return [mtrf_series_train, mtrf_series_val, mtrf_series]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3671d03a-bb10-4e3e-bdc3-5045182843ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "scalers = {}\n",
    "\n",
    "start_time = pd.Timestamp('2023-04-02 04:00:00')\n",
    "### TIME CHANGE ########################################################\n",
    "input_chunk_length = 24*7\n",
    "forecast_horizon = 24*3\n",
    "training_cutoff = pd.Timestamp(\"2023-06-01 06:00:00\")\n",
    "########################################################################\n",
    "lmp_series = de.lmp_series_drop_horizon(lmp_series, start_time, forecast_horizon)\n",
    "# training_cutoff = get_train_cutoff(lmp_series_drop_horizon)\n",
    "lmp_series_train, lmp_series_val, lmp_series_all = de.get_lmp_train_test_series(lmp_series, training_cutoff, forecast_horizon, input_chunk_length)\n",
    "(lmp_series_train_transformed, \n",
    " lmp_series_val_transformed, \n",
    " lmp_series_transformed,\n",
    " lmp_scaler) = de.scale_series(lmp_series_train, lmp_series_val, lmp_series_all, global_fit=True)\n",
    "scalers['series'] = lmp_scaler\n",
    "\n",
    "print(f'train start: {lmp_series_train.start_time()}')\n",
    "print(f'train end: {lmp_series_train.end_time()}')\n",
    "print(f'val start: {lmp_series_val.start_time()}')\n",
    "print(f'val end: {lmp_series_val.end_time()}')\n",
    "\n",
    "\n",
    "mtlf_series_train, mtlf_series_val, mtlf_series = de.get_mtlf_train_test_series(mtlf_series, start_time, training_cutoff)\n",
    "# (mtlf_series_train_transformed, \n",
    "#  mtlf_series_val_transformed, \n",
    "#  mtlf_series_transformed, \n",
    "#  mtlf_scaler) = scale_series(mtlf_series_train, mtlf_series_val, mtlf_series)\n",
    "# scalers['mtlf'] = mtlf_scaler\n",
    "\n",
    "# print(f'train start: {mtlf_series_train.start_time()}')\n",
    "# print(f'train end: {mtlf_series_train.end_time()}')\n",
    "# print(f'val start: {mtlf_series_val.start_time()}')\n",
    "# print(f'val end: {mtlf_series_val.end_time()}')\n",
    "\n",
    "\n",
    "avg_act_series_train, avg_act_series_val, avg_act_series = de.get_avg_act_train_test_series(avg_act_series, start_time, training_cutoff)\n",
    "(avg_act_series_train_transformed, \n",
    " avg_act_series_val_transformed, \n",
    " avg_act_series_transformed,\n",
    " past_scaler) = de.scale_series(avg_act_series_train, avg_act_series_val, avg_act_series)\n",
    "scalers['pc'] = past_scaler\n",
    "\n",
    "print(f'train start: {avg_act_series_train.start_time()}')\n",
    "print(f'train end: {avg_act_series_train.end_time()}')\n",
    "print(f'val start: {avg_act_series_val.start_time()}')\n",
    "print(f'val end: {avg_act_series_val.end_time()}')\n",
    "\n",
    "\n",
    "mtrf_series_train, mtrf_series_val, mtrf_series = de.get_mtrf_train_test_series(mtrf_series, start_time, training_cutoff)\n",
    "# mtrf_series_train_transformed, mtrf_series_val_transformed, mtrf_series_transformed = scale_mtrf_series(mtrf_series_train, mtrf_series_val, mtrf_series)\n",
    "\n",
    "# print(f'train start: {mtrf_series_train.start_time()}')\n",
    "# print(f'train end: {mtrf_series_train.end_time()}')\n",
    "# print(f'val start: {mtrf_series_val.start_time()}')\n",
    "# print(f'val end: {mtrf_series_val.end_time()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ce7197b-a709-4c71-9576-67445bfce11b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "past_cov_train = avg_act_series_train_transformed\n",
    "past_cov_val = avg_act_series_val_transformed\n",
    "past_cov = avg_act_series_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7068e6c7-8c21-4d41-bbd0-974c15bffa9c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate future training covariates\n",
    "future_covariates_train = concatenate([mtlf_series_train, mtrf_series_train], axis=1)\n",
    "future_covariates_train.values().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6e761aa-008f-4772-b8b5-18093014eec7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate future validation covariates\n",
    "end_time = mtlf_series_val.end_time() + pd.Timedelta('1H')\n",
    "mtrf_series_val_end_droped = mtrf_series_val.drop_after(end_time)\n",
    "\n",
    "future_covariates_val = concatenate([mtlf_series_val, mtrf_series_val_end_droped], axis=1)\n",
    "future_covariates_val.values().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2187efbc-bfaa-4d0e-a9ee-3dcde69e5076",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate the entire covariate series\n",
    "mtrf_series_end_droped = mtrf_series.drop_after(end_time)\n",
    "\n",
    "future_covariates = concatenate([mtlf_series, mtrf_series_end_droped], axis=1)\n",
    "future_covariates.values().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e52eb663-bc36-45d8-97d9-0b3cbb722e2f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(future_covariates_train_transformed, \n",
    " future_covariates_val_transformed, \n",
    " future_covariates_transformed, \n",
    " future_scaler) = de.scale_series(future_covariates_train, future_covariates_val, future_covariates)\n",
    "scalers['fc'] = future_scaler\n",
    "\n",
    "print(f'train start: {future_covariates_train.start_time()}')\n",
    "print(f'train end: {future_covariates_train.end_time()}')\n",
    "print(f'val start: {future_covariates_val.start_time()}')\n",
    "print(f'val end: {future_covariates_val.end_time()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c6e78b9-1b3f-44fd-b773-09854dcf3d3a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lmp_train_all = []\n",
    "for i in range(len(list_nodes_name)):\n",
    "    lmp_train_all.append(lmp_series_train_transformed[list_nodes_name[i]])\n",
    "\n",
    "\n",
    "lmp_val_all = []\n",
    "for i in range(len(list_nodes_name)):\n",
    "    lmp_val_all.append(lmp_series_val_transformed[list_nodes_name[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fa23eb3-e67f-47ef-b6be-cea9e98a019d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "scalers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e76cb082-c447-4c28-956b-30678e1d3b83",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Prediction using API endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c62ef9a-82a0-4d70-9b6a-5439262d8471",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mtlf_df = pd.read_parquet('mtlf_df.parquet').sort_values('GMTIntervalEnd')\n",
    "mtrf_df = pd.read_parquet('mtrf_df.parquet').sort_values('GMTIntervalEnd')\n",
    "\n",
    "common_times = np.intersect1d(mtlf_df.GMTIntervalEnd, mtlf_df.GMTIntervalEnd)\n",
    "mtlf_idx = [t in common_times for t in mtlf_df.GMTIntervalEnd]\n",
    "mtrf_idx = [t in common_times for t in mtrf_df.GMTIntervalEnd]\n",
    "\n",
    "mtrf_df = mtrf_df[mtrf_idx]\n",
    "mtlf_df = mtlf_df[mtlf_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74a5edef-79b6-4bcf-943e-96ac6e2f3ec2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "price_df = pd.read_parquet('lmp_df.parquet')\n",
    "price_df.rename(columns={'GMTIntervalEnd':'time', 'PNODE_Name':'node'}, inplace=True)\n",
    "price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05254cfb-7f16-4c24-bb68-2f9a6ad3bda9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lmp\n",
    "# psco_lmp_df, list_nodes_name, psco_price_df_long = de.get_psco_price_df(price_df)\n",
    "# lmp_series = de.create_psco_price_series(psco_lmp_df, list_nodes_name)\n",
    "\n",
    "# mtlf series\n",
    "mtlf_series, avg_act_series = de.create_mtlf_series(mtlf_df)\n",
    "\n",
    "# mtrf series\n",
    "mtrf_ratio_df = de.add_enrgy_ratio_to_mtrf(mtlf_df, mtrf_df)\n",
    "mtrf_series = de.create_mtrf_series(mtrf_ratio_df)\n",
    "\n",
    "future_covariates = concatenate([mtlf_series, mtrf_series], axis=1)\n",
    "past_covariates = avg_act_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "210e010e-b8bc-4fd5-b289-520bf1da70f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "node_name = list_nodes_name[5]\n",
    "lmp_series_df = price_df[price_df.node == node_name].drop('node', axis=1)\n",
    "lmp_series_df.rename(columns={'LMP_HOURLY':node_name}, inplace=True)\n",
    "lmp_series_df = lmp_series_df.sort_values('time')\n",
    "lmp_series_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c47e29ae-1435-45f8-8632-01235ce961ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "FCAST_TIME = pd.Timestamp('2023-07-28 12:00:00')\n",
    "# FCAST_TIME = pd.Timestamp('2023-06-05 12:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55426587-7c0e-4711-83f3-c522ae545fbe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lmp_series = TimeSeries.from_dataframe(\n",
    "            lmp_series_df, \n",
    "            time_col='time', \n",
    "            value_cols=node_name, \n",
    "            fill_missing_dates=True, \n",
    "            freq='H', \n",
    "            fillna_value=0, \n",
    "            static_covariates=None, \n",
    "            hierarchy=None\n",
    "        ).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "452daa24-ab01-401c-8e7f-204ff0e4ae9d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lmp_series = lmp_series.drop_after(FCAST_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9e841b4-aa93-45d4-bbc1-ef2756dbeb0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# node_series = lmp_series[list_nodes_name[1]]\n",
    "past_cov_series = avg_act_series\n",
    "future_cov_series = future_covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9e841b4-aa93-45d4-bbc1-ef2756dbeb0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'series': [lmp_series.to_json()],\n",
    "    'past_covariates': [past_cov_series.to_json()],\n",
    "    'future_covariates': [future_cov_series.to_json()],\n",
    "    'n': forecast_horizon,\n",
    "    'num_samples': 200\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13b35ed2-227c-4f22-b4c6-116f66d818a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def create_tf_serving_json(data):\n",
    "  return {'inputs': {name: data[name].tolist() for name in data.keys()} if isinstance(data, dict) else data.tolist()}\n",
    "\n",
    "def score_model(dataset):\n",
    "  url = 'https://dbc-beada314-1494.cloud.databricks.com/serving-endpoints/spp_weis/invocations'\n",
    "  api_token = 'dapi0744c2d5e8ed2b39576805ba0ad5f692'\n",
    "  headers = {'Authorization': f'Bearer {api_token}', 'Content-Type': 'application/json'}\n",
    "  ds_dict = {'dataframe_split': dataset.to_dict(orient='split')} if isinstance(dataset, pd.DataFrame) else create_tf_serving_json(dataset)\n",
    "  data_json = json.dumps(ds_dict, allow_nan=True)\n",
    "  response = requests.request(method='POST', headers=headers, url=url, data=data_json)\n",
    "  if response.status_code != 200:\n",
    "    raise Exception(f'Request failed with status {response.status_code}, {response.text}')\n",
    "  return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "592b4145-2290-43c6-be0d-21f10f72e8b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "endpoint_pred = score_model(df)\n",
    "# endpoint_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37f5a6ad-eb16-4bfb-a495-72525185db4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "preds = TimeSeries.from_json(endpoint_pred['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64588d01-a870-4a52-98f5-2787d42ab9e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "preds.mean(axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c55390d5-cd02-4391-9b4f-f1a4d5b5edd8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# preds.pd_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bc14ad4-f4c3-4fcd-b060-a0891a16a7c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def get_quantile_df(preds):\n",
    "\n",
    "#     # get dataframe from preds TimeSeries\n",
    "#     plot_df = (\n",
    "#         preds.pd_dataframe()\n",
    "#         .reset_index()\n",
    "#         .melt(id_vars='time')\n",
    "#         .rename(columns={'component':'node'})\n",
    "#     )\n",
    "\n",
    "#     # remove sample numbers\n",
    "#     plot_df.node = ['_'.join(n.split('_')[:-1]) for n in plot_df.node]\n",
    "\n",
    "#     # get quanitles\n",
    "#     q_df = plot_df.groupby(['time', 'node']).quantile([0.1, 0.5, 0.9])\n",
    "\n",
    "#     # create columns from quantiles\n",
    "#     q_pivot = q_df.reset_index().pivot(columns='level_2', index=['time', 'node'])\n",
    "\n",
    "#     # level from columns after pivot\n",
    "#     q_pivot.columns = q_pivot.columns.droplevel()\n",
    "\n",
    "#     # remove index level name\n",
    "#     q_pivot.columns.name = None\n",
    "    \n",
    "#     return q_pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ae44bfa-7065-491d-8f59-8bd3a5413b4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "q_df = plotting.get_quantile_df(preds)\n",
    "q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72d46028-35b7-4188-b7f8-82c08ab685aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def get_mean_df(preds):\n",
    "#     plot_df = (\n",
    "#         preds.pd_dataframe()\n",
    "#         .reset_index()\n",
    "#         .melt(id_vars='time')\n",
    "#         .rename(columns={'component':'node'})\n",
    "#     )\n",
    "\n",
    "#     # remove sample numbers\n",
    "#     plot_df.node = ['_'.join(n.split('_')[:-1]) for n in plot_df.node]\n",
    "\n",
    "#     # get quanitles\n",
    "#     mean_df = plot_df.groupby(['time', 'node']).mean()\n",
    "#     mean_df.rename(columns={'value':'mean_fcast'}, inplace=True)\n",
    "#     return mean_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec139c59-00ea-4cf7-a98a-780af55e0c08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_cov_df = future_cov_series.pd_dataframe()\n",
    "plot_cov_df = plot_cov_df.reset_index().rename(columns={'GMTIntervalEnd':'time'})\n",
    "plot_cov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "689f26f0-a825-4f5a-9d02-290cc639f064",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def get_plot_df(preds, plot_cov_df, prices_df, node_name):\n",
    "    \n",
    "#     fcast_df = get_mean_df(preds).merge(\n",
    "#         get_quantile_df(preds),\n",
    "#         left_index=True,\n",
    "#         right_index=True,\n",
    "#     )\n",
    "\n",
    "#     fcast_df.reset_index().drop('node', axis=1)\n",
    "\n",
    "#     plot_df = fcast_df.reset_index().drop('node', axis=1).merge(\n",
    "#         plot_cov_df,\n",
    "#         on=['time'],\n",
    "#         how='right',\n",
    "#     ).sort_values('time')\n",
    "\n",
    "#     plot_df = plot_df.merge(\n",
    "#         prices_df[prices_df.node == node_name],\n",
    "#         on=['time'],\n",
    "#         how='left',\n",
    "#     ).sort_values('time')\n",
    "\n",
    "#     return plot_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02850357-7971-41c1-a3b0-3ef054397b2e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_df = plotting.get_plot_df(preds, plot_cov_df, price_df, node_name)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b474cfe-71f6-4815-b909-99be97818444",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_fcast(plot_df, lookback = '7D', node_name=None):\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "    \n",
    "    min_fcast_time = plot_df.time[~plot_df.mean_fcast.isna()].min() - pd.Timedelta(lookback)\n",
    "    max_fcast_time = plot_df.time[~plot_df.mean_fcast.isna()].max()\n",
    "    plot_idx = (plot_df.time >= min_fcast_time) & (plot_df.time <= max_fcast_time)\n",
    "    \n",
    "    plot_data = plot_df[plot_idx]\n",
    "    plot_data[['time', 'mean_fcast', 'LMP_HOURLY']].plot(x='time', ax=ax1);\n",
    "    idx = ~plot_data['mean_fcast'].isna()\n",
    "\n",
    "    acc_data = plot_data[['mean_fcast', 'LMP_HOURLY']].dropna(axis=0)\n",
    "    if acc_data.shape[0] > 0:\n",
    "        err = np.round(mae(acc_data.LMP_HOURLY, acc_data.mean_fcast), 2)\n",
    "    else:\n",
    "        err = '-'\n",
    "    title_text = f'MAE forecast error: ${err}'\n",
    "    if node_name:\n",
    "        title_text = node_name + '\\n' + title_text\n",
    "        \n",
    "    # https://stackoverflow.com/questions/29329725/pandas-and-matplotlib-fill-between-vs-datetime64/29329823#29329823\n",
    "    ax1.fill_between(plot_data.time.values, plot_data[0.1], plot_data[0.9], where=idx, alpha=0.3)\n",
    "    ax1.set_xlabel('')\n",
    "    ax1.set_ylabel('$')\n",
    "    ax1.set_title(title_text)\n",
    "    \n",
    "    plot_df.loc[plot_idx, ['time', 'Ratio']].plot(x='time', ax=ax2);\n",
    "    ax2.set_ylabel('RE gen / load')\n",
    "    \n",
    "    fig.set_size_inches(6, 6)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    return plot_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2e8bf04-a37d-4ed2-ad1c-ace8b4ee418a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_data = plot_fcast(plot_df, lookback = '3D', node_name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f626fc16-92ed-49e8-b0a0-f7f564673e91",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "acc_data = plot_data[['mean_fcast', 'LMP_HOURLY']].dropna(axis=0)\n",
    "acc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "460dd0d0-3a77-4a66-911e-6a9dd7ff5ab0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "np.round(mae(acc_data.LMP_HOURLY, acc_data.mean_fcast), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af706a9b-4964-42d0-b4e4-aee1c37ad830",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29fdc8e4-be1c-4323-8320-e49c3ef139af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9923a783-e93a-4d5c-b912-a34a9c398e14",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4614bfa6-f4c6-4feb-b67b-7c81cf82eb7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1971e17-1e3d-447f-8b4f-8f85346b9877",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d11e627-8cb0-4168-b141-c74ab8287d9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "def plotly_forecast(plot_df, node_name=None, lookback='7D', show_fig=False):\n",
    "\n",
    "    acc_data = plot_data[['mean_fcast', 'LMP_HOURLY']].dropna(axis=0)\n",
    "    if acc_data.shape[0] > 0:\n",
    "        err = np.round(mae(acc_data.LMP_HOURLY, acc_data.mean_fcast), 2)\n",
    "    else:\n",
    "        err = '-'\n",
    "    title_text = f'MAE forecast error: ${err}'\n",
    "    if node_name:\n",
    "        title_text = node_name + '\\n' + title_text\n",
    "    \n",
    "    start_time = plot_df[~plot_df.mean_fcast.isna()].time.min() - pd.Timedelta(lookback)\n",
    "    end_time = plot_df[~plot_df.mean_fcast.isna()].time.max()\n",
    "    plotly_idx = (plot_df.time >= start_time) & (plot_df.time <= end_time)\n",
    "    plotly_data = plot_df[plotly_idx]\n",
    "    \n",
    "    x_actual = plotly_data.time\n",
    "    y_actual = plotly_data.LMP_HOURLY\n",
    "    \n",
    "    x_fcast = plotly_data.time\n",
    "    y_u_int = plotly_data[0.9]\n",
    "    y_l_int = plotly_data[0.1]\n",
    "    \n",
    "    y_fcast = plotly_data.mean_fcast\n",
    "    y_ratio = plotly_data.Ratio\n",
    "\n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
    "\n",
    "    # Actual values (history)\n",
    "    fig.append_trace(\n",
    "        go.Scatter(\n",
    "                x=x_actual,\n",
    "                y=y_actual,\n",
    "                line=dict(color='rgb(10,10,10)'),\n",
    "                mode='lines',\n",
    "                name='Actual'\n",
    "            ), row=1, col=1)\n",
    "\n",
    "    # confidence interval\n",
    "    fig.append_trace(\n",
    "        go.Scatter(\n",
    "                x=(\n",
    "                    x_fcast.tolist() +\n",
    "                    x_fcast[::-1].tolist()\n",
    "                ),\n",
    "                y=(\n",
    "                    y_u_int.tolist() +\n",
    "                    y_l_int[::-1].tolist()\n",
    "                ),\n",
    "                fill='toself',\n",
    "                fillcolor='rgba(200,40,40,0.2)',\n",
    "                line=dict(color='rgba(255,255,255,0)'),\n",
    "                showlegend=False,\n",
    "                name='forecast_ci'\n",
    "                ), row=1, col=1)\n",
    "\n",
    "    # point forecast\n",
    "    fig.append_trace(\n",
    "        go.Scatter(\n",
    "                x=x_fcast,\n",
    "                y=y_fcast,\n",
    "                line=dict(color='rgb(200,40,40)'),\n",
    "                mode='lines',\n",
    "                name='Forecast'\n",
    "            ), row=1, col=1)\n",
    "\n",
    "    # energy ratio\n",
    "    fig.append_trace(\n",
    "        go.Scatter(\n",
    "                x=x_fcast,\n",
    "                y=y_ratio,\n",
    "                line=dict(color='rgb(40,40,200)'),\n",
    "                mode='lines',\n",
    "                name='energy_ratio',\n",
    "            # visible='legendonly',\n",
    "            ), row=2, col=1,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    fig.update_layout(\n",
    "            title=title_text,\n",
    "            height=600,\n",
    "            width=1000,\n",
    "            yaxis_tickformat = ',',\n",
    "            plot_bgcolor=\"rgb(240, 240, 250, 1.0)\",\n",
    "            # Add range slider\n",
    "            xaxis=dict(\n",
    "                # rangeslider=dict(\n",
    "                #     visible=True\n",
    "                # ),\n",
    "                type=\"date\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_yaxes(title_text=\"$\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\" RE / Load\", row=2, col=1)\n",
    "\n",
    "    # range slider for subplots\n",
    "    # https://community.plotly.com/t/subplot-with-shared-x-axis-and-range-slider/3148\n",
    "    fig.update_layout(xaxis2_rangeslider_visible=True, \n",
    "                      xaxis2_rangeslider_thickness=0.1)\n",
    "    \n",
    "    \n",
    "    fig.for_each_trace(lambda t: t.update(\n",
    "        hoveron='points+fills',\n",
    "        # hovertemplate = 'Hours: %{y:,.0f} - %{x}',\n",
    "        hovertemplate = '%{y:,.2f} - %{x}',\n",
    "        ))\n",
    "    \n",
    "    # fig.update_xaxes(matches='x')\n",
    "    # fig.update_xaxes(row=1, col=1, rangeslider_visible=False)\n",
    "    \n",
    "    if show_fig:\n",
    "        fig.show()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a386559-654c-43c7-9aa8-cc0e8cec2ebb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig = plotly_forecast(plot_df, lookback='7D', show_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14729ce3-ed3e-466c-9bd1-1f677ec21183",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_td_fcast(df, k, hours: str, fcast_type: str, show_fig=True):\n",
    "    \n",
    "    # creat groups (keys)\n",
    "    mapping_cols = [\n",
    "        'CMPNY_NAME',\n",
    "        'UTILITY',\n",
    "        'AREA',\n",
    "        'PLANNING_PLANT_GRP'\n",
    "    ]\n",
    "    \n",
    "    df['key'] = df[mapping_cols].apply(' - '.join, axis=1)\n",
    "    \n",
    "    # create new df grouped by keys and yera_mmonth\n",
    "    select_cols = [hours] + ['LWR_0_1'] + ['UPR_0_9'] + ['key'] + ['YR_MTH']  + ['HOURS_TYPE'] \n",
    "    max_year_mon = df[select_cols[4]].max()\n",
    " \n",
    "    summed_df = (\n",
    "        df[select_cols]\n",
    "        .loc[df['YR_MTH'] <= max_year_mon,:]\n",
    "        .groupby(select_cols[3:])\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    # datetime format\n",
    "    summed_df['YR_MTH'] = pd.to_datetime(summed_df['YR_MTH'])\n",
    " \n",
    "    x_actual = summed_df[summed_df.key== k].loc[summed_df.HOURS_TYPE == 'actual', 'YR_MTH']\n",
    "    x_fcast = summed_df[summed_df.key== k].loc[summed_df.HOURS_TYPE == 'forecast', 'YR_MTH']\n",
    "    y_p_actual = summed_df[summed_df.key== k].loc[summed_df.HOURS_TYPE == 'actual', hours]\n",
    "    y_p_fcast = summed_df[summed_df.key== k].loc[summed_df.HOURS_TYPE == 'forecast', hours]\n",
    "    y_l_int = summed_df[summed_df.key== k].loc[summed_df.HOURS_TYPE == 'forecast', 'LWR_0_1']\n",
    "    y_u_int = summed_df[summed_df.key== k].loc[summed_df.HOURS_TYPE == 'forecast', 'UPR_0_9']\n",
    "        \n",
    "    fig = go.Figure([\n",
    "        # Actual values (history)\n",
    "        go.Scatter(\n",
    "            x=x_actual,\n",
    "            y=y_p_actual,\n",
    "            line=dict(color='rgb(10,10,10)'),\n",
    "            mode='lines',\n",
    "            name='Actual'\n",
    "        ),\n",
    "        # confidence interval\n",
    "        go.Scatter(\n",
    "            x=(\n",
    "                x_fcast.tolist() +\n",
    "                x_fcast[::-1].tolist()\n",
    "            ),\n",
    "            y=(\n",
    "                y_u_int.tolist() +\n",
    "                y_l_int[::-1].tolist()\n",
    "            ),\n",
    "            fill='toself',\n",
    "            fillcolor='rgba(200,40,40,0.2)',\n",
    "            line=dict(color='rgba(255,255,255,0)'),\n",
    "            showlegend=False,\n",
    "            name='forecast_ci'\n",
    "            ),\n",
    "\n",
    "        # point forecast\n",
    "        go.Scatter(\n",
    "            x=x_fcast,\n",
    "            y=y_p_fcast,\n",
    "            line=dict(color='rgb(200,40,40)'),\n",
    "            mode='lines',\n",
    "            name='Forecast'\n",
    "        ),\n",
    "\n",
    "    ])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"{fcast_type}: {k}\",\n",
    "        yaxis_tickformat = ',',\n",
    "        plot_bgcolor=\"rgb(240, 240, 250, 1.0)\",\n",
    "        # Add range slider\n",
    "        xaxis=dict(\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=2,\n",
    "                        label=\"2y\",\n",
    "                        step=\"year\",\n",
    "                        stepmode=\"backward\"),\n",
    "                    dict(count=3,\n",
    "                        label=\"3y\",\n",
    "                        step=\"year\",\n",
    "                        stepmode=\"backward\"),\n",
    "                    dict(step=\"all\")\n",
    "                ])\n",
    "            ),\n",
    "            rangeslider=dict(\n",
    "                visible=True\n",
    "            ),\n",
    "            type=\"date\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    fig.for_each_trace(lambda t: t.update(\n",
    "        hoveron='points+fills',\n",
    "        hovertemplate = 'Hours: %{y:,.0f} - %{x}'\n",
    "    ))\n",
    "    \n",
    "    if show_fig:\n",
    "        fig.show()\n",
    "    else:\n",
    "        return fig \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd4bf963-ee83-4703-b9fc-fe0258e24cf3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3955381523102072,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "get_pred_plot",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
