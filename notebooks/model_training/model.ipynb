{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ff4217-0cbe-49ef-b919-46bca277d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69203664-529c-4f3c-9526-4ca37adce1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b770fc59-5d59-4721-ad6a-438785b4a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_TYPE = 'ts_mixer'\n",
    "MODEL_TYPE = 'tide'\n",
    "# MODEL_TYPE = 'tft'\n",
    "\n",
    "RUN_EXP = True\n",
    "NUM_TRIALS = 100\n",
    "\n",
    "# for pyfunc model\n",
    "MODEL_NAME = 'spp_weis'\n",
    "\n",
    "REMOVE_PRIOR_MODELS = True\n",
    "TEST_BUILD_BACKTEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52cf595-9e8a-4d77-8f2a-f83bc5725504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import duckdb\n",
    "from typing import List, Optional\n",
    "\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "import ibis\n",
    "import ibis.selectors as s\n",
    "from ibis import _\n",
    "ibis.options.interactive = True\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import torch\n",
    "\n",
    "from darts import TimeSeries, concatenate\n",
    "from darts.dataprocessing.transformers import (\n",
    "    Scaler,\n",
    "    MissingValuesFiller,\n",
    "    Mapper,\n",
    "    InvertibleMapper,\n",
    ")\n",
    "from darts.dataprocessing import Pipeline\n",
    "from darts.metrics import mape, smape, mae, ope, rmse\n",
    "from darts.utils.statistics import check_seasonality, plot_acf\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from darts.utils.likelihood_models import QuantileRegression\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.utils.timeseries_generation import (\n",
    "    gaussian_timeseries,\n",
    "    linear_timeseries,\n",
    "    sine_timeseries,\n",
    ")\n",
    "from darts.models import (\n",
    "    TFTModel,\n",
    "    TiDEModel,\n",
    "    DLinearModel,\n",
    "    NLinearModel,\n",
    "    TSMixerModel,\n",
    "    NaiveEnsembleModel\n",
    ")\n",
    "\n",
    "\n",
    "from torchmetrics import (\n",
    "    SymmetricMeanAbsolutePercentageError, \n",
    "    MeanAbsoluteError, \n",
    "    MeanSquaredError,\n",
    ")\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "\n",
    "# define log\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9265743c-3605-48d9-83a8-69b56743c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_contour,\n",
    "    plot_param_importances,\n",
    "    plot_pareto_front,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fb2027-6f33-440d-ad6b-b3d3632d8103",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113b2e7-4a1b-4e41-959e-21bc661746fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom modules\n",
    "import src.data_engineering as de\n",
    "from src import parameters\n",
    "from src import plotting\n",
    "from src.modeling import (\n",
    "    get_ci_err, build_fit_tsmixerx, build_fit_tide, build_fit_tft, log_pretty\n",
    ")\n",
    "\n",
    "## will be loaded from root when deployed\n",
    "from src.darts_wrapper import DartsGlobalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211757e7-9d91-4d9b-916b-41501e357379",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(f'FORECAST_HORIZON: {parameters.FORECAST_HORIZON}')\n",
    "log.info(f'INPUT_CHUNK_LENGTH: {parameters.INPUT_CHUNK_LENGTH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c3b07-8384-47e7-bca2-c45644cac3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ac6abd-78e4-4add-b7ad-131851b3bc23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33d952be-198a-4d48-871b-4ccec3960b41",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98641b73-9d7c-4f14-94ab-3d6aacbc201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = de.create_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140bb69b-fc1b-4fcf-9e8e-c583956dea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90415453-776a-471b-8e98-76ff46507ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table('lmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4cec6d-bcc0-4756-9a77-a3b34eeaf83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_lmp(\n",
    "    con: ibis.duckdb.connect,\n",
    "    start_time: Optional[str] = None,\n",
    "    end_time: Optional[str] = None,\n",
    "    loc_filter: str = 'PSCO_',\n",
    "    clip_outliers: bool = False,\n",
    "):\n",
    "    # con = ibis.duckdb.connect(\"data/spp.ddb\", read_only=True)\n",
    "    lmp = con.table('lmp')\n",
    "    lmp = lmp.filter(_.Settlement_Location_Name.contains(loc_filter))\n",
    "    drop_cols = [\n",
    "        'Interval_HE', 'GMTIntervalEnd_HE', 'timestamp_mst_HE',\n",
    "        'Settlement_Location_Name', 'PNODE_Name',\n",
    "        'MLC', 'MCC', 'MEC'\n",
    "    ]\n",
    "\n",
    "    if not start_time:\n",
    "        # get last 1.5 years\n",
    "        start_time = pd.Timestamp.utcnow() - pd.Timedelta(parameters.TRAIN_START)\n",
    "\n",
    "    # TODO: handle checks for start_time < end_time\n",
    "    lmp = lmp.filter(_.timestamp_mst_HE >= start_time)\n",
    "\n",
    "    \n",
    "    if clip_outliers:\n",
    "        clipped_lwr = lmp.LMP.quantile(0.0025)\n",
    "        clipped_upr = lmp.LMP.quantile(0.9975)\n",
    "        lmp = (\n",
    "            lmp\n",
    "            .mutate(LMP = ibis.ifelse(_.LMP < clipped_upr, _.LMP, clipped_upr))\n",
    "            .mutate(LMP = ibis.ifelse(_.LMP > clipped_lwr, _.LMP, clipped_lwr))\n",
    "        )\n",
    "\n",
    "    if end_time:\n",
    "        lmp = lmp.filter(_.timestamp_mst_HE <= end_time)\n",
    "\n",
    "    lmp = (\n",
    "        lmp\n",
    "        .mutate(unique_id=_.Settlement_Location_Name)\n",
    "        .filter(~_.unique_id.contains(\"_ARPA\")) # is missing?\n",
    "        .drop_null(['unique_id'])\n",
    "        .mutate(timestamp_mst=_.timestamp_mst_HE)\n",
    "        .mutate(LMP=_.LMP.cast(parameters.PRECISION))\n",
    "        .drop(drop_cols)\n",
    "        .group_by(['unique_id'])\n",
    "        .order_by(['unique_id', 'timestamp_mst'])\n",
    "        .mutate(lmp_diff = _.LMP - _.LMP.lag(1))\n",
    "    )\n",
    "\n",
    "    for i in [2,3,4,6]:\n",
    "        win = ibis.window(preceding=i, following=0, group_by=lmp.unique_id, order_by=lmp.timestamp_mst)\n",
    "        lmp = (\n",
    "            lmp\n",
    "            .mutate(lmp.lmp_diff.sum().over(win).cast(parameters.PRECISION).name(f'lmp_diff_rolling_{i}'))\n",
    "        )\n",
    "    \n",
    "\n",
    "    return lmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1780824-cabc-4297-8576-e4662fddc3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmp = de.prep_lmp(con)\n",
    "lmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35cc946-5ea5-48fe-b935-99c8de00a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmp.LMP.min(), lmp.LMP.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031733c6-c7be-4694-b69c-3f79d7c81df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmp_df = lmp.to_pandas().rename(\n",
    "    columns={\n",
    "        'LMP': 'LMP_HOURLY',\n",
    "        'unique_id':'node', \n",
    "        'timestamp_mst':'time'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a6c863-53cf-4bd4-aa69-022ec3e9d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrf = de.prep_mtrf(con)\n",
    "mtrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f172aed-7668-4513-bcd2-4c205f05aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtlf = de.prep_mtlf(con)\n",
    "mtlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1825be37-1063-4edc-888a-a652265c739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = de.prep_all_df(con, clip_outliers=True)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd72351-f3e8-47ef-9d93-828351d255ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.LMP.min(), all_df.LMP.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7bdeb4-417e-4f61-834c-04af1d62db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_pd = de.all_df_to_pandas(all_df)\n",
    "all_df_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4725a70a-58e4-4dfc-a6ef-2b5e3a2c4c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51abfee0-2c47-4ac4-9e60-d384549ead72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "301eda94-6012-4a9d-a0d4-7b78368e642f",
   "metadata": {},
   "source": [
    "## Prep model training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa3670-c875-4fac-a50e-d609990b0a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmp_all, train_all, test_all, train_test_all = de.get_train_test_all(con, clip_outliers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8740e0-6904-4ff5-ac34-d0ecaa0135ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_series = de.get_series(lmp_all)\n",
    "all_series[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8dc7d6-3ed5-4edc-a7a3-2148894eb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_all_series = de.get_series(train_test_all)\n",
    "train_test_all_series[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc1d39-cc8c-48f3-9e58-e95cb384b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series = de.get_series(train_all)\n",
    "train_series[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fda754-0fed-485b-a07b-c28da5c2b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_series = de.get_series(test_all)\n",
    "test_series[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9cd46d-6617-4c04-9c51-3075aabc4af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "futr_cov = de.get_futr_cov(all_df_pd)\n",
    "futr_cov[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4ccf3-d3d3-4d78-8b0b-7ca7a6b4251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_cov = de.get_past_cov(all_df_pd)\n",
    "past_cov[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b81a27-f5a8-4a6f-b62d-375a2648022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff064d-bda8-4bc2-84ce-2f48713820a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d054499-799e-4414-9d1c-46e29f4842b6",
   "metadata": {},
   "source": [
    "## Set up hyperparameter tuning study\n",
    "\n",
    "https://unit8co.github.io/darts/examples/17-hyperparameter-optimization.html?highlight=optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f1be51-80b0-4977-9262-253104ec9e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test build fit function\n",
    "if TEST_BUILD_BACKTEST:\n",
    "    \n",
    "    model = build_fit_tide(\n",
    "        series=train_series,\n",
    "        val_series=test_series,\n",
    "        future_covariates=futr_cov,\n",
    "        past_covariates=past_cov,\n",
    "        n_epochs=1)\n",
    "    \n",
    "    log.info(f'model.MODEL_TYPE: {model.MODEL_TYPE}')\n",
    "    \n",
    "    err_metric = model.backtest(\n",
    "            series=test_series,\n",
    "            past_covariates=past_cov,\n",
    "            future_covariates=futr_cov,\n",
    "            retrain=False,\n",
    "            forecast_horizon=parameters.FORECAST_HORIZON,\n",
    "            stride=25,\n",
    "            metric=[mae],\n",
    "            verbose=False,\n",
    "        )\n",
    "    \n",
    "    err_metric = np.mean(err_metric)\n",
    "    log.info(f'err_metric: {err_metric}')\n",
    "    \n",
    "    preds = model.predict(\n",
    "            series=train_series, \n",
    "            n=parameters.FORECAST_HORIZON,\n",
    "            past_covariates=past_cov,\n",
    "            future_covariates=futr_cov,\n",
    "            num_samples=200,\n",
    "    )\n",
    "    \n",
    "    errs = mae(test_series, preds, n_jobs=-1, verbose=True)\n",
    "    errs = np.mean(errs)\n",
    "    log.info(f'errs: {errs}')\n",
    "    \n",
    "    test_ci_err = get_ci_err(test_series, preds)\n",
    "    log.info(f'test_ci_err: {test_ci_err}')\n",
    "    np.mean(test_ci_err)\n",
    "    log.info(f'np.mean(test_ci_err): {np.mean(test_ci_err)}')\n",
    "    \n",
    "    ### test custom metric\n",
    "    val_backtest = model.backtest(\n",
    "        series=test_series,\n",
    "        past_covariates=past_cov,\n",
    "        future_covariates=futr_cov,\n",
    "        retrain=False,\n",
    "        forecast_horizon=parameters.FORECAST_HORIZON,\n",
    "        stride=25,\n",
    "        metric=[mae, get_ci_err],\n",
    "        verbose=False,\n",
    "        num_samples=200,\n",
    "        # retrain=False,\n",
    "    )\n",
    "    log.info(f'val_backtest: {val_backtest}')\n",
    "    \n",
    "    errs = np.mean([e[0] for e in val_backtest])\n",
    "    ci_err = np.mean([e[1] for e in val_backtest])\n",
    "    log.info(f'mean backtest errors: errs - {errs} - ci_err {ci_err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d464a4-0393-43ed-ac42-e3331abe4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_tsmixer(trial):\n",
    "    callback = [PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")]\n",
    "\n",
    "    # Hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 32, 256, step=2)\n",
    "    ff_size = trial.suggest_int(\"ff_size\", 16, 256, step=2)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 4, 12)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-4, step=1e-6)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 4, 12)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.4, 0.50, step=0.01)\n",
    "    activation = trial.suggest_categorical(\"activation\", ['ELU', 'SELU']) # , 'SELU', 'GELU'\n",
    "    encoder_key = trial.suggest_categorical(\"encoder_key\", ['rel', 'rel_mon', 'rel_mon_day'])\n",
    "    \n",
    "\n",
    "    # build and train the tsmixer model with these hyper-parameters:\n",
    "    model = build_fit_tsmixerx(\n",
    "        series=train_series,\n",
    "        val_series=test_series,\n",
    "        future_covariates=futr_cov,\n",
    "        past_covariates=past_cov,\n",
    "        hidden_size=hidden_size,\n",
    "        ff_size=ff_size,\n",
    "        num_blocks=num_blocks,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        dropout=dropout, \n",
    "        encoder_key=encoder_key,\n",
    "        activation=activation,\n",
    "        callbacks=callback,\n",
    "        model_id=f\"{trial.number:03}\",\n",
    "        log_tensorboard=True,\n",
    "    )\n",
    "\n",
    "    model_path = f\"{TRIAL_MODEL_DIR}/model_{trial.number}\"\n",
    "    trial.set_user_attr(\"model_path\", model_path)\n",
    "    model.save(model_path)\n",
    "\n",
    "    # Evaluate how good it is on the validation set\n",
    "    val_backtest = model.backtest(\n",
    "        series=test_series,\n",
    "        past_covariates=past_cov,\n",
    "        future_covariates=futr_cov,\n",
    "        retrain=False,\n",
    "        forecast_horizon=parameters.FORECAST_HORIZON,\n",
    "        stride=25,\n",
    "        metric=[mae, get_ci_err],\n",
    "        verbose=False,\n",
    "        num_samples=200,\n",
    "        # retrain=False,\n",
    "    )\n",
    "    \n",
    "    err_metric = np.mean([e[0] for e in val_backtest])\n",
    "    ci_error = np.mean([e[1] for e in val_backtest])\n",
    "    \n",
    "    if err_metric!= np.nan:\n",
    "        pass\n",
    "    else:\n",
    "        err_metric = float(\"inf\")\n",
    "\n",
    "    if ci_error!= np.nan:\n",
    "        pass\n",
    "    else:\n",
    "        ci_error = float(\"inf\")\n",
    "    \n",
    "\n",
    "    return err_metric , ci_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43ea990-8d76-4133-9cba-08e52c2bed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_futr = futr_cov[0].shape[1]\n",
    "n_past = past_cov[0].shape[1]\n",
    "\n",
    "n_futr, n_past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13de3bea-2b03-46bb-a450-bf84c5893a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_tide(trial):\n",
    "    callback = [PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")]\n",
    "\n",
    "    # Hyperparameters\n",
    "    num_encoder_decoder_layers = trial.suggest_int(\"num_encoder_decoder_layers\", 1, 8)\n",
    "    decoder_output_dim = trial.suggest_int(\"decoder_output_dim\", 8, 32)\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 8, 64, 1)\n",
    "    temporal_width_past = trial.suggest_int(\"temporal_width_past\", 0, n_past)\n",
    "    temporal_width_future = trial.suggest_int(\"temporal_width_future\", 0, n_futr)\n",
    "    # temporal_width = trial.suggest_int(\"temporal_width\", 0, 2)\n",
    "    temporal_decoder_hidden  = trial.suggest_int(\"temporal_decoder_hidden\", 4, 64, 1)\n",
    "    temporal_hidden_size_past = trial.suggest_int(\"temporal_hidden_size_past\", 8, 32, 1)\n",
    "    temporal_hidden_size_future = trial.suggest_int(\"temporal_hidden_size_future\", 8, 32, 1)\n",
    "    # temporal_hidden_size = trial.suggest_int(\"temporal_hidden_size\", 4, 16, 1)\n",
    "    \n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 5e-5, step=1e-6)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 6, 20)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.35, 0.5, step=0.01)\n",
    "    # use_layer_norm = trial.suggest_categorical(\"use_layer_norm\", [True, False])\n",
    "    # use_reversible_instance_norm = trial.suggest_categorical(\"use_reversible_instance_norm\", [True, False])\n",
    "    encoder_key = trial.suggest_categorical(\"encoder_key\", ['rel', 'rel_mon', 'rel_mon_day'])\n",
    "    \n",
    "\n",
    "    # build and train the tide model with these hyper-parameters:\n",
    "    model = build_fit_tide(\n",
    "        series=train_series,\n",
    "        val_series=test_series,\n",
    "        future_covariates=futr_cov,\n",
    "        past_covariates=past_cov,\n",
    "        num_encoder_decoder_layers=num_encoder_decoder_layers,\n",
    "        decoder_output_dim=decoder_output_dim,\n",
    "        hidden_size=hidden_size,\n",
    "        temporal_width_past=temporal_width_past,\n",
    "        temporal_width_future=temporal_width_future,\n",
    "        temporal_decoder_hidden=temporal_decoder_hidden,\n",
    "        temporal_hidden_size_past=temporal_hidden_size_past,\n",
    "        temporal_hidden_size_future=temporal_hidden_size_future,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        dropout=dropout, \n",
    "        # use_layer_norm=use_layer_norm,\n",
    "        # use_reversible_instance_norm=use_reversible_instance_norm,\n",
    "        encoder_key=encoder_key,\n",
    "        callbacks=callback,\n",
    "        model_id=f\"{trial.number:03}\",\n",
    "        log_tensorboard=True,\n",
    "    )\n",
    "\n",
    "    model_path = f\"{TRIAL_MODEL_DIR}/model_{trial.number}\"\n",
    "    trial.set_user_attr(\"model_path\", model_path)\n",
    "    model.save(model_path)\n",
    "\n",
    "    # Evaluate how good it is on the validation set\n",
    "    val_backtest = model.backtest(\n",
    "        series=test_series,\n",
    "        past_covariates=past_cov,\n",
    "        future_covariates=futr_cov,\n",
    "        retrain=False,\n",
    "        forecast_horizon=parameters.FORECAST_HORIZON,\n",
    "        stride=25,\n",
    "        metric=[mae, get_ci_err],\n",
    "        verbose=False,\n",
    "        num_samples=200,\n",
    "        # retrain=False,\n",
    "    )\n",
    "    \n",
    "    err_metric = np.mean([e[0] for e in val_backtest])\n",
    "    ci_error = np.mean([e[1] for e in val_backtest])\n",
    "    \n",
    "    if err_metric!= np.nan:\n",
    "        pass\n",
    "    else:\n",
    "        err_metric = float(\"inf\")\n",
    "\n",
    "    if ci_error!= np.nan:\n",
    "        pass\n",
    "    else:\n",
    "        ci_error = float(\"inf\")\n",
    "    \n",
    "\n",
    "    return err_metric , ci_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46663c6c-71dc-40e0-88f9-766fcd4ad641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_tft(trial):\n",
    "    callback = [PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")]\n",
    "\n",
    "    # Hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 8, 32)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 2)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 2)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-3, step=1e-6)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 2, 6)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.3, 0.5, step=0.01)\n",
    "    full_attention = trial.suggest_categorical(\"full_attention\", [False, True])\n",
    "    encoder_key = trial.suggest_categorical(\"encoder_key\", ['rel', 'rel_mon', 'rel_mon_day'])\n",
    "    \n",
    "\n",
    "    # build and train the tft model with these hyper-parameters:\n",
    "    model = build_fit_tft(\n",
    "        series=train_series,\n",
    "        val_series=test_series,\n",
    "        future_covariates=futr_cov,\n",
    "        past_covariates=past_cov,\n",
    "        hidden_size=hidden_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        dropout=dropout, \n",
    "        encoder_key = encoder_key,\n",
    "        full_attention=full_attention,\n",
    "        batch_size=64,\n",
    "        callbacks=callback,\n",
    "        model_id=f\"{trial.number:03}\",\n",
    "        log_tensorboard=True,\n",
    "    )\n",
    "\n",
    "    model_path = f\"{TRIAL_MODEL_DIR}/model_{trial.number}\"\n",
    "    trial.set_user_attr(\"model_path\", model_path)\n",
    "    model.save(model_path)\n",
    "\n",
    "    # Evaluate how good it is on the validation set\n",
    "    val_backtest = model.backtest(\n",
    "        series=test_series,\n",
    "        past_covariates=past_cov,\n",
    "        future_covariates=futr_cov,\n",
    "        retrain=False,\n",
    "        forecast_horizon=parameters.FORECAST_HORIZON,\n",
    "        stride=25,\n",
    "        metric=[mae, get_ci_err],\n",
    "        verbose=False,\n",
    "        num_samples=200,\n",
    "        # retrain=False,\n",
    "    )\n",
    "    \n",
    "    err_metric = np.mean([e[0] for e in val_backtest])\n",
    "    ci_error = np.mean([e[1] for e in val_backtest])\n",
    "    \n",
    "    if err_metric!= np.nan:\n",
    "        pass\n",
    "    else:\n",
    "        err_metric = float(\"inf\")\n",
    "\n",
    "    if ci_error!= np.nan:\n",
    "        pass\n",
    "    else:\n",
    "        ci_error = float(\"inf\")\n",
    "    \n",
    "\n",
    "    return err_metric , ci_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b901d-12b1-462b-864b-967cfb0e86a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'study_csv/{MODEL_TYPE}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15c569-e172-44d3-970a-ed7ed6f9d788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_callback(study, trial):\n",
    "    best_smape = min(study.best_trials, key=lambda t: t.values[0])\n",
    "    best_ci = min(study.best_trials, key=lambda t: t.values[1])\n",
    "    best_total = min(study.best_trials, key=lambda t: sum(t.values))\n",
    "    print('\\n' + '*'*30, flush=True)\n",
    "    log.info(f\"\\nTrial: {trial.number} Current values: {trial.values}\")\n",
    "    log.info(f\"Current params: \\n{log_pretty(trial.params)}\")\n",
    "    log.info(f\"Best {target_names[0]}: Num: {best_smape.number}, {best_smape.values}, Best params: \\n{log_pretty(best_smape.params)}\")\n",
    "    log.info(f\"Best {target_names[1]}: Num: {best_ci.number}, {best_ci.values}, Best params: \\n{log_pretty(best_ci.params)}\")\n",
    "    log.info(f\"Best Total: Num: {best_total.number}, {best_total.values}, Best params: \\n{log_pretty(best_total.params)}\")\n",
    "    \n",
    "    study.trials_dataframe().to_csv(f'study_csv/{MODEL_TYPE}/{trial.number:03}.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52afa956-a088-48e2-b788-decbdf3f41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['MAE', 'CI_ERROR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e7af9-87af-4085-ae40-1f45df699d1d",
   "metadata": {},
   "source": [
    "## Start Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffe4cf1-fa87-4fc3-b967-b7680c1f6b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_MODEL_DIR = f'optuna/{MODEL_TYPE}'\n",
    "MODEL_CHECKPOINT_DIR = f'model_checkpoints/{MODEL_TYPE}_model'\n",
    "\n",
    "if REMOVE_PRIOR_MODELS:\n",
    "    try:\n",
    "        optuna.delete_study(study_name=f\"spp_weis_{MODEL_TYPE}\", storage=\"sqlite:///spp_trials.db\")\n",
    "        shutil.rmtree(TRIAL_MODEL_DIR)\n",
    "        shutil.rmtree(MODEL_CHECKPOINT_DIR)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "os.makedirs(TRIAL_MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_CHECKPOINT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17adf815-84b5-404a-ac2f-09899ce26d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_TYPE == 'tft':\n",
    "    objective_func = objective_tft\n",
    "    \n",
    "elif MODEL_TYPE == 'tide':\n",
    "    objective_func = objective_tide\n",
    "    \n",
    "elif MODEL_TYPE == 'ts_mixer':\n",
    "    objective_func = objective_tsmixer\n",
    "\n",
    "elif MODEL_TYPE == 'dlinear':\n",
    "    objective_func = objective_dlinear\n",
    "\n",
    "elif MODEL_TYPE == 'nlinear':\n",
    "    objective_func = objective_nlinear\n",
    "    \n",
    "else:\n",
    "    raise ValueError(f'Unsuported MODEL_TYPE: {MODEL_TYPE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff5d5d-8efd-473b-92ab-254c5d7b2158",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_name = f'spp_weis_{MODEL_TYPE}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aef6336-c015-4a2c-bcb2-afa60c4f9737",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "        directions=[\"minimize\", \"minimize\"],\n",
    "        storage=\"sqlite:///spp_trials.db\", \n",
    "        study_name=study_name,\n",
    "        load_if_exists=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d0bfc-075c-48c1-a5f2-26770bbb25f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_EXP:\n",
    "    study.optimize(objective_func, n_trials=NUM_TRIALS, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894cf193-3175-4bc8-ad75-acbe94cb079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, target_name in enumerate(target_names):\n",
    "    fig = plot_optimization_history(study, target=lambda t: t.values[i], target_name=target_name)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2958ec75-b07e-4c0e-aae9-803c73d787b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, target_name in enumerate(target_names):\n",
    "    fig = plot_contour(study, params=[\"lr\", \"n_epochs\"], target=lambda t: t.values[i], target_name=target_name)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5781f00d-757d-4acd-b082-ecd3e0ab7aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c64fac4-3cc7-4a60-92e5-c5492e7eb830",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pareto_front(study, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84fee56-caae-4e70-9fc5-3c2114f2de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pareto_front(study, target_names=target_names, include_dominated_trials=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe90afd-c684-47d5-9c13-4ef5212d79b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: think about how to wieght values to get best model\n",
    "# best_model = min(study.best_trials, key=lambda t: sum(t.values))\n",
    "best_model = min(study.best_trials, key=lambda t: t.values[0] + 0.5*t.values[1])\n",
    "log.info(f\"Best number: {best_model.number}\")\n",
    "log.info(f\"Best values: {best_model.values}\")\n",
    "log.info(f\"Best params: \\n{log_pretty(best_model.params)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c9cec9-f5d9-440d-892d-7b5fb8fdfe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.trials_dataframe().to_csv(f'study_csv/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc88e650-4fd1-4f5b-aecd-3885aa06bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_trials(\n",
    "    study_name: str,\n",
    "    storage: str=\"sqlite:///spp_trials.db\",\n",
    "    n_results: int=5,\n",
    "    ci_scaler: float=0.25,\n",
    ") -> pd.DataFrame:\n",
    "    study = optuna.load_study(\n",
    "        study_name=study_name,\n",
    "        storage=storage, \n",
    "    )\n",
    "    \n",
    "    trials = pd.DataFrame([{'number': s.number, 'values': s.values, 'params': s.params} for s in study.trials])\n",
    "    trials['total_value'] = [v[0] + ci_scaler*v[1] if v else np.nan for v in trials['values']]\n",
    "    trials['model_path'] = [s.user_attrs['model_path'] if s.user_attrs else None for s in study.trials]\n",
    "    trials = trials[~trials.params.duplicated()]\n",
    "    best_trials = trials.sort_values('total_value').head(n_results)\n",
    "    \n",
    "    \n",
    "    return best_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6524649-60d7-4cee-b91b-3a5e984d4063",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trials = get_best_trials(study_name, ci_scaler=0.5, n_results=5)\n",
    "# best_trials['model_path'] = [p.pop('user_attrs_model_path', None) for p in best_trials.params]\n",
    "best_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a1905-ea70-400e-864d-0490d20c9b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the list of best params in sxc/parameters.py\n",
    "[p for p in best_trials.params]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c3bcf4-7a66-4334-b655-00184c9317bf",
   "metadata": {},
   "source": [
    "## Create ensemble from best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092fb08-39d2-46de-8530-e38d08949fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasting_models = []\n",
    "for m in best_trials.model_path:\n",
    "    if 'ts_mixer' in m.lower():\n",
    "        forecasting_models += [TSMixerModel.load(m, map_location=torch.device('cpu'))]\n",
    "        \n",
    "    elif 'tide' in m.lower():\n",
    "        forecasting_models += [TiDEModel.load(m, map_location=torch.device('cpu'))]\n",
    "\n",
    "    elif 'tft' in m.lower():\n",
    "        forecasting_models += [TFTModel.load(m, map_location=torch.device('cpu'))]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'Unsuported MODEL_TYPE: {m}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90438975-d305-44ad-8e87-125d06170f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e23af-7398-4bb6-8f73-1daad52ea1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = NaiveEnsembleModel(\n",
    "    forecasting_models=forecasting_models, \n",
    "    train_forecasting_models=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b984cc4-bef4-469d-b102-16aa3473d468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d84debb-a12d-4882-b55f-61a9a18e7e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "354b246f-2f5f-4847-bbc3-a254b664dea6",
   "metadata": {},
   "source": [
    "## Plot test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fad7c8-0a4b-47b4-8117-fc16c73c3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ind = 3\n",
    "plot_series = all_series[plot_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe27758-ff9c-408e-8d5e-0f5456a026b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series.static_covariates.unique_id.LMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef569b3-64d4-4339-a0c1-c851c3286325",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc56455-325e-4002-8dab-d77bff29953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_end_times = pd.date_range(\n",
    "    end=test_series[plot_ind].end_time(),\n",
    "    periods=10,\n",
    "    freq='d',\n",
    ")\n",
    "\n",
    "plot_end_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd21863-5d50-43df-9767-0e3804d9f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "for plot_end_time in plot_end_times:\n",
    "    log.info(f'plot_end_time: {plot_end_time}')\n",
    "    \n",
    "    plot_node_name = plot_series.static_covariates.unique_id.LMP\n",
    "    \n",
    "    # if test_end_time < test_series.end_time():\n",
    "    node_series = plot_series.drop_after(plot_end_time)\n",
    "        \n",
    "    log.info(f'plot_end_time: {plot_end_time}')\n",
    "    log.info(f'node_series.end_time(): {node_series.end_time()}')\n",
    "    future_cov_series = futr_cov[0]\n",
    "    past_cov_series = past_cov[0]\n",
    "    \n",
    "    data = {\n",
    "        'series': [node_series.to_json()],\n",
    "        'past_covariates': [past_cov_series.to_json()],\n",
    "        'future_covariates': [future_cov_series.to_json()],\n",
    "        'n': parameters.FORECAST_HORIZON,\n",
    "        'num_samples': 200\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    plot_cov_df = future_cov_series.pd_dataframe()\n",
    "    plot_cov_df = (\n",
    "        plot_cov_df\n",
    "        .reset_index()\n",
    "        .rename(columns={'timestamp_mst':'time', 're_ratio': 'Ratio'})\n",
    "    )\n",
    "    \n",
    "    # Predict on a Pandas DataFrame.\n",
    "    df['num_samples'] = 500\n",
    "    \n",
    "    # for mlflow pyfunc model\n",
    "    # preds_json = loaded_model.predict(df)\n",
    "    # preds = TimeSeries.from_json(preds_json)\n",
    "\n",
    "    # for darts model\n",
    "    preds = loaded_model.predict(\n",
    "        series=node_series,\n",
    "        past_covariates=past_cov_series,\n",
    "        future_covariates=future_cov_series,\n",
    "        n=parameters.FORECAST_HORIZON,\n",
    "        num_samples=500,\n",
    "    )\n",
    "    \n",
    "    q_df = plotting.get_quantile_df(preds, plot_node_name)\n",
    "    \n",
    "    plot_df = plotting.get_mean_df(preds, plot_node_name).merge(\n",
    "        plotting.get_quantile_df(preds, plot_node_name),\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "    \n",
    "    plot_df = plotting.get_plot_df(\n",
    "            # TimeSeries.from_json(pred),\n",
    "            preds,\n",
    "            plot_cov_df,\n",
    "            lmp_df,\n",
    "            plot_node_name,\n",
    "        )\n",
    "    plot_df.rename(columns={'mean':'mean_fcast'}, inplace=True)\n",
    "    plot_df\n",
    "    \n",
    "    plotting.plotly_forecast(plot_df, plot_node_name, show_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41797fb1-0ef8-4efc-9951-6b6b6b427eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94b0bb-ecde-48e2-905e-54e06a59f8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7d6c8e7-f212-4c56-9805-4065afe0a8a2",
   "metadata": {},
   "source": [
    "## Deprecated MLFlow code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa0813a-cb4c-44f9-8013-ddea2aeae86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLFlow set up\n",
    "## mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "# log.info(f'mlflow.get_tracking_uri(): {mlflow.get_tracking_uri()}')\n",
    "# exp_name = 'spp_weis'\n",
    "\n",
    "# if mlflow.get_experiment_by_name(exp_name) is None:\n",
    "#     exp = mlflow.create_experiment(exp_name)\n",
    "    \n",
    "# exp = mlflow.get_experiment_by_name(exp_name)\n",
    "# exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a8a589-1143-406c-854b-5ffbfedbf1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get signature\n",
    "# node_series = train_series[0]\n",
    "# future_cov_series = futr_cov[0]\n",
    "# past_cov_series = past_cov[0]\n",
    "\n",
    "# data = {\n",
    "#     'series': [node_series.to_json()],\n",
    "#     'past_covariates': [past_cov_series.to_json()],\n",
    "#     'future_covariates': [future_cov_series.to_json()],\n",
    "#     'n': parameters.FORECAST_HORIZON,\n",
    "#     'num_samples': 200\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# ouput_example = 'the endpoint return json as a string'\n",
    "\n",
    "# from mlflow.models import infer_signature\n",
    "# darts_signature = infer_signature(df, ouput_example)\n",
    "# darts_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de9a04-be94-45f4-9ea9-4aa947c19041",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create and log ensemble model\n",
    "# with mlflow.start_run(experiment_id=exp.experiment_id) as run:\n",
    "\n",
    "#     MODEL_TYPE = 'naive_ens'\n",
    "\n",
    "#     # all_models = models_tsmixer + models_tide + models_tft\n",
    "#     # fit model with best params from study\n",
    "#     model = NaiveEnsembleModel(\n",
    "#         forecasting_models=all_models, \n",
    "#         train_forecasting_models=False\n",
    "#     )\n",
    "\n",
    "#     model.MODEL_TYPE = MODEL_TYPE\n",
    "#     model.TRAIN_TIMESTAMP = pd.Timestamp.utcnow()\n",
    "    \n",
    "#     log.info(f'run.info: \\n{run.info}')\n",
    "#     artifact_path = \"model_artifacts\"\n",
    "    \n",
    "#     metrics = {}\n",
    "#     model_params = model.model_params\n",
    "    \n",
    "#     # final model back test on validation data\n",
    "#     acc = model.backtest(\n",
    "#             series=test_series,\n",
    "#             past_covariates=past_cov,\n",
    "#             future_covariates=futr_cov,\n",
    "#             retrain=False,\n",
    "#             forecast_horizon=parameters.FORECAST_HORIZON,\n",
    "#             stride=49,\n",
    "#             metric=[mae, rmse, get_ci_err],\n",
    "#             verbose=False,\n",
    "#             num_samples=200,\n",
    "#         )\n",
    "\n",
    "#     mean_acc = np.mean(acc, axis=0)\n",
    "#     log.info(f'FINAL ACC: mae - {mean_acc[0]} | rmse - {mean_acc[1]} | ci_err - {mean_acc[2]}')\n",
    "#     acc_df = pd.DataFrame(\n",
    "#         mean_acc.reshape(1,-1),\n",
    "#         columns=['mae', 'rmse', 'ci_error']\n",
    "#     )\n",
    "\n",
    "#     # add and log metrics\n",
    "#     metrics['final_mae'] = acc_df.mae[0]\n",
    "#     metrics['final_rmse'] = acc_df.rmse[0]\n",
    "#     metrics['final_ci_error'] = acc_df.ci_error[0]\n",
    "#     mlflow.log_metrics(metrics)\n",
    "\n",
    "#     # set up path to save model\n",
    "#     model_path = '/'.join([artifact_path, model.MODEL_TYPE])\n",
    "#     model_path = '/'.join([artifact_path, 'ens_models'])\n",
    "\n",
    "#     shutil.rmtree(artifact_path, ignore_errors=True)\n",
    "#     os.makedirs(model_path)\n",
    "\n",
    "#     # log params\n",
    "#     mlflow.log_params(model_params)\n",
    "\n",
    "#     # save model files (model, model.ckpt) \n",
    "#     # and load them to artifacts when logging the model\n",
    "#     # model.save(model_path)\n",
    "    \n",
    "#     for i, m in enumerate(all_models):\n",
    "#         m.save(f'{model_path}/{m.MODEL_TYPE}_{i}')\n",
    "\n",
    "#     # save MODEL_TYPE to artifacts\n",
    "#     # this will be used to load the model from the artifacts\n",
    "#     model_type_path = '/'.join([artifact_path, 'MODEL_TYPE.pkl'])\n",
    "#     with open(model_type_path, 'wb') as handle:\n",
    "#         pickle.dump(model.MODEL_TYPE, handle)\n",
    "\n",
    "#     model_timestamp = '/'.join([artifact_path, 'TRAIN_TIMESTAMP.pkl'])\n",
    "#     with open(model_timestamp, 'wb') as handle:\n",
    "#         pickle.dump(model.TRAIN_TIMESTAMP, handle)\n",
    "    \n",
    "#     # map model artififacts in dictionary\n",
    "#     artifacts = {f:f'{artifact_path}/{f}' for f in os.listdir('model_artifacts')}\n",
    "#     artifacts['model'] = model_path\n",
    "    \n",
    "#     # log model\n",
    "#     # https://www.mlflow.org/docs/latest/tutorials-and-examples/tutorial.html#pip-requirements-example\n",
    "#     mlflow.pyfunc.log_model(\n",
    "#         artifact_path='GlobalForecasting',\n",
    "#         code_path=['src/darts_wrapper.py'],\n",
    "#         signature=darts_signature,\n",
    "#         artifacts=artifacts,\n",
    "#         python_model=DartsGlobalModel(), \n",
    "#         pip_requirements=[\"-r notebooks/model_training/requirements.txt\"],\n",
    "#         registered_model_name=parameters.MODEL_NAME,\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84324797-1d16-45cb-9ebf-06fc9a543802",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get latest run\n",
    "# runs = mlflow.search_runs(\n",
    "#     experiment_ids = exp.experiment_id,\n",
    "#     # order_by=['metrics.test_mae']\n",
    "#     order_by=['end_time']\n",
    "#     )\n",
    "\n",
    "# runs.sort_values('end_time', ascending=False, inplace=True)\n",
    "# runs.head()\n",
    "\n",
    "# best_run_id = runs.run_id.iloc[0]\n",
    "# best_run_id\n",
    "\n",
    "# runs['artifact_uri'].iloc[0]\n",
    "\n",
    "# model_path = runs['artifact_uri'].iloc[0] + '/GlobalForecasting'\n",
    "\n",
    "# loaded_model = mlflow.pyfunc.load_model(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
