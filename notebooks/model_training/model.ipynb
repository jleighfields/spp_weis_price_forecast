{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69203664-529c-4f3c-9526-4ca37adce1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b770fc59-5d59-4721-ad6a-438785b4a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = 'ts_mixer'\n",
    "# MODEL_TYPE = 'tft'\n",
    "# MODEL_TYPE = 'tide'\n",
    "\n",
    "RUN_EXP = True\n",
    "NUM_TRIALS = 100\n",
    "\n",
    "TEST_BUILD_BACKTEST = False\n",
    "\n",
    "# for pyfunc model\n",
    "MODEL_NAME = 'spp_weis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52cf595-9e8a-4d77-8f2a-f83bc5725504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from typing import List\n",
    "\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "import ibis\n",
    "import ibis.selectors as s\n",
    "from ibis import _\n",
    "ibis.options.interactive = True\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import torch\n",
    "\n",
    "from darts import TimeSeries, concatenate\n",
    "from darts.dataprocessing.transformers import (\n",
    "    Scaler,\n",
    "    MissingValuesFiller,\n",
    "    Mapper,\n",
    "    InvertibleMapper,\n",
    ")\n",
    "from darts.dataprocessing import Pipeline\n",
    "from darts.metrics import mape, smape, mae, ope, rmse\n",
    "from darts.utils.statistics import check_seasonality, plot_acf\n",
    "from darts.datasets import AirPassengersDataset, IceCreamHeaterDataset\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from darts.utils.likelihood_models import QuantileRegression, GumbelLikelihood, GaussianLikelihood\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.utils.timeseries_generation import (\n",
    "    gaussian_timeseries,\n",
    "    linear_timeseries,\n",
    "    sine_timeseries,\n",
    ")\n",
    "from darts.models import (\n",
    "    TFTModel,\n",
    "    TiDEModel,\n",
    "    DLinearModel,\n",
    "    NLinearModel,\n",
    "    TSMixerModel\n",
    ")\n",
    "\n",
    "\n",
    "from torchmetrics import (\n",
    "    SymmetricMeanAbsolutePercentageError, \n",
    "    MeanAbsoluteError, \n",
    "    MeanSquaredError,\n",
    ")\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "\n",
    "# define log\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9265743c-3605-48d9-83a8-69b56743c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_contour,\n",
    "    plot_param_importances,\n",
    "    plot_pareto_front,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fb2027-6f33-440d-ad6b-b3d3632d8103",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113b2e7-4a1b-4e41-959e-21bc661746fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom modules\n",
    "import src.data_engineering as de\n",
    "from src import parameters\n",
    "from src import plotting\n",
    "from src.modeling import (\n",
    "    get_ci_err, build_fit_tsmixerx, build_fit_tide, build_fit_tft, log_pretty\n",
    ")\n",
    "\n",
    "## will be loaded from root when deployed\n",
    "from src.darts_wrapper import DartsGlobalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211757e7-9d91-4d9b-916b-41501e357379",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(f'FORECAST_HORIZON: {parameters.FORECAST_HORIZON}')\n",
    "log.info(f'INPUT_CHUNK_LENGTH: {parameters.INPUT_CHUNK_LENGTH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c3b07-8384-47e7-bca2-c45644cac3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ade2b-8136-4348-817a-fb8c15510a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna.delete_study(study_name=\"spp_weis_tsmixer\", storage=\"sqlite:///spp_trials.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d952be-198a-4d48-871b-4ccec3960b41",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b59c65b-8e78-4e3a-8a2e-fbf009fef686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to database\n",
    "con = ibis.duckdb.connect(\"data/spp.ddb\", read_only=True)\n",
    "con.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1780824-cabc-4297-8576-e4662fddc3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmp = de.prep_lmp(con)\n",
    "lmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031733c6-c7be-4694-b69c-3f79d7c81df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmp_df = lmp.to_pandas().rename(\n",
    "    columns={\n",
    "        'LMP': 'LMP_HOURLY',\n",
    "        'unique_id':'node', \n",
    "        'timestamp_mst':'time'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a6c863-53cf-4bd4-aa69-022ec3e9d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrf = de.prep_mtrf(con)\n",
    "mtrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f172aed-7668-4513-bcd2-4c205f05aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtlf = de.prep_mtlf(con)\n",
    "mtlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1825be37-1063-4edc-888a-a652265c739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = de.prep_all_df(con)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7bdeb4-417e-4f61-834c-04af1d62db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_pd = de.all_df_to_pandas(de.prep_all_df(con))\n",
    "all_df_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4725a70a-58e4-4dfc-a6ef-2b5e3a2c4c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9765b785-b1e7-4f77-a8dc-52fbadfce88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "301eda94-6012-4a9d-a0d4-7b78368e642f",
   "metadata": {},
   "source": [
    "## Prep model training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa3670-c875-4fac-a50e-d609990b0a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmp_all, train_all, test_all, train_test_all = de.get_train_test_all(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8740e0-6904-4ff5-ac34-d0ecaa0135ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_series = de.get_series(lmp_all)\n",
    "all_series[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8dc7d6-3ed5-4edc-a7a3-2148894eb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_all_series = de.get_series(train_test_all)\n",
    "train_test_all_series[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc1d39-cc8c-48f3-9e58-e95cb384b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series = de.get_series(train_all)\n",
    "train_series[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fda754-0fed-485b-a07b-c28da5c2b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_series = de.get_series(test_all)\n",
    "test_series[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9cd46d-6617-4c04-9c51-3075aabc4af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "futr_cov = de.get_futr_cov(all_df_pd)\n",
    "futr_cov[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4ccf3-d3d3-4d78-8b0b-7ca7a6b4251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_cov = de.get_past_cov(all_df_pd)\n",
    "past_cov[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b81a27-f5a8-4a6f-b62d-375a2648022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff064d-bda8-4bc2-84ce-2f48713820a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d054499-799e-4414-9d1c-46e29f4842b6",
   "metadata": {},
   "source": [
    "## Set up hyperparameter tuning study\n",
    "\n",
    "https://unit8co.github.io/darts/examples/17-hyperparameter-optimization.html?highlight=optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f1be51-80b0-4977-9262-253104ec9e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test build fit function\n",
    "if TEST_BUILD_BACKTEST:\n",
    "    \n",
    "    model = build_fit_tide(\n",
    "        series=train_series,\n",
    "        val_series=test_series,\n",
    "        future_covariates=futr_cov,\n",
    "        past_covariates=past_cov,\n",
    "        n_epochs=1)\n",
    "    \n",
    "    log.info(f'model.MODEL_TYPE: {model.MODEL_TYPE}')\n",
    "    \n",
    "    err_metric = model.backtest(\n",
    "            series=test_series,\n",
    "            past_covariates=past_cov,\n",
    "            future_covariates=futr_cov,\n",
    "            retrain=False,\n",
    "            forecast_horizon=parameters.FORECAST_HORIZON,\n",
    "            stride=25,\n",
    "            metric=[mae],\n",
    "            verbose=False,\n",
    "        )\n",
    "    \n",
    "    err_metric = np.mean(err_metric)\n",
    "    log.info(f'err_metric: {err_metric}')\n",
    "    \n",
    "    preds = model.predict(\n",
    "            series=train_series, \n",
    "            n=parameters.FORECAST_HORIZON,\n",
    "            past_covariates=past_cov,\n",
    "            future_covariates=futr_cov,\n",
    "            num_samples=200,\n",
    "    )\n",
    "    \n",
    "    errs = rmse(test_series, preds, n_jobs=-1, verbose=True)\n",
    "    errs = np.mean(errs)\n",
    "    log.info(f'errs: {errs}')\n",
    "    \n",
    "    test_ci_err = get_ci_err(test_series, preds)\n",
    "    log.info(f'test_ci_err: {test_ci_err}')\n",
    "    np.mean(test_ci_err)\n",
    "    log.info(f'np.mean(test_ci_err): {np.mean(test_ci_err)}')\n",
    "    \n",
    "    ### test custom metric\n",
    "    val_backtest = model.backtest(\n",
    "        series=test_series,\n",
    "        past_covariates=past_cov,\n",
    "        future_covariates=futr_cov,\n",
    "        retrain=False,\n",
    "        forecast_horizon=parameters.FORECAST_HORIZON,\n",
    "        stride=25,\n",
    "        metric=[mae, get_ci_err],\n",
    "        verbose=False,\n",
    "        num_samples=200,\n",
    "        # retrain=False,\n",
    "    )\n",
    "    log.info(f'val_backtest: {val_backtest}')\n",
    "    \n",
    "    errs = np.mean([e[0] for e in val_backtest])\n",
    "    ci_err = np.mean([e[1] for e in val_backtest])\n",
    "    log.info(f'mean backtest errors: errs - {errs} - ci_err {ci_err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f713f4b5-c1e0-4541-b279-0e6d25d5eef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d464a4-0393-43ed-ac42-e3331abe4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_tsmixer(trial):\n",
    "    callback = [PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")]\n",
    "\n",
    "    # Hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 64, 256, step=2)\n",
    "    ff_size = trial.suggest_int(\"ff_size\", 64, 256, step=2)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 8)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 2e-4, step=1e-6)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 2, 6)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.4, 0.5, step=0.01)\n",
    "    \n",
    "\n",
    "    # build and train the TCN model with these hyper-parameters:\n",
    "    model = build_fit_tsmixerx(\n",
    "        series=train_series,\n",
    "        val_series=test_series,\n",
    "        future_covariates=futr_cov,\n",
    "        past_covariates=past_cov,\n",
    "        hidden_size=hidden_size,\n",
    "        ff_size=ff_size,\n",
    "        num_blocks=num_blocks,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        dropout=dropout, \n",
    "        callbacks=callback,\n",
    "    )\n",
    "\n",
    "    # Evaluate how good it is on the validation set\n",
    "    val_backtest = model.backtest(\n",
    "        series=test_series,\n",
    "        past_covariates=past_cov,\n",
    "        future_covariates=futr_cov,\n",
    "        retrain=False,\n",
    "        forecast_horizon=parameters.FORECAST_HORIZON,\n",
    "        stride=25,\n",
    "        metric=[mae, get_ci_err],\n",
    "        verbose=False,\n",
    "        num_samples=200,\n",
    "        # retrain=False,\n",
    "    )\n",
    "    \n",
    "    err_metric = np.mean([e[0] for e in val_backtest])\n",
    "    ci_error = np.mean([e[1] for e in val_backtest])\n",
    "    \n",
    "    if err_metric!= np.nan:\n",
    "        pass\n",
    "    else:\n",
    "        err_metric = float(\"inf\")\n",
    "\n",
    "    if ci_error!= np.nan:\n",
    "        pass\n",
    "    else:\n",
    "        ci_error = float(\"inf\")\n",
    "    \n",
    "\n",
    "    return err_metric , ci_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13de3bea-2b03-46bb-a450-bf84c5893a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_tide(trial):\n",
    "    callback = [PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")]\n",
    "\n",
    "    # Hyperparameters\n",
    "    num_encoder_decoder_layers = trial.suggest_int(\"num_encoder_layers\", 1, 2)\n",
    "    decoder_output_dim = trial.suggest_int(\"decoder_output_dim\", 8, 32)\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 32, 128, 4)\n",
    "    temporal_width_past = trial.suggest_int(\"temporal_width_past\", 0, 10)\n",
    "    temporal_width_future = trial.suggest_int(\"temporal_width_future\", 0, 10)\n",
    "    temporal_decoder_hidden  = trial.suggest_int(\"temporal_decoder_hidden\", 4, 32, 2)\n",
    "    temporal_hidden_size_past = trial.suggest_int(\"temporal_hidden_size_past\", 4, 32, 2)\n",
    "    temporal_hidden_size_future = trial.suggest_int(\"temporal_hidden_size_future\", 4, 32, 2)\n",
    "    \n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 5e-4, step=1e-6)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 4, 8)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.4, 0.5, step=0.01)\n",
    "    \n",
    "\n",
    "    # build and train the TCN model with these hyper-parameters:\n",
    "    model = build_fit_tide(\n",
    "        series=train_series,\n",
    "        val_series=test_series,\n",
    "        future_covariates=futr_cov,\n",
    "        past_covariates=past_cov,\n",
    "        num_encoder_layers=num_encoder_decoder_layers,\n",
    "        num_decoder_layers=num_encoder_decoder_layers,\n",
    "        decoder_output_dim=decoder_output_dim,\n",
    "        hidden_size=hidden_size,\n",
    "        temporal_width_past=temporal_width_past,\n",
    "        temporal_width_future=temporal_width_future,\n",
    "        temporal_decoder_hidden=temporal_decoder_hidden,\n",
    "        temporal_hidden_size_past = temporal_hidden_size_past,\n",
    "        temporal_hidden_size_future = temporal_hidden_size_future,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        dropout=dropout, \n",
    "        callbacks=callback,\n",
    "    )\n",
    "\n",
    "    # Evaluate how good it is on the validation set\n",
    "    val_backtest = model.backtest(\n",
    "        series=test_series,\n",
    "        past_covariates=past_cov,\n",
    "        future_covariates=futr_cov,\n",
    "        retrain=False,\n",
    "        forecast_horizon=parameters.FORECAST_HORIZON,\n",
    "        stride=25,\n",
    "        metric=[mae, get_ci_err],\n",
    "        verbose=False,\n",
    "        num_samples=200,\n",
    "        # retrain=False,\n",
    "    )\n",
    "    \n",
    "    err_metric = np.mean([e[0] for e in val_backtest])\n",
    "    ci_error = np.mean([e[1] for e in val_backtest])\n",
    "    \n",
    "    if err_metric!= np.nan:\n",
    "        pass\n",
    "    else:\n",
    "        err_metric = float(\"inf\")\n",
    "\n",
    "    if ci_error!= np.nan:\n",
    "        pass\n",
    "    else:\n",
    "        ci_error = float(\"inf\")\n",
    "    \n",
    "\n",
    "    return err_metric , ci_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46663c6c-71dc-40e0-88f9-766fcd4ad641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_tft(trial):\n",
    "    callback = [PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")]\n",
    "\n",
    "    # Hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 4, 10)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-3, step=1e-5)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 2, 4)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.3, 0.5, step=0.01)\n",
    "    # full_attention = trial.suggest_categorical(\"full_attention\", [False, True])\n",
    "    \n",
    "\n",
    "    # build and train the TCN model with these hyper-parameters:\n",
    "    model = build_fit_tft(\n",
    "        series=train_series,\n",
    "        val_series=test_series,\n",
    "        future_covariates=futr_cov,\n",
    "        past_covariates=past_cov,\n",
    "        hidden_size=hidden_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        dropout=dropout, \n",
    "        full_attention=False,\n",
    "        batch_size=64,\n",
    "        callbacks=callback,\n",
    "    )\n",
    "\n",
    "    # Evaluate how good it is on the validation set\n",
    "    val_backtest = model.backtest(\n",
    "        series=test_series,\n",
    "        past_covariates=past_cov,\n",
    "        future_covariates=futr_cov,\n",
    "        retrain=False,\n",
    "        forecast_horizon=parameters.FORECAST_HORIZON,\n",
    "        stride=25,\n",
    "        metric=[mae, get_ci_err],\n",
    "        verbose=False,\n",
    "        num_samples=200,\n",
    "        # retrain=False,\n",
    "    )\n",
    "    \n",
    "    err_metric = np.mean([e[0] for e in val_backtest])\n",
    "    ci_error = np.mean([e[1] for e in val_backtest])\n",
    "    \n",
    "    if err_metric!= np.nan:\n",
    "        pass\n",
    "    else:\n",
    "        err_metric = float(\"inf\")\n",
    "\n",
    "    if ci_error!= np.nan:\n",
    "        pass\n",
    "    else:\n",
    "        ci_error = float(\"inf\")\n",
    "    \n",
    "\n",
    "    return err_metric , ci_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15c569-e172-44d3-970a-ed7ed6f9d788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_callback(study, trial):\n",
    "    best_smape = min(study.best_trials, key=lambda t: t.values[0])\n",
    "    best_ci = min(study.best_trials, key=lambda t: t.values[1])\n",
    "    best_total = min(study.best_trials, key=lambda t: sum(t.values))\n",
    "    print('\\n' + '*'*30, flush=True)\n",
    "    log.info(f\"\\nTrial: {trial.number} Current values: {trial.values}\")\n",
    "    log.info(f\"Current params: \\n{log_pretty(trial.params)}\")\n",
    "    log.info(f\"Best {target_names[0]}: {best_smape.values}, Best params: \\n{log_pretty(best_smape.params)}\")\n",
    "    log.info(f\"Best {target_names[1]}: {best_ci.values}, Best params: \\n{log_pretty(best_ci.params)}\")\n",
    "    log.info(f\"Best Total: {best_total.values}, Best params: \\n{log_pretty(best_total.params)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52afa956-a088-48e2-b788-decbdf3f41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['MAE', 'CI_ERROR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e7af9-87af-4085-ae40-1f45df699d1d",
   "metadata": {},
   "source": [
    "## Start Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17adf815-84b5-404a-ac2f-09899ce26d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_TYPE == 'tft':\n",
    "    study_name = \"spp_weis_tft\"\n",
    "    objective_func = objective_tft\n",
    "    \n",
    "elif MODEL_TYPE == 'tide':\n",
    "    study_name = \"spp_weis_tide\"\n",
    "    objective_func = objective_tide\n",
    "    \n",
    "elif MODEL_TYPE == 'ts_mixer':\n",
    "    study_name = \"spp_weis_tsmixer\"\n",
    "    objective_func = objective_tsmixer\n",
    "\n",
    "else:\n",
    "    raise ValueError(f'Unsuported MODEL_TYPE: {MODEL_TYPE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aef6336-c015-4a2c-bcb2-afa60c4f9737",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "        directions=[\"minimize\", \"minimize\"],\n",
    "        storage=\"sqlite:///spp_trials.db\", \n",
    "        study_name=study_name,\n",
    "        load_if_exists=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d0bfc-075c-48c1-a5f2-26770bbb25f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_EXP:\n",
    "    study.optimize(objective_func, n_trials=NUM_TRIALS, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894cf193-3175-4bc8-ad75-acbe94cb079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, target_name in enumerate(target_names):\n",
    "    fig = plot_optimization_history(study, target=lambda t: t.values[i], target_name=target_name)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2958ec75-b07e-4c0e-aae9-803c73d787b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, target_name in enumerate(target_names):\n",
    "    fig = plot_contour(study, params=[\"lr\", \"n_epochs\"], target=lambda t: t.values[i], target_name=target_name)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5781f00d-757d-4acd-b082-ecd3e0ab7aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c64fac4-3cc7-4a60-92e5-c5492e7eb830",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pareto_front(study, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84fee56-caae-4e70-9fc5-3c2114f2de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pareto_front(study, target_names=target_names, include_dominated_trials=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe90afd-c684-47d5-9c13-4ef5212d79b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: think about how to wieght values to get best model\n",
    "# best_model = min(study.best_trials, key=lambda t: sum(t.values))\n",
    "best_model = min(study.best_trials, key=lambda t: t.values[0] + 0.5*t.values[1])\n",
    "log.info(f\"Best number: {best_model.number}\")\n",
    "log.info(f\"Best values: {best_model.values}\")\n",
    "log.info(f\"Best params: \\n{log_pretty(best_model.params)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc88e650-4fd1-4f5b-aecd-3885aa06bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_trials(\n",
    "    study_name: str,\n",
    "    storage: str=\"sqlite:///spp_trials.db\",\n",
    "    n_results: int=5,\n",
    ") -> pd.DataFrame:\n",
    "    study = optuna.load_study(\n",
    "        study_name=study_name,\n",
    "        storage=storage, \n",
    "    )\n",
    "    \n",
    "    best_trials = pd.DataFrame([{'number': s.number, 'values': s.values, 'params': s.params} for s in study.best_trials])\n",
    "    best_trials['total_value'] = [v[0] + 0.25*v[1] for v in best_trials['values']]\n",
    "    best_trials = best_trials.sort_values('total_value').head(n_results)\n",
    "    return best_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6524649-60d7-4cee-b91b-3a5e984d4063",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trials = get_best_trials(study_name)\n",
    "best_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a1905-ea70-400e-864d-0490d20c9b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the list of best params in sxc/parameters.py\n",
    "[p for p in best_trials.params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aafc3e-9330-44c4-b38f-ec2b72fa3ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e838f28f-fddd-4788-b41d-c7600da415be",
   "metadata": {},
   "source": [
    "## MLFlow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7783faae-9f1e-47fa-9bbc-ad9f3976da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "log.info(f'mlflow.get_tracking_uri(): {mlflow.get_tracking_uri()}')\n",
    "exp_name = 'spp_weis'\n",
    "\n",
    "if mlflow.get_experiment_by_name(exp_name) is None:\n",
    "    exp = mlflow.create_experiment(exp_name)\n",
    "    \n",
    "exp = mlflow.get_experiment_by_name(exp_name)\n",
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe56f9-202f-4c25-a09f-b7a0570dd765",
   "metadata": {},
   "source": [
    "## Get model signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0116e37e-c8f9-4e63-ad08-738158489da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_series = train_series[0]\n",
    "future_cov_series = futr_cov[0]\n",
    "past_cov_series = past_cov[0]\n",
    "\n",
    "data = {\n",
    "    'series': [node_series.to_json()],\n",
    "    'past_covariates': [past_cov_series.to_json()],\n",
    "    'future_covariates': [future_cov_series.to_json()],\n",
    "    'n': parameters.FORECAST_HORIZON,\n",
    "    'num_samples': 200\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "ouput_example = 'the endpoint return json as a string'\n",
    "\n",
    "from mlflow.models import infer_signature\n",
    "darts_signature = infer_signature(df, ouput_example)\n",
    "darts_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e41926-a978-454c-85a5-1c0448811d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = best_model.params\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c3bcf4-7a66-4334-b655-00184c9317bf",
   "metadata": {},
   "source": [
    "## Refit and log model with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e23af-7398-4bb6-8f73-1daad52ea1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(experiment_id=exp.experiment_id) as run:\n",
    "    \n",
    "    # fit model with best params from study\n",
    "    if MODEL_TYPE == 'ts_mixer':\n",
    "        \n",
    "        model = build_fit_tsmixerx(\n",
    "            series=train_series,\n",
    "            val_series=test_series,\n",
    "            future_covariates=futr_cov,\n",
    "            past_covariates=past_cov,\n",
    "            **best_params\n",
    "        )\n",
    "\n",
    "    elif MODEL_TYPE == 'tide':\n",
    "        \n",
    "        model = build_fit_tide(\n",
    "            series=train_series,\n",
    "            val_series=test_series,\n",
    "            future_covariates=futr_cov,\n",
    "            past_covariates=past_cov,\n",
    "            **best_model.params\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        model = build_fit_tft(\n",
    "            series=train_series,\n",
    "            val_series=test_series,\n",
    "            future_covariates=futr_cov,\n",
    "            past_covariates=past_cov,\n",
    "            **best_model.params\n",
    "        )\n",
    "    \n",
    "    log.info(f'run.info: \\n{run.info}')\n",
    "    artifact_path = \"model_artifacts\"\n",
    "    metrics = {}\n",
    "    model_params = model.model_params\n",
    "    \n",
    "    # back test on validation data\n",
    "    acc = model.backtest(\n",
    "        series=test_series,\n",
    "        # series=all_series,\n",
    "        past_covariates=past_cov,\n",
    "        future_covariates=futr_cov,\n",
    "        retrain=False,\n",
    "        forecast_horizon=model_params['output_chunk_length'],\n",
    "        stride=25,\n",
    "        metric=[mae, rmse, get_ci_err],\n",
    "        verbose=False,\n",
    "        num_samples=200,\n",
    "    )\n",
    "\n",
    "    # log.info(f'BACKTEST: acc: {acc}')\n",
    "    mean_acc = np.mean(acc, axis=0)\n",
    "    log.info(f'BACKTEST: mae - {mean_acc[0]} | rmse - {mean_acc[1]} | ci_err - {mean_acc[2]}')\n",
    "    acc_df = pd.DataFrame(\n",
    "        mean_acc.reshape(1,-1),\n",
    "        columns=['mae', 'rmse', 'ci_error']\n",
    "    )\n",
    "\n",
    "    # add metrics\n",
    "    metrics['test_mae'] = acc_df.mae[0]\n",
    "    metrics['test_rmse'] = acc_df.rmse[0]\n",
    "    metrics['test_ci_error'] = acc_df.ci_error[0]\n",
    "\n",
    "    # final training\n",
    "    final_train_series = test_series\n",
    "    log.info('final training')\n",
    "    model.fit(\n",
    "            series=test_series,\n",
    "            past_covariates=past_cov,\n",
    "            future_covariates=futr_cov,\n",
    "            verbose=True,\n",
    "            )\n",
    "    \n",
    "    # final model back test on validation data\n",
    "    acc = model.backtest(\n",
    "            series=test_series,\n",
    "            past_covariates=past_cov,\n",
    "            future_covariates=futr_cov,\n",
    "            retrain=False,\n",
    "            forecast_horizon=model_params['output_chunk_length'],\n",
    "            stride=25,\n",
    "            metric=[mae, rmse, get_ci_err],\n",
    "            verbose=False,\n",
    "            num_samples=200,\n",
    "        )\n",
    "\n",
    "    mean_acc = np.mean(acc, axis=0)\n",
    "    log.info(f'FINAL ACC: mae - {mean_acc[0]} | rmse - {mean_acc[1]} | ci_err - {mean_acc[2]}')\n",
    "    acc_df = pd.DataFrame(\n",
    "        mean_acc.reshape(1,-1),\n",
    "        columns=['mae', 'rmse', 'ci_error']\n",
    "    )\n",
    "\n",
    "    # add and log metrics\n",
    "    metrics['final_mae'] = acc_df.mae[0]\n",
    "    metrics['final_rmse'] = acc_df.rmse[0]\n",
    "    metrics['final_ci_error'] = acc_df.ci_error[0]\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # set up path to save model\n",
    "    model_path = '/'.join([artifact_path, model.MODEL_TYPE])\n",
    "\n",
    "    shutil.rmtree(artifact_path, ignore_errors=True)\n",
    "    os.makedirs(artifact_path)\n",
    "\n",
    "    # log params\n",
    "    mlflow.log_params(model_params)\n",
    "\n",
    "    # save model files (model, model.ckpt) \n",
    "    # and load them to artifacts when logging the model\n",
    "    model.save(model_path)\n",
    "\n",
    "    # save MODEL_TYPE to artifacts\n",
    "    # this will be used to load the model from the artifacts\n",
    "    model_type_path = '/'.join([artifact_path, 'MODEL_TYPE.pkl'])\n",
    "    with open(model_type_path, 'wb') as handle:\n",
    "        pickle.dump(model.MODEL_TYPE, handle)\n",
    "\n",
    "    model_timestamp = '/'.join([artifact_path, 'TRAIN_TIMESTAMP.pkl'])\n",
    "    with open(model_timestamp, 'wb') as handle:\n",
    "        pickle.dump(model.TRAIN_TIMESTAMP, handle)\n",
    "    \n",
    "    # map model artififacts in dictionary\n",
    "    # artifacts = {\n",
    "    #     'model': model_path,\n",
    "    #     'model.ckpt': model_path+'.ckpt',\n",
    "    #     'MODEL_TYPE': model_type_path,\n",
    "    #     'TRAIN_TIMESTAMP': model_timestamp,\n",
    "    # }\n",
    "    artifacts = {f:f'{artifact_path}/{f}' for f in os.listdir('model_artifacts')}\n",
    "    artifacts['model'] = model_path\n",
    "    \n",
    "    # log model\n",
    "    # https://www.mlflow.org/docs/latest/tutorials-and-examples/tutorial.html#pip-requirements-example\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path='GlobalForecasting',\n",
    "        code_path=['src/darts_wrapper.py'],\n",
    "        signature=darts_signature,\n",
    "        artifacts=artifacts,\n",
    "        python_model=DartsGlobalModel(), \n",
    "        pip_requirements=[\"-r notebooks/model_training/requirements.txt\"],\n",
    "        registered_model_name=MODEL_NAME,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b984cc4-bef4-469d-b102-16aa3473d468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12398672-837a-414c-a72a-09c533611cc2",
   "metadata": {},
   "source": [
    "## Get latest run and test predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3c7efb-9cc0-40ed-a894-9aa73208ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(\n",
    "    experiment_ids = exp.experiment_id,\n",
    "    # order_by=['metrics.test_mae']\n",
    "    order_by=['end_time']\n",
    "    )\n",
    "\n",
    "runs.sort_values('end_time', ascending=False, inplace=True)\n",
    "runs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45812534-9c6e-4bd6-9a74-7c525d4a8006",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run_id = runs.run_id.iloc[0]\n",
    "best_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79254137-df64-4796-a7c7-06c9ce8b8308",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs['artifact_uri'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a950dc70-8dde-4b6d-b2b5-293e5eb47692",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = runs['artifact_uri'].iloc[0] + '/GlobalForecasting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c1f67-56f6-4d68-a151-5d058213eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d84debb-a12d-4882-b55f-61a9a18e7e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "354b246f-2f5f-4847-bbc3-a254b664dea6",
   "metadata": {},
   "source": [
    "## Plot test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fad7c8-0a4b-47b4-8117-fc16c73c3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ind = 3\n",
    "plot_series = all_series[plot_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe27758-ff9c-408e-8d5e-0f5456a026b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series.static_covariates.unique_id.LMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef569b3-64d4-4339-a0c1-c851c3286325",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc56455-325e-4002-8dab-d77bff29953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_end_times = pd.date_range(\n",
    "    end=test_series[plot_ind].end_time(),\n",
    "    periods=10,\n",
    "    freq='d',\n",
    ")\n",
    "\n",
    "plot_end_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd21863-5d50-43df-9767-0e3804d9f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "for plot_end_time in plot_end_times:\n",
    "    # plot_end_time = min(\n",
    "    #     plot_series.end_time() - pd.Timedelta(f'{parameters.INPUT_CHUNK_LENGTH+1}h'), \n",
    "    #     pd.Timestamp(plot_end_time)\n",
    "    # )\n",
    "    log.info(f'plot_end_time: {plot_end_time}')\n",
    "    \n",
    "    plot_node_name = plot_series.static_covariates.unique_id.LMP\n",
    "    \n",
    "    # if test_end_time < test_series.end_time():\n",
    "    node_series = plot_series.drop_after(plot_end_time)\n",
    "        \n",
    "    log.info(f'plot_end_time: {plot_end_time}')\n",
    "    log.info(f'node_series.end_time(): {node_series.end_time()}')\n",
    "    future_cov_series = futr_cov[0]\n",
    "    past_cov_series = past_cov[0]\n",
    "    \n",
    "    data = {\n",
    "        'series': [node_series.to_json()],\n",
    "        'past_covariates': [past_cov_series.to_json()],\n",
    "        'future_covariates': [future_cov_series.to_json()],\n",
    "        'n': parameters.FORECAST_HORIZON,\n",
    "        'num_samples': 200\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    plot_cov_df = future_cov_series.pd_dataframe()\n",
    "    plot_cov_df = (\n",
    "        plot_cov_df\n",
    "        .reset_index()\n",
    "        .rename(columns={'timestamp_mst':'time', 're_ratio': 'Ratio'})\n",
    "    )\n",
    "    \n",
    "    # Predict on a Pandas DataFrame.\n",
    "    df['num_samples'] = 500\n",
    "    pred = loaded_model.predict(df)\n",
    "    preds = TimeSeries.from_json(pred)\n",
    "    \n",
    "    q_df = plotting.get_quantile_df(preds)\n",
    "    \n",
    "    plot_df = plotting.get_mean_df(preds).merge(\n",
    "        plotting.get_quantile_df(preds),\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "    \n",
    "    plot_df = plotting.get_plot_df(\n",
    "            TimeSeries.from_json(pred),\n",
    "            plot_cov_df,\n",
    "            lmp_df,\n",
    "            plot_node_name,\n",
    "        )\n",
    "    plot_df.rename(columns={'mean':'mean_fcast'}, inplace=True)\n",
    "    plot_df\n",
    "    \n",
    "    plotting.plotly_forecast(plot_df, plot_node_name, show_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d0845-8d97-4abc-99c9-90d81a3ea981",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea49c91a-0960-4df4-b9bf-5245b65a0c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21b0ce0-098e-403d-a350-62f995c86ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
