{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52cf595-9e8a-4d77-8f2a-f83bc5725504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from typing import List\n",
    "\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "import ibis\n",
    "import ibis.selectors as s\n",
    "from ibis import _\n",
    "ibis.options.interactive = True\n",
    "\n",
    "from darts import TimeSeries, concatenate\n",
    "from darts.dataprocessing.transformers import (\n",
    "    Scaler,\n",
    "    MissingValuesFiller,\n",
    "    Mapper,\n",
    "    InvertibleMapper,\n",
    ")\n",
    "from darts.dataprocessing import Pipeline\n",
    "from darts.metrics import mape, smape, mae, ope, rmse\n",
    "from darts.utils.statistics import check_seasonality, plot_acf\n",
    "from darts.datasets import AirPassengersDataset, IceCreamHeaterDataset\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from darts.utils.likelihood_models import QuantileRegression, GumbelLikelihood, GaussianLikelihood\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.utils.timeseries_generation import (\n",
    "    gaussian_timeseries,\n",
    "    linear_timeseries,\n",
    "    sine_timeseries,\n",
    ")\n",
    "from darts.models import (\n",
    "    TFTModel,\n",
    "    TiDEModel,\n",
    "    DLinearModel,\n",
    "    NLinearModel,\n",
    "    TSMixerModel\n",
    ")\n",
    "\n",
    "\n",
    "from torchmetrics import (\n",
    "    SymmetricMeanAbsolutePercentageError, \n",
    "    MeanAbsoluteError, \n",
    "    MeanSquaredError,\n",
    ")\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "\n",
    "# define log\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9265743c-3605-48d9-83a8-69b56743c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_contour,\n",
    "    plot_param_importances,\n",
    "    plot_pareto_front,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c455b79-12ce-4c73-9f95-3cdbd270a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "## will be loaded from root when deployed\n",
    "from darts_wrapper import DartsGlobalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fb2027-6f33-440d-ad6b-b3d3632d8103",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113b2e7-4a1b-4e41-959e-21bc661746fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom modules\n",
    "import src.data_engineering as de\n",
    "from src import plotting\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66fe529-88bc-47a1-968a-7006c10e8dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33d952be-198a-4d48-871b-4ccec3960b41",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b59c65b-8e78-4e3a-8a2e-fbf009fef686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to database\n",
    "con = ibis.duckdb.connect(\"data/spp.ddb\")\n",
    "con.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20063522-bf7a-4fec-af44-9caef36e7b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmp = con.table('lmp')\n",
    "lmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee90b120-f45a-417f-a4aa-04b7bb3a30cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmp = lmp.filter(_.Settlement_Location_Name.contains('PSCO'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a184d8c8-262f-427d-a3a8-296931d7f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmp.to_pandas()[['GMTIntervalEnd_HE', 'Settlement_Location_Name']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4437a273-e2c7-4100-8470-9c63e3879809",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    'Interval_HE', 'GMTIntervalEnd_HE', 'timestamp_mst_HE',\n",
    "    'Settlement_Location_Name', 'PNODE_Name', \n",
    "    'MLC', 'MCC', 'MEC'\n",
    "]\n",
    "\n",
    "lmp = (\n",
    "    lmp\n",
    "    .mutate(unique_id = _.Settlement_Location_Name )\n",
    "    .mutate(timestamp_mst = _.timestamp_mst_HE)\n",
    "    # .mutate(y = _.LMP) \n",
    "    .drop(drop_cols) \n",
    "    .order_by(['unique_id', 'timestamp_mst'])\n",
    ")\n",
    "\n",
    "lmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66587731-3255-4ec6-8e3e-ed59ce3466d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrf = con.table('mtrf')\n",
    "mtrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed81f14b-9c33-47ab-a038-06885e68eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Interval', 'GMTIntervalEnd']\n",
    "\n",
    "mtrf = (\n",
    "    mtrf\n",
    "    # .mutate(ds = _.timestamp_mst)\n",
    "    .drop(drop_cols) \n",
    "    .order_by(['timestamp_mst'])\n",
    ")\n",
    "\n",
    "mtrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fe8245-ba6a-4f6a-b144-c7564db0577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtlf = con.table('mtlf')\n",
    "mtlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fdd7b0-ea80-4ba3-9bd6-2f67fff1d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Interval', 'GMTIntervalEnd',]\n",
    "\n",
    "mtlf = (\n",
    "    mtlf\n",
    "    # .mutate(ds = _.timestamp_mst)\n",
    "    .drop(drop_cols) \n",
    "    .order_by(['timestamp_mst'])\n",
    ")\n",
    "\n",
    "mtlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d31451-312b-478f-b0f4-30aad7ed2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = (\n",
    "    mtlf\n",
    "    .left_join(mtrf, 'timestamp_mst')\n",
    "    .select(~s.contains(\"_right\")) # remove 'dt_right'\n",
    "    .left_join(lmp, 'timestamp_mst')\n",
    "    .select(~s.contains(\"_right\")) # remove 'dt_right'\n",
    "    .order_by(['unique_id', 'timestamp_mst'])\n",
    ")\n",
    "all_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f574e3f9-274c-4f70-bb27-c2480ef0b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530378dc-2973-47fe-8183-33dbc8420d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = (\n",
    "    all_df\n",
    "    .drop_null(['unique_id'])\n",
    "    # .mutate(hour = _.ds.hour())\n",
    "    # .mutate(weekday = _.ds.day_of_week.index())\n",
    "    # .mutate(month = _.ds.month())\n",
    "    .mutate(re_ratio = (_.Wind_Forecast_MW + _.Solar_Forecast_MW) / _.MTLF)\n",
    ")\n",
    "\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f860f-17f3-4ded-9c24-8d464d89220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_pd = all_df.to_pandas()\n",
    "all_df_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568ac6a-216f-4fc4-8dcb-8409c07e436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb63f13-4ca6-4432-b0fa-6237033bad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_df_pd.timestamp_mst.unique()) * len(all_df_pd.unique_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a606f55-755f-479c-84df-c1bf15b57134",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_groups = all_df_pd.unique_id.unique()\n",
    "log.info(f'number of nodes: {len(node_groups)}')\n",
    "node_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bbe26a-45fa-4fea-9ae5-cf843c0c3685",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_groups = [node for node in node_groups if 'PSCO_' in node]\n",
    "log.info(f'number of nodes: {len(node_groups)}')\n",
    "node_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd446306-18e9-4fc5-8fb9-cda36e6ef9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_pd = all_df_pd[all_df_pd.unique_id.isin(node_groups)].reset_index(drop=True)\n",
    "all_df_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d53e76-7e84-495e-921b-24e00a0d7f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df_pd.drop(['Averaged_Actual'], axis=1, errors='ignore', inplace=True)\n",
    "all_df_pd.set_index('timestamp_mst', inplace=True)\n",
    "all_df_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301eda94-6012-4a9d-a0d4-7b78368e642f",
   "metadata": {},
   "source": [
    "## Prep model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a515e-f520-4efa-94cf-856bb5cc19dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORECAST_HORIZON = 24*5\n",
    "INPUT_CHUNK_LENGTH = 2*FORECAST_HORIZON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f74359-c108-4dc6-82aa-5ea012909092",
   "metadata": {},
   "outputs": [],
   "source": [
    "futr_cols = ['MTLF', 'Wind_Forecast_MW', 'Solar_Forecast_MW', 're_ratio']\n",
    "past_cols = ['Averaged_Actual']\n",
    "y = ['LMP']\n",
    "ids = ['unique_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f8fea9-f2b9-4e1c-9847-4782608b0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_pd = all_df_pd[ids + y + past_cols + futr_cols]\n",
    "all_df_pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7894011-a2cf-47db-88b5-849cf2507955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa3670-c875-4fac-a50e-d609990b0a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = all_df_pd.index.min() + pd.Timedelta(f'{2*INPUT_CHUNK_LENGTH}h')\n",
    "test_end = all_df_pd.index.max() - pd.Timedelta(f'{2*FORECAST_HORIZON}h')\n",
    "tr_tst_split =  test_end - pd.Timedelta(f'{2*INPUT_CHUNK_LENGTH}h')\n",
    "log.info(f'train_start: {train_start}')\n",
    "log.info(f'tr_tst_split: {tr_tst_split}')\n",
    "log.info(f'test_end: {test_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02982760-ef6f-4df5-8782-7c5d42bd2bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = (all_df_pd.index < tr_tst_split) & (all_df_pd.index > train_start)\n",
    "test_idx = (all_df_pd.index > tr_tst_split) & (all_df_pd.index < test_end)\n",
    "train_all = all_df_pd[train_idx]\n",
    "train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c94c68-50a3-4790-93d4-a0b01c0cdd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all = all_df_pd[test_idx]\n",
    "test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd0b16-bc97-4eab-8c59-13dba396ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(series):\n",
    "    for i in range(len(series)):\n",
    "        transformer = MissingValuesFiller()\n",
    "        series[i] = transformer.transform(series[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8740e0-6904-4ff5-ac34-d0ecaa0135ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_series = TimeSeries.from_group_dataframe(\n",
    "    all_df_pd,\n",
    "    group_cols=ids,\n",
    "    value_cols=y,\n",
    "    fill_missing_dates=True,\n",
    "    freq='h',\n",
    ")\n",
    "\n",
    "fill_missing(all_series) \n",
    "all_series[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc1d39-cc8c-48f3-9e58-e95cb384b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series = TimeSeries.from_group_dataframe(\n",
    "    train_all,\n",
    "    group_cols=ids,\n",
    "    value_cols=y,\n",
    "    fill_missing_dates=True,\n",
    "    freq='h',\n",
    ")\n",
    "fill_missing(train_series)\n",
    "train_series[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fda754-0fed-485b-a07b-c28da5c2b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_series = TimeSeries.from_group_dataframe(\n",
    "    test_all,\n",
    "    group_cols=ids,\n",
    "    value_cols=y,\n",
    "    fill_missing_dates=True,\n",
    "    freq='h',\n",
    ")\n",
    "fill_missing(test_series)\n",
    "test_series[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9cd46d-6617-4c04-9c51-3075aabc4af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "futr_cov = TimeSeries.from_group_dataframe(\n",
    "    all_df_pd,\n",
    "    group_cols=ids,\n",
    "    value_cols=futr_cols,\n",
    "    fill_missing_dates=True,\n",
    "    freq='h',\n",
    ")\n",
    "fill_missing(futr_cov)\n",
    "futr_cov[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4ccf3-d3d3-4d78-8b0b-7ca7a6b4251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_cov = TimeSeries.from_group_dataframe(\n",
    "    all_df_pd,\n",
    "    group_cols=ids,\n",
    "    value_cols=past_cols,\n",
    "    fill_missing_dates=True,\n",
    "    freq='h',\n",
    ")\n",
    "fill_missing(past_cov)\n",
    "past_cov[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26cdef1-5984-4dd1-8904-c24d365d6661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_futr_cov = TimeSeries.from_group_dataframe(\n",
    "#     test_all,\n",
    "#     group_cols=ids,\n",
    "#     value_cols=cov_cols,\n",
    "#     fill_missing_dates=True,\n",
    "#     freq='h',\n",
    "# )\n",
    "\n",
    "# test_futr_cov[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b81a27-f5a8-4a6f-b62d-375a2648022b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "259d7d9a-382a-4186-b63f-881e5070e7f7",
   "metadata": {},
   "source": [
    "## MLFlow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1501f6-c76c-430a-a894-8f474c5fe760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eba6ea8-e9d3-4d78-8651-d1dfcc13fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "mlflow.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09557a80-f94b-4032-a593-2e7e5d6c90b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'spp_weis'\n",
    "\n",
    "if mlflow.get_experiment_by_name(exp_name) is None:\n",
    "    exp = mlflow.create_experiment(exp_name)\n",
    "    \n",
    "exp = mlflow.get_experiment_by_name(exp_name)\n",
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f81087-a7ef-4704-ba72-2cf096e0e406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2e48722-3892-4f7e-94c7-c4c6c03b846d",
   "metadata": {},
   "source": [
    "## Get model signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee5eea0-8f09-4908-acb7-4e3aa2eda4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_series = train_series[0]\n",
    "future_cov_series = futr_cov[0]\n",
    "past_cov_series = past_cov[0]\n",
    "\n",
    "data = {\n",
    "    'series': [node_series.to_json()],\n",
    "    'past_covariates': [past_cov_series.to_json()],\n",
    "    'future_covariates': [future_cov_series.to_json()],\n",
    "    'n': FORECAST_HORIZON,\n",
    "    'num_samples': 200\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "ouput_example = 'the endpoint return json as a string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165147f8-6c30-4c16-a8d8-bc74bedbd0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models import infer_signature\n",
    "darts_signature = infer_signature(df, ouput_example)\n",
    "darts_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d539f-e016-4c0f-a6bc-267299739169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d054499-799e-4414-9d1c-46e29f4842b6",
   "metadata": {},
   "source": [
    "## Set up hyperparameter tuning study\n",
    "\n",
    "https://unit8co.github.io/darts/examples/17-hyperparameter-optimization.html?highlight=optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494fc5d4-f245-4b93-84af-97e86d62aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pprint\n",
    "# set up pretty printer\n",
    "pp = pprint.PrettyPrinter(indent=2, sort_dicts=False)\n",
    "\n",
    "def log_pretty(obj):\n",
    "    pretty_out = f\"{pp.pformat(obj)}\"\n",
    "\n",
    "    return f'{pretty_out}\\n'\n",
    "    \n",
    "def build_fit_tsmixerx(\n",
    "    series: List[TimeSeries]=train_series,\n",
    "    val_series: List[TimeSeries]=test_series,\n",
    "    future_covariates: List[TimeSeries]=futr_cov,\n",
    "    past_covariates: List[TimeSeries]=past_cov,\n",
    "    hidden_size: int=32,\n",
    "    ff_size: int=128,\n",
    "    num_blocks: int=2,\n",
    "    forecast_horizon: int=FORECAST_HORIZON,\n",
    "    input_chunk_length: int=INPUT_CHUNK_LENGTH,\n",
    "    lr: float=1e-4,\n",
    "    batch_size: int=64,\n",
    "    n_epochs: int=4,\n",
    "    force_reset: bool=True, # reset model if already exists\n",
    "    callbacks=None,\n",
    "):\n",
    "    work_dir = os.getcwd() + '/model_checkpoints'\n",
    "    MODEL_TYPE = \"ts_mixer_model\"\n",
    "    quantiles = [0.01]+np.arange(0.05, 1, 0.05).tolist()+[0.99]\n",
    "    \n",
    "    #TODO: pick a metric...\n",
    "    torch_metrics = MeanAbsoluteError()\n",
    "    # torch_metrics = MeanSquaredError(squared=False)\n",
    "    # torch_metrics = SymmetricMeanAbsolutePercentageError()\n",
    "    \n",
    "    encoders = {\n",
    "        \"datetime_attribute\": {\n",
    "            \"future\": [\"hour\", \"dayofweek\", \"month\"], # \n",
    "            \"past\": [\"hour\", \"dayofweek\", \"month\"], # \n",
    "        },\n",
    "        \"position\": {\n",
    "            \"past\": [\"relative\"], \n",
    "            \"future\": [\"relative\"]\n",
    "        },\n",
    "        \"transformer\": Scaler(global_fit=True)\n",
    "    }\n",
    "\n",
    "    # common parameters across models\n",
    "    model_params = {\n",
    "        'hidden_size': hidden_size,\n",
    "        'ff_size': ff_size,\n",
    "        'num_blocks': num_blocks,\n",
    "        'input_chunk_length': input_chunk_length,\n",
    "        'output_chunk_length': forecast_horizon,\n",
    "        'batch_size': batch_size,\n",
    "        'n_epochs': n_epochs,\n",
    "        'add_encoders': encoders,\n",
    "        'likelihood': QuantileRegression(quantiles=quantiles),  # QuantileRegression is set per default\n",
    "        'optimizer_kwargs': {\"lr\": lr},\n",
    "        'random_state': 42,\n",
    "        'torch_metrics': torch_metrics,\n",
    "        'use_static_covariates': False,\n",
    "        'save_checkpoints': True,\n",
    "        'work_dir': work_dir,\n",
    "        'model_name': MODEL_TYPE, # used for checkpoint saves\n",
    "        'force_reset': force_reset, # reset model if already exists\n",
    "    }\n",
    "    log.info(f'model_params: \\n{log_pretty(model_params)}')\n",
    "\n",
    "    # throughout training we'll monitor the validation loss for early stopping\n",
    "    early_stopper = EarlyStopping(\"val_loss\", min_delta=0.01, patience=3, verbose=True)\n",
    "    if callbacks is None:\n",
    "        callbacks = [early_stopper]\n",
    "    else:\n",
    "        callbacks = [early_stopper] + callbacks\n",
    "\n",
    "    # detect if a GPU is available\n",
    "    if torch.cuda.is_available():\n",
    "        pl_trainer_kwargs = {\n",
    "            \"accelerator\": \"gpu\",\n",
    "            \"gpus\": -1,\n",
    "            \"auto_select_gpus\": True,\n",
    "            \"callbacks\": callbacks,\n",
    "        }\n",
    "    else:\n",
    "        pl_trainer_kwargs = {\"callbacks\": callbacks}\n",
    "        \n",
    "\n",
    "    model = TSMixerModel(**model_params)\n",
    "\n",
    "    # train the model\n",
    "    fit_params = {\n",
    "        'series': train_series,\n",
    "        'val_series': test_series,\n",
    "        'future_covariates': futr_cov,\n",
    "        'past_covariates': past_cov,\n",
    "        'val_future_covariates': futr_cov,\n",
    "        'val_past_covariates': past_cov,\n",
    "    }\n",
    "    model.fit(**fit_params)\n",
    "\n",
    "    # reload best model over course of training\n",
    "    model = TSMixerModel.load_from_checkpoint(\n",
    "        work_dir=work_dir,\n",
    "        model_name=MODEL_TYPE\n",
    "    )\n",
    "    \n",
    "    model.MODEL_TYPE = MODEL_TYPE\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a2ba76-2330-44ef-8bd2-0884797e70b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fit_tft(\n",
    "    series: List[TimeSeries]=train_series,\n",
    "    val_series: List[TimeSeries]=test_series,\n",
    "    future_covariates: List[TimeSeries]=futr_cov,\n",
    "    past_covariates: List[TimeSeries]=past_cov,\n",
    "    hidden_size: int=16, # Hidden state size of the TFT. It is the main hyper-parameter and common across the internal TFT architecture.\n",
    "    lstm_layers: int = 1, # Number of layers for the Long Short Term Memory (LSTM) Encoder and Decoder (1 is a good default).\n",
    "    num_attention_heads: int=2, # Number of attention heads (4 is a good default)\n",
    "    dropout: float=0.1,\n",
    "    forecast_horizon: int=FORECAST_HORIZON,\n",
    "    input_chunk_length: int=INPUT_CHUNK_LENGTH,\n",
    "    lr: float=1e-4,\n",
    "    batch_size: int=64,\n",
    "    n_epochs: int=4,\n",
    "    force_reset: bool=True, # reset model if already exists\n",
    "    callbacks=None,\n",
    "):\n",
    "    work_dir = os.getcwd() + '/model_checkpoints'\n",
    "    MODEL_TYPE = \"tft_model\"\n",
    "    quantiles = [0.01]+np.arange(0.05, 1, 0.05).tolist()+[0.99]\n",
    "    \n",
    "    #TODO: pick a metric...\n",
    "    torch_metrics = MeanAbsoluteError()\n",
    "    # torch_metrics = MeanSquaredError(squared=False)\n",
    "    # torch_metrics = SymmetricMeanAbsolutePercentageError()\n",
    "    \n",
    "    encoders = {\n",
    "        \"datetime_attribute\": {\n",
    "            \"future\": [\"hour\", \"dayofweek\", \"month\"], # \n",
    "            \"past\": [\"hour\", \"dayofweek\", \"month\"], # \n",
    "        },\n",
    "        \"position\": {\n",
    "            \"past\": [\"relative\"], \n",
    "            \"future\": [\"relative\"]\n",
    "        },\n",
    "        \"transformer\": Scaler(global_fit=True)\n",
    "    }\n",
    "\n",
    "    # common parameters across models\n",
    "    model_params = {\n",
    "        'hidden_size': hidden_size,\n",
    "        'lstm_layers': lstm_layers,\n",
    "        'num_attention_heads': num_attention_heads,\n",
    "        'dropout': dropout,\n",
    "        'input_chunk_length': input_chunk_length,\n",
    "        'output_chunk_length': forecast_horizon,\n",
    "        'batch_size': batch_size,\n",
    "        'n_epochs': n_epochs,\n",
    "        'add_encoders': encoders,\n",
    "        'likelihood': QuantileRegression(quantiles=quantiles),  # QuantileRegression is set per default\n",
    "        'optimizer_kwargs': {\"lr\": lr},\n",
    "        'random_state': 42,\n",
    "        'torch_metrics': torch_metrics,\n",
    "        'use_static_covariates': False,\n",
    "        'save_checkpoints': True,\n",
    "        'work_dir': work_dir,\n",
    "        'model_name': MODEL_TYPE, # used for checkpoint saves\n",
    "        'force_reset': force_reset, # reset model if already exists\n",
    "    }\n",
    "    log.info(f'model_params: \\n{log_pretty(model_params)}')\n",
    "\n",
    "    # throughout training we'll monitor the validation loss for early stopping\n",
    "    early_stopper = EarlyStopping(\"val_loss\", min_delta=0.01, patience=3, verbose=True)\n",
    "    if callbacks is None:\n",
    "        callbacks = [early_stopper]\n",
    "    else:\n",
    "        callbacks = [early_stopper] + callbacks\n",
    "\n",
    "    # detect if a GPU is available\n",
    "    if torch.cuda.is_available():\n",
    "        pl_trainer_kwargs = {\n",
    "            \"accelerator\": \"gpu\",\n",
    "            \"gpus\": -1,\n",
    "            \"auto_select_gpus\": True,\n",
    "            \"callbacks\": callbacks,\n",
    "        }\n",
    "    else:\n",
    "        pl_trainer_kwargs = {\"callbacks\": callbacks}\n",
    "        \n",
    "\n",
    "    model = TFTModel(**model_params)\n",
    "\n",
    "    # train the model\n",
    "    fit_params = {\n",
    "        'series': train_series,\n",
    "        'val_series': test_series,\n",
    "        'future_covariates': futr_cov,\n",
    "        'past_covariates': past_cov,\n",
    "        'val_future_covariates': futr_cov,\n",
    "        'val_past_covariates': past_cov,\n",
    "    }\n",
    "    model.fit(**fit_params)\n",
    "\n",
    "    # reload best model over course of training\n",
    "    model = TFTModel.load_from_checkpoint(\n",
    "        work_dir=work_dir,\n",
    "        model_name=MODEL_TYPE\n",
    "    )\n",
    "    \n",
    "    model.MODEL_TYPE = MODEL_TYPE\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f1be51-80b0-4977-9262-253104ec9e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test build fit function\n",
    "# model = build_fit_tsmixerx(n_epochs=1)\n",
    "model = build_fit_tft(n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d8bc8e-efe8-4942-96ff-43565c6d87a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.MODEL_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce679a-90bb-44e4-ab90-b838344bd1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bded5395-8219-4b2c-b97c-21b38f476967",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(\n",
    "        series=train_series, \n",
    "        n=FORECAST_HORIZON,\n",
    "        past_covariates=past_cov,\n",
    "        future_covariates=futr_cov,\n",
    "        num_samples=200,\n",
    ")\n",
    "\n",
    "smapes = smape(test_series, preds, n_jobs=-1, verbose=True)\n",
    "smape_val = np.mean(smapes)\n",
    "smape_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03255e07-9d8e-43ad-aa58-e3803d95ec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "### retest this....\n",
    "# acc = model.backtest(\n",
    "#     series=test_series,\n",
    "#     past_covariates=past_cov,\n",
    "#     future_covariates=futr_cov,\n",
    "#     retrain=False,\n",
    "#     forecast_horizon=FORECAST_HORIZON,\n",
    "#     stride=25,\n",
    "#     metric=[get_ci_error],\n",
    "#     verbose=False,\n",
    "#     num_samples=200,\n",
    "    # retrain=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2c5c5a-ed02-459e-9c66-8674ebe95408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.metrics.metrics import multi_ts_support, multivariate_support\n",
    "\n",
    "# @multivariate_support\n",
    "def get_ci_error(actual_series, pred_series, n_jobs=1, verbose=False):\n",
    "    series_qs = pred_series.quantiles_df((0.2, 0.8))\n",
    "    val_y = actual_series.pd_dataframe()\n",
    "    \n",
    "    eval_df = series_qs.merge(\n",
    "        val_y,\n",
    "        how='inner',\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # 0 if u > l\n",
    "    upper_error = (\n",
    "        (eval_df['LMP_0.8'] - eval_df['LMP']) # upper - pred\n",
    "        .apply(lambda x: min(x, 0)) # min(u-p, 0)\n",
    "        .abs().mean() # sum(abs(min(u-p, 0)))\n",
    "    )\n",
    "\n",
    "    # 0 if p > l\n",
    "    lower_error = (\n",
    "        (eval_df['LMP_0.2'] - eval_df['LMP']) # lower - pred\n",
    "        .apply(lambda x: max(x, 0)) # max(l-p, 0)\n",
    "        .abs().mean() # sum(abs(max(l-p, 0)))\n",
    "    )\n",
    "\n",
    "    return upper_error + lower_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984d0728-6544-4e4d-bc52-66d4f996188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci_cover_err(actual_series, pred_series, n_jobs=1, verbose=False):\n",
    "    series_qs = pred_series.quantiles_df((0.1, 0.9))\n",
    "    val_y = actual_series.pd_dataframe()\n",
    "    \n",
    "    eval_df = series_qs.merge(\n",
    "        val_y,\n",
    "        how='inner',\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # 0 if u > l\n",
    "    cover = (\n",
    "        (eval_df['LMP_0.9'] < eval_df['LMP']) |\n",
    "        (eval_df['LMP_0.1'] > eval_df['LMP'])\n",
    "    ).mean() # should be about 80%\n",
    "\n",
    "    return 100 * np.abs(cover - 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d464a4-0393-43ed-ac42-e3331abe4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_tsmixer(trial):\n",
    "    callback = [PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")]\n",
    "\n",
    "    # Hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 16, 64)\n",
    "    ff_size = trial.suggest_int(\"ff_size\", 64, 256)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 5e-4, step=1e-4)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 3, 10)\n",
    "    \n",
    "\n",
    "    # build and train the TCN model with these hyper-parameters:\n",
    "    model = build_fit_tsmixerx(\n",
    "        hidden_size=hidden_size,\n",
    "        ff_size=ff_size,\n",
    "        num_blocks=num_blocks,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        callbacks=callback,\n",
    "    )\n",
    "\n",
    "    # Evaluate how good it is on the validation set\n",
    "    preds = model.predict(\n",
    "        series=train_series, \n",
    "        n=len(test_series[0]),\n",
    "        past_covariates=past_cov,\n",
    "        future_covariates=futr_cov,\n",
    "        num_samples=200,\n",
    "    )\n",
    "\n",
    "    smapes = smape(test_series, preds, n_jobs=-1, verbose=True)\n",
    "    smape_val = np.mean(smapes)\n",
    "    \n",
    "    if smape_val!= np.nan:\n",
    "        pass\n",
    "    else:\n",
    "        smape_val = float(\"inf\")\n",
    "\n",
    "    ci_error = np.mean([get_ci_cover_err(test_series[i], preds[i]) for i in range(len(preds))])\n",
    "    \n",
    "\n",
    "    return smape_val , ci_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2707ed-e20c-4514-9646-2fc19bdd23de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_tft(trial):\n",
    "    callback = [PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")]\n",
    "\n",
    "    # Hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 8, 32)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 2)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 5e-4, step=1e-4)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 3, 6)\n",
    "    \n",
    "\n",
    "    # build and train the TCN model with these hyper-parameters:\n",
    "    model = build_fit_tft(\n",
    "        hidden_size=hidden_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        callbacks=callback,\n",
    "    )\n",
    "\n",
    "    # Evaluate how good it is on the validation set\n",
    "    preds = model.predict(\n",
    "        series=train_series, \n",
    "        n=len(test_series[0]),\n",
    "        past_covariates=past_cov,\n",
    "        future_covariates=futr_cov,\n",
    "        num_samples=200,\n",
    "    )\n",
    "\n",
    "    smapes = smape(test_series, preds, n_jobs=-1, verbose=True)\n",
    "    smape_val = np.mean(smapes)\n",
    "    \n",
    "    if smape_val!= np.nan:\n",
    "        pass\n",
    "    else:\n",
    "        smape_val = float(\"inf\")\n",
    "\n",
    "    ci_error = np.mean([get_ci_cover_err(test_series[i], preds[i]) for i in range(len(preds))])\n",
    "    \n",
    "\n",
    "    return smape_val , ci_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15c569-e172-44d3-970a-ed7ed6f9d788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_callback(study, trial):\n",
    "    best_smape = min(study.best_trials, key=lambda t: t.values[0])\n",
    "    best_ci = min(study.best_trials, key=lambda t: t.values[1])\n",
    "    log.info(f\"Current values: {trial.values}, Current params: \\n{log_pretty(trial.params)}\")\n",
    "    log.info(f\"Best SMAPE: {best_smape.values}, Best params: \\n{log_pretty(best_smape.params)}\")\n",
    "    log.info(f\"Best CI: {best_ci.values}, Best params: \\n{log_pretty(best_ci.params)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea6ac4f-ae9c-4866-ac81-ec251cba6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    directions=[\"minimize\", \"minimize\"],\n",
    "    storage=\"sqlite:///spp_trials.db\", \n",
    "    study_name=\"spp_weis_tft\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "study.optimize(objective_tft, n_trials=10, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246b4858-2543-4b05-97b5-8b2a34e10786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = optuna.create_study(\n",
    "#     directions=[\"minimize\", \"minimize\"],\n",
    "#     storage=\"sqlite:///spp_trials.db\", \n",
    "#     study_name=\"spp_weis\",\n",
    "#     load_if_exists=True,\n",
    "# )\n",
    "\n",
    "# study.optimize(objective_tsmixer, n_trials=40, callbacks=[print_callback])\n",
    "# # or limit time\n",
    "# # study.optimize(objective, timeout=7200, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894cf193-3175-4bc8-ad75-acbe94cb079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study, target=lambda t: t.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a341b5-ba38-4ed0-a76b-00b4ccedd361",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study, target=lambda t: t.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2958ec75-b07e-4c0e-aae9-803c73d787b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contour(study, params=[\"lr\", \"ff_size\"], target=lambda t: t.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5781f00d-757d-4acd-b082-ecd3e0ab7aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c64fac4-3cc7-4a60-92e5-c5492e7eb830",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pareto_front(study, target_names=[\"SMAPE\", \"CI Error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe90afd-c684-47d5-9c13-4ef5212d79b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: think about how to wieght values to get best model\n",
    "best_model = min(study.best_trials, key=lambda t: sum(t.values))\n",
    "log.info(f\"Best number: {best_model.number}\")\n",
    "log.info(f\"Best values: {best_model.values}\")\n",
    "log.info(f\"Best params: \\n{log_pretty(best_model.params)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7783faae-9f1e-47fa-9bbc-ad9f3976da89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1c3bcf4-7a66-4334-b655-00184c9317bf",
   "metadata": {},
   "source": [
    "## Refit and log model with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e23af-7398-4bb6-8f73-1daad52ea1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(experiment_id=exp.experiment_id) as run:\n",
    "    # fit model with best params from study\n",
    "    model = build_fit_tsmixerx(**best_model.params)\n",
    "    \n",
    "    log.info(f'run.info: \\n{run.info}')\n",
    "    artifact_path = \"model_artifacts\"\n",
    "    metrics = {}\n",
    "    params = model.model_params\n",
    "    \n",
    "    # back test on validation data\n",
    "    acc = model.backtest(\n",
    "        series=test_series,\n",
    "        # series=all_series,\n",
    "        past_covariates=past_cov,\n",
    "        future_covariates=futr_cov,\n",
    "        retrain=False,\n",
    "        forecast_horizon=params['output_chunk_length'],\n",
    "        stride=25,\n",
    "        metric=[mae, rmse],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    log.info(f'BACKTEST: acc: {acc}')\n",
    "    log.info(f'BACKTEST: np.mean(acc, axis=0): {np.mean(acc, axis=0)}')\n",
    "    acc_df = pd.DataFrame(\n",
    "        np.mean(acc, axis=0).reshape(1,-1),\n",
    "        columns=['mae', 'rmse']\n",
    "    )\n",
    "\n",
    "    # add metrics\n",
    "    metrics['test_mae'] = acc_df.mae[0]\n",
    "    metrics['test_rmse'] = acc_df.rmse[0]\n",
    "\n",
    "    # final training\n",
    "    final_train_series = test_series\n",
    "    log.info('final training')\n",
    "    model.fit(\n",
    "            series=test_series,\n",
    "            past_covariates=past_cov,\n",
    "            future_covariates=futr_cov,\n",
    "            verbose=True,\n",
    "            # epochs=params['n_epochs_final'], # continue training\n",
    "            )\n",
    "    \n",
    "    # final model back test on validation data\n",
    "    acc = model.backtest(\n",
    "            series=test_series,\n",
    "            past_covariates=past_cov,\n",
    "            future_covariates=futr_cov,\n",
    "            retrain=False,\n",
    "            forecast_horizon=params['output_chunk_length'],\n",
    "            stride=25,\n",
    "            metric=[mae, rmse],\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "    log.info(f'TEST ACC: acc: {acc}')\n",
    "    log.info(f'TEST ACC: np.mean(acc, axis=0): {np.mean(acc, axis=0)}')\n",
    "    acc_df = pd.DataFrame(\n",
    "        np.mean(acc, axis=0).reshape(1,-1),\n",
    "        columns=['mae', 'rmse']\n",
    "    )\n",
    "\n",
    "    # add and log metrics\n",
    "    metrics['mae_final'] = acc_df.mae[0]\n",
    "    metrics['rmse_final'] = acc_df.rmse[0]\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # set up path to save model\n",
    "    model_path = '/'.join([artifact_path, model.MODEL_TYPE])\n",
    "\n",
    "    shutil.rmtree(artifact_path, ignore_errors=True)\n",
    "    os.makedirs(artifact_path)\n",
    "\n",
    "    # log params\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # save model files (model, model.ckpt) \n",
    "    # and load them to artifacts when logging the model\n",
    "    model.save(model_path)\n",
    "\n",
    "    # save MODEL_TYPE to artifacts\n",
    "    # this will be used to load the model from the artifacts\n",
    "    model_type_path = '/'.join([artifact_path, 'MODEL_TYPE.pkl'])\n",
    "    with open(model_type_path, 'wb') as handle:\n",
    "        pickle.dump(model.MODEL_TYPE, handle)\n",
    "    \n",
    "    # map model artififacts in dictionary\n",
    "    artifacts = {\n",
    "        'model': model_path,\n",
    "        'model.ckpt': model_path+'.ckpt',\n",
    "        'MODEL_TYPE': model_type_path,\n",
    "    }\n",
    "    \n",
    "    # log model\n",
    "    # https://www.mlflow.org/docs/latest/tutorials-and-examples/tutorial.html#pip-requirements-example\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path='GlobalForecasting',\n",
    "        code_path=['notebooks/model_training/darts_wrapper.py'],\n",
    "        signature=darts_signature,\n",
    "        artifacts=artifacts,\n",
    "        # model will get loaded from artifacts, we don't need instantiate with one\n",
    "        python_model=DartsGlobalModel(), \n",
    "        pip_requirements=[\"-r notebooks/model_training/requirements.txt\"],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b984cc4-bef4-469d-b102-16aa3473d468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12398672-837a-414c-a72a-09c533611cc2",
   "metadata": {},
   "source": [
    "## Get latest run and test predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3c7efb-9cc0-40ed-a894-9aa73208ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(\n",
    "    experiment_ids = exp.experiment_id,\n",
    "    # order_by=['metrics.test_mae']\n",
    "    order_by=['end_time']\n",
    "    )\n",
    "\n",
    "runs.sort_values('end_time', ascending=False, inplace=True)\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45812534-9c6e-4bd6-9a74-7c525d4a8006",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run_id = runs.run_id.iloc[0]\n",
    "best_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79254137-df64-4796-a7c7-06c9ce8b8308",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs['artifact_uri'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a950dc70-8dde-4b6d-b2b5-293e5eb47692",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = runs['artifact_uri'].iloc[0] + '/GlobalForecasting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c1f67-56f6-4d68-a151-5d058213eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f8fb9-6842-4b3c-89fc-2ac6ae858f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series = all_series[0]\n",
    "# plot_end_time = min(plot_series.end_time(), pd.Timestamp('2024-07-01T23:00:00'))\n",
    "# plot_end_time = min(plot_series.end_time(), pd.Timestamp('2024-07-15T23:00:00'))\n",
    "plot_end_time = min(plot_series.end_time(), pd.Timestamp('2024-07-14T23:00:00'))\n",
    "plot_end_time = min(plot_series.end_time(), pd.Timestamp('2024-07-20T23:00:00'))\n",
    "plot_end_time = min(plot_series.end_time(), pd.Timestamp('2024-08-01T23:00:00'))\n",
    "log.info(F'plot_end_time: {plot_end_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf5ae44-7da5-4f65-b779-5ed516b11434",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_node_name = plot_series.static_covariates.unique_id.LMP\n",
    "plot_node_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024d88a-cb3c-4309-ae89-68145f54fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if test_end_time < test_series.end_time():\n",
    "node_series = plot_series.drop_after(plot_end_time)\n",
    "    \n",
    "log.info(f'plot_end_time: {plot_end_time}')\n",
    "log.info(f'node_series.end_time(): {node_series.end_time()}')\n",
    "future_cov_series = futr_cov[0]\n",
    "past_cov_series = past_cov[0]\n",
    "\n",
    "\n",
    "data = {\n",
    "    'series': [node_series.to_json()],\n",
    "    'past_covariates': [past_cov_series.to_json()],\n",
    "    'future_covariates': [future_cov_series.to_json()],\n",
    "    'n': FORECAST_HORIZON,\n",
    "    'num_samples': 200\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "plot_cov_df = future_cov_series.pd_dataframe()\n",
    "plot_cov_df = (\n",
    "    plot_cov_df\n",
    "    .reset_index()\n",
    "    .rename(columns={'timestamp_mst':'time', 're_ratio': 'Ratio'})\n",
    ")\n",
    "plot_cov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aa4401-8268-4c3f-8ac0-734d86be0c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec4f2d3-9ed8-4c1b-ba10-a096e6306a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a Pandas DataFrame.\n",
    "df['num_samples'] = 500\n",
    "pred = loaded_model.predict(df)\n",
    "preds = TimeSeries.from_json(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e389ff-ef9a-49ed-9939-3baa420d3323",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_df = plotting.get_quantile_df(preds)\n",
    "q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303d2ece-a9d3-47b6-a521-3d45e03d4a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = plotting.get_mean_df(preds).merge(\n",
    "    plotting.get_quantile_df(preds),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "plot_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d0845-8d97-4abc-99c9-90d81a3ea981",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmp_df = lmp.to_pandas().rename(\n",
    "    columns={\n",
    "        'LMP': 'LMP_HOURLY',\n",
    "        'unique_id':'node', \n",
    "        'timestamp_mst':'time'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea49c91a-0960-4df4-b9bf-5245b65a0c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = plotting.get_plot_df(\n",
    "        TimeSeries.from_json(pred),\n",
    "        plot_cov_df,\n",
    "        lmp_df,\n",
    "        plot_node_name,\n",
    "    )\n",
    "plot_df.rename(columns={'mean':'mean_fcast'}, inplace=True)\n",
    "plot_df\n",
    "\n",
    "plotting.plotly_forecast(plot_df, plot_node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21b0ce0-098e-403d-a350-62f995c86ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b959212-49c0-4449-aad1-4750d549501a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8244f8d4-c3ca-4d9e-9d3f-468b31cb612f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb1bf91-efaa-4c54-bba0-95b8483b40fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c89310-d39a-4ae6-82f4-06cae53f5354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spp_weis",
   "language": "python",
   "name": "spp_weis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
