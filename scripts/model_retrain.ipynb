{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b9662e0-d4e2-411a-a2af-124e1fbbcae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:adding module path\n",
      "INFO:__main__:os.getcwd(): /home/justinfields/Documents/spp_weis_price_forecast\n",
      "INFO:__main__:os.listdir(): ['.gitattributes', 'scripts', 'data', '.ipynb_checkpoints', 'jobs', 'study_csv', '.gitignore', 'saved_models', 'tide_1.pt', 'model_artifacts', '.streamlit', 'tft_0.pt', '.git', 'model_checkpoints', '.github', 'TRAIN_TIMESTAMP.pkl', 'notebooks', 'app.py', 'tide_1.pt.ckpt', 'tft_1.pt', 'optuna', 'tft_1.pt.ckpt', 'tide_0.pt', 'requirements.txt', '.idea', 'LICENSE', 'env', 'mlruns', 'README.md', 'imgs', '.env', 'GlobalForecasting', '.devcontainer', 'app.py.bak', 'spp_trials.db', 'venv', 'tft_0.pt.ckpt', 'tide_0.pt.ckpt', 's3_models', 's3_mlruns.db', 'src']\n",
      "INFO:data_engineering:adding module path\n",
      "INFO:modeling:adding module path\n",
      "INFO:botocore.credentials:Found credentials in environment variables.\n",
      "INFO:__main__:FORECAST_HORIZON: 120\n",
      "INFO:__main__:INPUT_CHUNK_LENGTH: 168\n",
      "INFO:__main__:MODEL_NAME: spp_weis\n",
      "INFO:__main__:getting lmp data from s3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:getting mtrf data from s3\n",
      "INFO:__main__:getting mtlf data from s3\n",
      "INFO:__main__:getting weather data from s3\n",
      "INFO:__main__:finished getting data from s3\n",
      "INFO:__main__:preparing lmp data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2045dfff2f5d40d09d43de9a68c54d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:preparing covariate data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9deb6976601747d1b19bb306c17932b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1136ae91f3774a44ab04d2c61d666c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 80271 entries, 2024-02-01 00:00:00 to 2024-12-01 12:00:00\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   unique_id             80271 non-null  object \n",
      " 1   LMP                   73708 non-null  float32\n",
      " 2   Averaged_Actual       78462 non-null  float32\n",
      " 3   lmp_diff              73699 non-null  float32\n",
      " 4   lmp_load_net_re       73708 non-null  float32\n",
      " 5   MTLF                  80271 non-null  float32\n",
      " 6   Wind_Forecast_MW      80271 non-null  float32\n",
      " 7   Solar_Forecast_MW     80271 non-null  float32\n",
      " 8   re_ratio              80271 non-null  float32\n",
      " 9   re_diff               80270 non-null  float32\n",
      " 10  load_net_re           80271 non-null  float32\n",
      " 11  load_net_re_diff_lag  80270 non-null  float32\n",
      " 12  temperature           80271 non-null  float32\n",
      "dtypes: float32(12), object(1)\n",
      "memory usage: 4.9+ MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44d93481a67440b9ab6908adb2a3e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data_engineering:train_start: 2024-02-15 00:00:00\n",
      "INFO:data_engineering:tr_tst_split: 2025-01-09 16:00:00\n",
      "INFO:data_engineering:test_end: 2025-01-23 16:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ibis\n",
    "import boto3\n",
    "import torch\n",
    "\n",
    "ibis.options.interactive = True\n",
    "\n",
    "from darts.metrics import mae, rmse\n",
    "from darts.models import (\n",
    "    TFTModel,\n",
    "    TiDEModel,\n",
    "    TSMixerModel,\n",
    "    NaiveEnsembleModel,\n",
    ")\n",
    "\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# define log\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# adding module folder to system path\n",
    "# needed for running scripts as jobs\n",
    "os.chdir('..')\n",
    "home = os.getenv('HOME')\n",
    "module_paths = [\n",
    "    f'{home}/spp_weis_price_forecast/src',\n",
    "    f'{home}/Documents/spp_weis_price_forecast/src',\n",
    "]\n",
    "for module_path in module_paths:\n",
    "    if os.path.isdir(module_path):\n",
    "        log.info('adding module path')\n",
    "        sys.path.insert(0, module_path)\n",
    "\n",
    "log.info(f'os.getcwd(): {os.getcwd()}')\n",
    "log.info(f'os.listdir(): {os.listdir()}')\n",
    "\n",
    "# from module path\n",
    "import data_engineering as de\n",
    "import parameters\n",
    "from modeling import get_ci_err, build_fit_tsmixerx, build_fit_tft, build_fit_tide, log_pretty\n",
    "\n",
    "# will be loaded from root when deployed\n",
    "from darts_wrapper import DartsGlobalModel\n",
    "\n",
    "# client for uploading model weights\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# check parameters\n",
    "log.info(f'FORECAST_HORIZON: {parameters.FORECAST_HORIZON}')\n",
    "log.info(f'INPUT_CHUNK_LENGTH: {parameters.INPUT_CHUNK_LENGTH}')\n",
    "log.info(f'MODEL_NAME: {parameters.MODEL_NAME}')\n",
    "\n",
    "# connect to database and prepare data\n",
    "print('\\n' + '*' * 40)\n",
    "con = de.create_database()\n",
    "\n",
    "\n",
    "log.info('preparing lmp data')\n",
    "lmp = de.prep_lmp(con)\n",
    "lmp_df = lmp.to_pandas().rename(\n",
    "    columns={\n",
    "        'LMP': 'LMP_HOURLY',\n",
    "        'unique_id': 'node',\n",
    "        'timestamp_mst': 'time'\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "log.info('preparing covariate data')\n",
    "# all_df = de.prep_all_df(con)\n",
    "all_df_pd = de.all_df_to_pandas(de.prep_all_df(con))\n",
    "all_df_pd.info()\n",
    "\n",
    "lmp_all, train_all, test_all, train_test_all = de.get_train_test_all(con)\n",
    "con.disconnect()\n",
    "\n",
    "all_series = de.get_series(lmp_all)\n",
    "train_test_all_series = de.get_series(train_test_all)\n",
    "train_series = de.get_series(train_all)\n",
    "test_series = de.get_series(test_all)\n",
    "\n",
    "futr_cov = de.get_futr_cov(all_df_pd)\n",
    "past_cov = de.get_past_cov(all_df_pd)\n",
    "\n",
    "print('\\n' + '*' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8cd103d-00e3-485e-8413-695dea0c1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pretrained models\n",
    "models_tsmixer = []\n",
    "if parameters.USE_TSMIXER:\n",
    "    for i, param in enumerate(parameters.TSMIXER_PARAMS[:parameters.TOP_N]):\n",
    "        print(f'\\ni: {i} \\t' + '*' * 25, flush=True)\n",
    "        model_tsmixer = build_fit_tsmixerx(\n",
    "            series=train_test_all_series,\n",
    "            val_series=test_series,\n",
    "            future_covariates=futr_cov,\n",
    "            past_covariates=past_cov,\n",
    "            **param\n",
    "        )\n",
    "        models_tsmixer += [model_tsmixer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24e1747a-cdb5-4fa7-bba4-712e7b31b921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "i: 0 \t*************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modeling:model_params: \n",
      "{ 'num_encoder_layers': 1,\n",
      "  'num_decoder_layers': 1,\n",
      "  'decoder_output_dim': 26,\n",
      "  'hidden_size': 19,\n",
      "  'temporal_width_past': 2,\n",
      "  'temporal_width_future': 6,\n",
      "  'temporal_decoder_hidden': 7,\n",
      "  'temporal_hidden_size_past': 19,\n",
      "  'temporal_hidden_size_future': 28,\n",
      "  'input_chunk_length': 168,\n",
      "  'output_chunk_length': 120,\n",
      "  'batch_size': 64,\n",
      "  'use_layer_norm': False,\n",
      "  'use_reversible_instance_norm': True,\n",
      "  'n_epochs': 6,\n",
      "  'dropout': 0.42,\n",
      "  'add_encoders': { 'datetime_attribute': { 'future': ['month'],\n",
      "                                            'past': ['month']},\n",
      "                    'position': {'past': ['relative'], 'future': ['relative']},\n",
      "                    'transformer': Scaler},\n",
      "  'likelihood': QuantileRegression(quantiles: Optional[List[float]] = None),\n",
      "  'optimizer_kwargs': {'lr': 3.5e-05},\n",
      "  'random_state': 42,\n",
      "  'torch_metrics': MeanSquaredError(),\n",
      "  'use_static_covariates': False,\n",
      "  'save_checkpoints': True,\n",
      "  'work_dir': '/home/justinfields/Documents/spp_weis_price_forecast/model_checkpoints/tide_model',\n",
      "  'model_name': 'tide',\n",
      "  'force_reset': True,\n",
      "  'log_tensorboard': False}\n",
      "\n",
      "INFO:darts.models.forecasting.torch_forecasting_model:Train dataset contains 71640 samples.\n",
      "INFO:darts.models.forecasting.torch_forecasting_model:Time series values are 32-bits; casting model to float32.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                  | Type             | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0  | criterion             | MSELoss          | 0      | train\n",
      "1  | train_criterion       | MSELoss          | 0      | train\n",
      "2  | val_criterion         | MSELoss          | 0      | train\n",
      "3  | train_metrics         | MetricCollection | 0      | train\n",
      "4  | val_metrics           | MetricCollection | 0      | train\n",
      "5  | rin                   | RINorm           | 2      | train\n",
      "6  | past_cov_projection   | _ResidualBlock   | 166    | train\n",
      "7  | future_cov_projection | _ResidualBlock   | 548    | train\n",
      "8  | encoders              | Sequential       | 85.2 K | train\n",
      "9  | decoders              | Sequential       | 2.6 M  | train\n",
      "10 | temporal_decoder      | _ResidualBlock   | 15.7 K | train\n",
      "11 | lookback_skip         | Linear           | 425 K  | train\n",
      "--------------------------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.595    Total estimated model params size (MB)\n",
      "46        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a0d11eb42645b8bbab1a435e3d5101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "i: 1 \t*************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modeling:model_params: \n",
      "{ 'num_encoder_layers': 4,\n",
      "  'num_decoder_layers': 4,\n",
      "  'decoder_output_dim': 15,\n",
      "  'hidden_size': 20,\n",
      "  'temporal_width_past': 2,\n",
      "  'temporal_width_future': 6,\n",
      "  'temporal_decoder_hidden': 25,\n",
      "  'temporal_hidden_size_past': 4,\n",
      "  'temporal_hidden_size_future': 12,\n",
      "  'input_chunk_length': 168,\n",
      "  'output_chunk_length': 120,\n",
      "  'batch_size': 64,\n",
      "  'use_layer_norm': False,\n",
      "  'use_reversible_instance_norm': True,\n",
      "  'n_epochs': 4,\n",
      "  'dropout': 0.41,\n",
      "  'add_encoders': { 'datetime_attribute': { 'future': ['month', 'dayofweek'],\n",
      "                                            'past': ['month', 'dayofweek']},\n",
      "                    'position': {'past': ['relative'], 'future': ['relative']},\n",
      "                    'transformer': Scaler},\n",
      "  'likelihood': QuantileRegression(quantiles: Optional[List[float]] = None),\n",
      "  'optimizer_kwargs': {'lr': 7.9e-05},\n",
      "  'random_state': 42,\n",
      "  'torch_metrics': MeanSquaredError(),\n",
      "  'use_static_covariates': False,\n",
      "  'save_checkpoints': True,\n",
      "  'work_dir': '/home/justinfields/Documents/spp_weis_price_forecast/model_checkpoints/tide_model',\n",
      "  'model_name': 'tide',\n",
      "  'force_reset': True,\n",
      "  'log_tensorboard': False}\n",
      "\n",
      "INFO:darts.models.forecasting.torch_forecasting_model:Train dataset contains 71640 samples.\n",
      "INFO:darts.models.forecasting.torch_forecasting_model:Time series values are 32-bits; casting model to float32.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                  | Type             | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0  | criterion             | MSELoss          | 0      | train\n",
      "1  | train_criterion       | MSELoss          | 0      | train\n",
      "2  | val_criterion         | MSELoss          | 0      | train\n",
      "3  | train_metrics         | MetricCollection | 0      | train\n",
      "4  | val_metrics           | MetricCollection | 0      | train\n",
      "5  | rin                   | RINorm           | 2      | train\n",
      "6  | past_cov_projection   | _ResidualBlock   | 52     | train\n",
      "7  | future_cov_projection | _ResidualBlock   | 294    | train\n",
      "8  | encoders              | Sequential       | 93.5 K | train\n",
      "9  | decoders              | Sequential       | 1.6 M  | train\n",
      "10 | temporal_decoder      | _ResidualBlock   | 15.4 K | train\n",
      "11 | lookback_skip         | Linear           | 425 K  | train\n",
      "--------------------------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.508     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0badc0f3f20f4fd4ac0dba606b8e550e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "i: 2 \t*************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modeling:model_params: \n",
      "{ 'num_encoder_layers': 1,\n",
      "  'num_decoder_layers': 1,\n",
      "  'decoder_output_dim': 17,\n",
      "  'hidden_size': 23,\n",
      "  'temporal_width_past': 2,\n",
      "  'temporal_width_future': 4,\n",
      "  'temporal_decoder_hidden': 23,\n",
      "  'temporal_hidden_size_past': 23,\n",
      "  'temporal_hidden_size_future': 19,\n",
      "  'input_chunk_length': 168,\n",
      "  'output_chunk_length': 120,\n",
      "  'batch_size': 64,\n",
      "  'use_layer_norm': False,\n",
      "  'use_reversible_instance_norm': True,\n",
      "  'n_epochs': 6,\n",
      "  'dropout': 0.42,\n",
      "  'add_encoders': { 'position': {'past': ['relative'], 'future': ['relative']},\n",
      "                    'transformer': Scaler},\n",
      "  'likelihood': QuantileRegression(quantiles: Optional[List[float]] = None),\n",
      "  'optimizer_kwargs': {'lr': 3.5e-05},\n",
      "  'random_state': 42,\n",
      "  'torch_metrics': MeanSquaredError(),\n",
      "  'use_static_covariates': False,\n",
      "  'save_checkpoints': True,\n",
      "  'work_dir': '/home/justinfields/Documents/spp_weis_price_forecast/model_checkpoints/tide_model',\n",
      "  'model_name': 'tide',\n",
      "  'force_reset': True,\n",
      "  'log_tensorboard': False}\n",
      "\n",
      "INFO:darts.models.forecasting.torch_forecasting_model:Train dataset contains 71640 samples.\n",
      "INFO:darts.models.forecasting.torch_forecasting_model:Time series values are 32-bits; casting model to float32.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                  | Type             | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0  | criterion             | MSELoss          | 0      | train\n",
      "1  | train_criterion       | MSELoss          | 0      | train\n",
      "2  | val_criterion         | MSELoss          | 0      | train\n",
      "3  | train_metrics         | MetricCollection | 0      | train\n",
      "4  | val_metrics           | MetricCollection | 0      | train\n",
      "5  | rin                   | RINorm           | 2      | train\n",
      "6  | past_cov_projection   | _ResidualBlock   | 173    | train\n",
      "7  | future_cov_projection | _ResidualBlock   | 310    | train\n",
      "8  | encoders              | Sequential       | 76.8 K | train\n",
      "9  | decoders              | Sequential       | 2.1 M  | train\n",
      "10 | temporal_decoder      | _ResidualBlock   | 16.4 K | train\n",
      "11 | lookback_skip         | Linear           | 425 K  | train\n",
      "--------------------------------------------------------------------\n",
      "2.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 M     Total params\n",
      "10.306    Total estimated model params size (MB)\n",
      "46        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89709fea5ed9446682786874cc349c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "i: 3 \t*************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modeling:model_params: \n",
      "{ 'num_encoder_layers': 4,\n",
      "  'num_decoder_layers': 4,\n",
      "  'decoder_output_dim': 24,\n",
      "  'hidden_size': 23,\n",
      "  'temporal_width_past': 1,\n",
      "  'temporal_width_future': 2,\n",
      "  'temporal_decoder_hidden': 12,\n",
      "  'temporal_hidden_size_past': 23,\n",
      "  'temporal_hidden_size_future': 30,\n",
      "  'input_chunk_length': 168,\n",
      "  'output_chunk_length': 120,\n",
      "  'batch_size': 64,\n",
      "  'use_layer_norm': False,\n",
      "  'use_reversible_instance_norm': True,\n",
      "  'n_epochs': 5,\n",
      "  'dropout': 0.5,\n",
      "  'add_encoders': { 'position': {'past': ['relative'], 'future': ['relative']},\n",
      "                    'transformer': Scaler},\n",
      "  'likelihood': QuantileRegression(quantiles: Optional[List[float]] = None),\n",
      "  'optimizer_kwargs': {'lr': 2e-05},\n",
      "  'random_state': 42,\n",
      "  'torch_metrics': MeanSquaredError(),\n",
      "  'use_static_covariates': False,\n",
      "  'save_checkpoints': True,\n",
      "  'work_dir': '/home/justinfields/Documents/spp_weis_price_forecast/model_checkpoints/tide_model',\n",
      "  'model_name': 'tide',\n",
      "  'force_reset': True,\n",
      "  'log_tensorboard': False}\n",
      "\n",
      "INFO:darts.models.forecasting.torch_forecasting_model:Train dataset contains 71640 samples.\n",
      "INFO:darts.models.forecasting.torch_forecasting_model:Time series values are 32-bits; casting model to float32.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                  | Type             | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0  | criterion             | MSELoss          | 0      | train\n",
      "1  | train_criterion       | MSELoss          | 0      | train\n",
      "2  | val_criterion         | MSELoss          | 0      | train\n",
      "3  | train_metrics         | MetricCollection | 0      | train\n",
      "4  | val_metrics           | MetricCollection | 0      | train\n",
      "5  | rin                   | RINorm           | 2      | train\n",
      "6  | past_cov_projection   | _ResidualBlock   | 144    | train\n",
      "7  | future_cov_projection | _ResidualBlock   | 382    | train\n",
      "8  | encoders              | Sequential       | 47.5 K | train\n",
      "9  | decoders              | Sequential       | 2.9 M  | train\n",
      "10 | temporal_decoder      | _ResidualBlock   | 17.0 K | train\n",
      "11 | lookback_skip         | Linear           | 425 K  | train\n",
      "--------------------------------------------------------------------\n",
      "3.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.4 M     Total params\n",
      "13.598    Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f146725b5b24aff9a15009ebe5c91cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "i: 4 \t*************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modeling:model_params: \n",
      "{ 'num_encoder_layers': 1,\n",
      "  'num_decoder_layers': 1,\n",
      "  'decoder_output_dim': 26,\n",
      "  'hidden_size': 25,\n",
      "  'temporal_width_past': 2,\n",
      "  'temporal_width_future': 4,\n",
      "  'temporal_decoder_hidden': 16,\n",
      "  'temporal_hidden_size_past': 23,\n",
      "  'temporal_hidden_size_future': 19,\n",
      "  'input_chunk_length': 168,\n",
      "  'output_chunk_length': 120,\n",
      "  'batch_size': 64,\n",
      "  'use_layer_norm': False,\n",
      "  'use_reversible_instance_norm': True,\n",
      "  'n_epochs': 6,\n",
      "  'dropout': 0.42,\n",
      "  'add_encoders': { 'position': {'past': ['relative'], 'future': ['relative']},\n",
      "                    'transformer': Scaler},\n",
      "  'likelihood': QuantileRegression(quantiles: Optional[List[float]] = None),\n",
      "  'optimizer_kwargs': {'lr': 3.5e-05},\n",
      "  'random_state': 42,\n",
      "  'torch_metrics': MeanSquaredError(),\n",
      "  'use_static_covariates': False,\n",
      "  'save_checkpoints': True,\n",
      "  'work_dir': '/home/justinfields/Documents/spp_weis_price_forecast/model_checkpoints/tide_model',\n",
      "  'model_name': 'tide',\n",
      "  'force_reset': True,\n",
      "  'log_tensorboard': False}\n",
      "\n",
      "INFO:darts.models.forecasting.torch_forecasting_model:Train dataset contains 71640 samples.\n",
      "INFO:darts.models.forecasting.torch_forecasting_model:Time series values are 32-bits; casting model to float32.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                  | Type             | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0  | criterion             | MSELoss          | 0      | train\n",
      "1  | train_criterion       | MSELoss          | 0      | train\n",
      "2  | val_criterion         | MSELoss          | 0      | train\n",
      "3  | train_metrics         | MetricCollection | 0      | train\n",
      "4  | val_metrics           | MetricCollection | 0      | train\n",
      "5  | rin                   | RINorm           | 2      | train\n",
      "6  | past_cov_projection   | _ResidualBlock   | 173    | train\n",
      "7  | future_cov_projection | _ResidualBlock   | 310    | train\n",
      "8  | encoders              | Sequential       | 83.5 K | train\n",
      "9  | decoders              | Sequential       | 3.4 M  | train\n",
      "10 | temporal_decoder      | _ResidualBlock   | 20.7 K | train\n",
      "11 | lookback_skip         | Linear           | 425 K  | train\n",
      "--------------------------------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.9 M     Total params\n",
      "15.753    Total estimated model params size (MB)\n",
      "46        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c6e1b89e544117a18dab96f4677776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    }
   ],
   "source": [
    "models_tide = []\n",
    "if parameters.USE_TIDE:\n",
    "    for i, param in enumerate(parameters.TIDE_PARAMS[:parameters.TOP_N]):\n",
    "        print(f'\\ni: {i} \\t' + '*' * 25, flush=True)\n",
    "        model_tide = build_fit_tide(\n",
    "            series=train_test_all_series,\n",
    "            val_series=test_series,\n",
    "            future_covariates=futr_cov,\n",
    "            past_covariates=past_cov,\n",
    "            **param\n",
    "        )\n",
    "        models_tide += [model_tide]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00bd7563-7dc3-40c2-8062-16c96aa42290",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_tft = []\n",
    "if parameters.USE_TFT:\n",
    "    for i, param in enumerate(parameters.TFT_PARAMS[:parameters.TOP_N]):\n",
    "        print(f'\\ni: {i} \\t' + '*' * 25, flush=True)\n",
    "        model_tft = build_fit_tft(\n",
    "            series=train_test_all_series,\n",
    "            val_series=test_series,\n",
    "            future_covariates=futr_cov,\n",
    "            past_covariates=past_cov,\n",
    "            **param\n",
    "        )\n",
    "        models_tft += [model_tft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af01ccc-9615-45a7-8abc-d3ee1612a6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "439e768d-719f-4058-a888-ed27cf3b37a2",
   "metadata": {},
   "source": [
    "## Save and upload models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8846efb3-6343-4543-97a3-d1c4793c2610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory to store artifacts\n",
    "if os.path.isdir('saved_models'):\n",
    "    shutil.rmtree('saved_models')\n",
    "os.mkdir('saved_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58a21e87-b694-475b-a8b1-cec54018b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_timestamp = '/'.join(['saved_models', 'TRAIN_TIMESTAMP.pkl'])\n",
    "with open(model_timestamp, 'wb') as handle:\n",
    "    pickle.dump(pd.Timestamp.utcnow(), handle)\n",
    "\n",
    "for i, m in enumerate(models_tide):\n",
    "    m.save(f'saved_models/tide_{i}.pt')\n",
    "\n",
    "for i, m in enumerate(models_tsmixer):\n",
    "    m.save(f'saved_models/tsmixer_{i}.pt')\n",
    "\n",
    "for i, m in enumerate(models_tft):\n",
    "    m.save(f'saved_models/tft_{i}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "016410c2-0775-403d-9a69-20f22b5cacd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:ckpt_uploads: ['tide_2.pt', 'tide_1.pt', 'tide_4.pt.ckpt', 'tide_2.pt.ckpt', 'tide_4.pt', 'tide_3.pt.ckpt', 'TRAIN_TIMESTAMP.pkl', 'tide_1.pt.ckpt', 'tide_0.pt', 'tide_3.pt', 'tide_0.pt.ckpt']\n"
     ]
    }
   ],
   "source": [
    "ckpt_uploads = [f for f in os.listdir('saved_models') if '.pt' in f or '.ckpt' in f or 'TRAIN_TIMESTAMP.pkl' in f]\n",
    "log.info(f'ckpt_uploads: {ckpt_uploads}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55e69763-d540-4cbb-ba43-f29b22bc964f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:uploading: tide_2.pt\n",
      "INFO:__main__:uploading: tide_1.pt\n",
      "INFO:__main__:uploading: tide_4.pt.ckpt\n",
      "INFO:__main__:uploading: tide_2.pt.ckpt\n",
      "INFO:__main__:uploading: tide_4.pt\n",
      "INFO:__main__:uploading: tide_3.pt.ckpt\n",
      "INFO:__main__:uploading: TRAIN_TIMESTAMP.pkl\n",
      "INFO:__main__:uploading: tide_1.pt.ckpt\n",
      "INFO:__main__:uploading: tide_0.pt\n",
      "INFO:__main__:uploading: tide_3.pt\n",
      "INFO:__main__:uploading: tide_0.pt.ckpt\n"
     ]
    }
   ],
   "source": [
    "# upload artifacts\n",
    "for ckpt in ckpt_uploads:\n",
    "    log.info(f'uploading: {ckpt}')\n",
    "    s3.upload_file(f'saved_models/{ckpt}', 'spp-weis', f's3_models/{ckpt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65a4fb15-6118-4f17-8a20-1c109143026f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:loaded_models: ['s3_models/TRAIN_TIMESTAMP.pkl', 's3_models/tide_0.pt', 's3_models/tide_0.pt.ckpt', 's3_models/tide_1.pt', 's3_models/tide_1.pt.ckpt', 's3_models/tide_2.pt', 's3_models/tide_2.pt.ckpt', 's3_models/tide_3.pt', 's3_models/tide_3.pt.ckpt', 's3_models/tide_4.pt', 's3_models/tide_4.pt.ckpt']\n"
     ]
    }
   ],
   "source": [
    "loaded_models = [d['Key'] for d in s3.list_objects(Bucket='spp-weis')['Contents'] if 's3_models/' in d['Key']]\n",
    "log.info(f'loaded_models: {loaded_models}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5549db87-5fce-41ed-933f-259b22685891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:models_to_delete: []\n"
     ]
    }
   ],
   "source": [
    "models_to_delete = [l for l in loaded_models if l.split('/')[-1] not in ckpt_uploads]\n",
    "log.info(f'models_to_delete: {models_to_delete}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e38e5fd9-b60a-495d-a90b-c5a89dab0c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for del_model in models_to_delete:\n",
    "    log.info(f'removing: {del_model}')\n",
    "    s3.delete_object(Bucket='spp-weis', Key=del_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0308d4-769f-4452-bbfe-02f4d14b330e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98b59b3d-14e7-4036-bc2e-4ba89147556c",
   "metadata": {},
   "source": [
    "## Test loading models from S3 and doing inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed4d398c-1acf-4fe4-9491-f58a94a6e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('s3_models'):\n",
    "    shutil.rmtree('s3_models')\n",
    "os.mkdir('s3_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ed1ec95-a263-4dea-b034-2b28d01f7df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:loaded_models: ['s3_models/TRAIN_TIMESTAMP.pkl', 's3_models/tide_0.pt', 's3_models/tide_0.pt.ckpt', 's3_models/tide_1.pt', 's3_models/tide_1.pt.ckpt', 's3_models/tide_2.pt', 's3_models/tide_2.pt.ckpt', 's3_models/tide_3.pt', 's3_models/tide_3.pt.ckpt', 's3_models/tide_4.pt', 's3_models/tide_4.pt.ckpt']\n"
     ]
    }
   ],
   "source": [
    "loaded_models = [d['Key'] for d in s3.list_objects(Bucket='spp-weis')['Contents'] if 's3_models/' in d['Key']]\n",
    "log.info(f'loaded_models: {loaded_models}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a22c2b95-69ef-4dc2-a946-e044002c1316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:downloading: s3_models/TRAIN_TIMESTAMP.pkl\n",
      "INFO:__main__:downloading: s3_models/tide_0.pt\n",
      "INFO:__main__:downloading: s3_models/tide_0.pt.ckpt\n",
      "INFO:__main__:downloading: s3_models/tide_1.pt\n",
      "INFO:__main__:downloading: s3_models/tide_1.pt.ckpt\n",
      "INFO:__main__:downloading: s3_models/tide_2.pt\n",
      "INFO:__main__:downloading: s3_models/tide_2.pt.ckpt\n",
      "INFO:__main__:downloading: s3_models/tide_3.pt\n",
      "INFO:__main__:downloading: s3_models/tide_3.pt.ckpt\n",
      "INFO:__main__:downloading: s3_models/tide_4.pt\n",
      "INFO:__main__:downloading: s3_models/tide_4.pt.ckpt\n"
     ]
    }
   ],
   "source": [
    "for lm in loaded_models:\n",
    "    log.info(f'downloading: {lm}')\n",
    "    s3.download_file(Bucket='spp-weis', Key=lm, Filename=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b4a4a0-b509-4f57-9de9-7b097a8a9d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af6f681d-d53a-40c2-8c0d-a0e90e047747",
   "metadata": {},
   "source": [
    "### Load models by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c25a712-f19e-48cd-b3de-f112b37b3387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_mixer_ckpts = [f for f in os.listdir('s3_models') if 'tsmixer' in f and '.pt' in f and '.ckpt' not in f and 'TRAIN_TIMESTAMP.pkl' not in f]\n",
    "ts_mixer_ckpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e70ef0a8-3186-4b15-8dc4-d8936920a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_mixer_forecasting_models = []\n",
    "for m_ckpt in ts_mixer_ckpts:\n",
    "    log.info(f'loading model: {m_ckpt}')\n",
    "    ts_mixer_forecasting_models += [TSMixerModel.load(f's3_models/{m_ckpt}', map_location=torch.device('cpu'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fd04b32-266e-4505-9c6d-a0e8c7b4bbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tide_2.pt', 'tide_1.pt', 'tide_4.pt', 'tide_0.pt', 'tide_3.pt']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tide_ckpts = [f for f in os.listdir('s3_models') if 'tide_' in f and '.pt' in f and '.ckpt' not in f and 'TRAIN_TIMESTAMP.pkl' not in f]\n",
    "tide_ckpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96100e2f-09fd-4954-bbf5-1986b4e6b1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:loading model: tide_2.pt\n",
      "INFO:__main__:loading model: tide_1.pt\n",
      "INFO:__main__:loading model: tide_4.pt\n",
      "INFO:__main__:loading model: tide_0.pt\n",
      "INFO:__main__:loading model: tide_3.pt\n"
     ]
    }
   ],
   "source": [
    "tide_forecasting_models = []\n",
    "for m_ckpt in tide_ckpts:\n",
    "    log.info(f'loading model: {m_ckpt}')\n",
    "    tide_forecasting_models += [TiDEModel.load(f's3_models/{m_ckpt}', map_location=torch.device('cpu'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b2ff28f-436a-4f41-aa4a-9680ad0e6382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tft_ckpts = [f for f in os.listdir('s3_models') if 'tft' in f and '.pt' in f and '.ckpt' not in f and 'TRAIN_TIMESTAMP.pkl' not in f]\n",
    "tft_ckpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "227755cb-637f-464d-a63b-e9b29deb28e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tft_forecasting_models = []\n",
    "for m_ckpt in tft_ckpts:\n",
    "    log.info(f'loading model: {m_ckpt}')\n",
    "    tide_forecasting_models += [TFTModel.load(f's3_models/{m_ckpt}', map_location=torch.device('cpu'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d9e7de-6ef7-4b0a-b91b-8b28754ae075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6684892-8699-4c10-bbdb-bdba600d05d4",
   "metadata": {},
   "source": [
    "## Create ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1c44597-6e76-4471-aaec-9b5f6bc554a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasting_models = ts_mixer_forecasting_models + tide_forecasting_models + tft_forecasting_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f0c24b2-c993-4ca0-b0a5-9c085128a177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:loading model from checkpoints\n",
      "INFO:__main__:test getting predictions\n",
      "INFO:__main__:plot_end_time: 2025-01-23 15:00:00\n",
      "INFO:__main__:plot_end_time: 2025-01-23 15:00:00\n",
      "INFO:__main__:node_series.end_time(): 2025-01-23 14:00:00\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31541ef0db464eeda5aa7157311de52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628e783dfb4845d2ac618335b66a0f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400d8359dc8044adb71be1d6e389be61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93141e6af1c46d78142fab3ead42f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0bd08ff2784c04a8e542824be94d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:pred: <TimeSeries (DataArray) (timestamp_mst: 5, component: 1, sample: 2)> Size: 80B\n",
      "array([[[235.71188354,   6.32315302]],\n",
      "\n",
      "       [[ 15.58251381,  12.78510475]],\n",
      "\n",
      "       [[ 18.42877769,  99.97803497]],\n",
      "\n",
      "       [[-16.76118088, 226.35668945]],\n",
      "\n",
      "       [[ 54.79317474,  57.86698151]]])\n",
      "Coordinates:\n",
      "  * timestamp_mst  (timestamp_mst) datetime64[ns] 40B 2025-01-23T15:00:00 ......\n",
      "  * component      (component) object 8B 'LMP'\n",
      "Dimensions without coordinates: sample\n",
      "Attributes:\n",
      "    static_covariates:  static_covariates     unique_id\\ncomponent           ...\n",
      "    hierarchy:          None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# test predictions on latest run\n",
    "print('\\n' + '*' * 40)\n",
    "log.info('loading model from checkpoints')\n",
    "loaded_model = NaiveEnsembleModel(\n",
    "        forecasting_models=forecasting_models, \n",
    "        train_forecasting_models=False\n",
    "    )\n",
    "\n",
    "log.info('test getting predictions')\n",
    "plot_ind = 3\n",
    "plot_series = all_series[plot_ind]\n",
    "\n",
    "plot_end_time = plot_series.end_time() - pd.Timedelta(f'{parameters.INPUT_CHUNK_LENGTH + 1}h')\n",
    "log.info(f'plot_end_time: {plot_end_time}')\n",
    "\n",
    "plot_node_name = plot_series.static_covariates.unique_id.LMP\n",
    "node_series = plot_series.drop_after(plot_end_time)\n",
    "log.info(f'plot_end_time: {plot_end_time}')\n",
    "log.info(f'node_series.end_time(): {node_series.end_time()}')\n",
    "future_cov_series = futr_cov[0]\n",
    "past_cov_series = past_cov[0]\n",
    "\n",
    "data = {\n",
    "    'series': [node_series.to_json()],\n",
    "    'past_covariates': [past_cov_series.to_json()],\n",
    "    'future_covariates': [future_cov_series.to_json()],\n",
    "    'n': 5,\n",
    "    'num_samples': 2\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['num_samples'] = 2\n",
    "pred=loaded_model.predict(\n",
    "    series=node_series,\n",
    "    past_covariates=past_cov_series,\n",
    "    future_covariates=future_cov_series,\n",
    "    n=5,\n",
    "    num_samples=2,\n",
    ")\n",
    "\n",
    "print('\\n' + '*' * 40)\n",
    "log.info(f'pred: {pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8069c8b1-11d6-4da1-a5a5-084abda36838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:darts.timeseries:You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LMP_s0</th>\n",
       "      <th>LMP_s1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp_mst</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-23 15:00:00</th>\n",
       "      <td>235.711884</td>\n",
       "      <td>6.323153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-23 16:00:00</th>\n",
       "      <td>15.582514</td>\n",
       "      <td>12.785105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-23 17:00:00</th>\n",
       "      <td>18.428778</td>\n",
       "      <td>99.978035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-23 18:00:00</th>\n",
       "      <td>-16.761181</td>\n",
       "      <td>226.356689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-23 19:00:00</th>\n",
       "      <td>54.793175</td>\n",
       "      <td>57.866982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         LMP_s0      LMP_s1\n",
       "timestamp_mst                              \n",
       "2025-01-23 15:00:00  235.711884    6.323153\n",
       "2025-01-23 16:00:00   15.582514   12.785105\n",
       "2025-01-23 17:00:00   18.428778   99.978035\n",
       "2025-01-23 18:00:00  -16.761181  226.356689\n",
       "2025-01-23 19:00:00   54.793175   57.866982"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.pd_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d5476a9-d161-4c60-ab02-8ddcff44c87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:finished retraining\n"
     ]
    }
   ],
   "source": [
    "log.info('finished retraining')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98804f4-8b3a-4318-b2b7-8883d52d35b6",
   "metadata": {},
   "source": [
    "## Load models to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee01ee6d-9d5c-412a-a35f-1565ea6b6aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create directory to store artifacts\n",
    "# if os.path.isdir('saved_models'):\n",
    "#     shutil.rmtree('saved_models')\n",
    "# os.mkdir('saved_models')\n",
    "\n",
    "\n",
    "# model_timestamp = '/'.join(['saved_models', 'TRAIN_TIMESTAMP.pkl'])\n",
    "# with open(model_timestamp, 'wb') as handle:\n",
    "#     pickle.dump(pd.Timestamp.utcnow(), handle)\n",
    "\n",
    "# for i, m in enumerate(models_tide):\n",
    "#     m.save(f'saved_models/tide_{i}.pt')\n",
    "\n",
    "# for i, m in enumerate(models_tsmixer):\n",
    "#     m.save(f'saved_models/tsmixer_{i}.pt')\n",
    "\n",
    "# for i, m in enumerate(models_tft):\n",
    "#     m.save(f'saved_models/tft_{i}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b43f8d1-6f60-4839-a969-3e7f74b745a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_uploads = [f for f in os.listdir('saved_models') if '.pt' in f or '.ckpt' in f or 'TRAIN_TIMESTAMP.pkl' in f]\n",
    "# log.info(f'ckpt_uploads: {ckpt_uploads}')\n",
    "\n",
    "\n",
    "# # upload artifacts\n",
    "# for ckpt in ckpt_uploads:\n",
    "#     log.info(f'uploading: {ckpt}')\n",
    "#     s3.upload_file(f'saved_models/{ckpt}', 'spp-weis', f's3_models/{ckpt}')\n",
    "\n",
    "\n",
    "# loaded_models = [d['Key'] for d in s3.list_objects(Bucket='spp-weis')['Contents'] if 's3_models/' in d['Key']]\n",
    "# log.info(f'loaded_models: {loaded_models}')\n",
    "\n",
    "\n",
    "# models_to_delete = [l for l in loaded_models if l.split('/')[-1] not in ckpt_uploads]\n",
    "# log.info(f'models_to_delete: {models_to_delete}')\n",
    "\n",
    "\n",
    "# for del_model in models_to_delete:\n",
    "#     log.info(f'removing: {del_model}')\n",
    "#     s3.delete_object(Bucket='spp-weis', Key=del_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbedd42-e0f9-4996-8303-921ee2936643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a20ff10-b4e8-4e54-b5e7-ee2e15d40318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_models = [d['Key'] for d in s3.list_objects(Bucket='spp-weis')['Contents'] if 's3_models/' in d['Key']]\n",
    "# loaded_models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac402c83-01ff-488f-bad9-a9245138b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lm in loaded_models:\n",
    "#     log.info(f'downloading: {lm}') \n",
    "#     s3.download_file(Bucket='spp-weis', Key=lm, Filename=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d914cc3f-58e8-488e-9e2a-706fdfdbfd93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a32594d-c655-4a28-a5eb-ba83156f1a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_to_remove = [f for f in os.listdir('.') if f.endswith('.pt') or f.endswith('.ckpt') or f.endswith('.pkl')]\n",
    "# for f in files_to_remove:\n",
    "#     log.info(f'removing: {f}')\n",
    "#     os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f2944d-78bc-49ef-b1d5-83ffeba67181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f580c13-0af3-4226-bbab-00acdf0ac433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Refit and log model with best params\n",
    "# log.info('log ensemble model')\n",
    "\n",
    "# # supress training logging\n",
    "# # logging.disable(logging.WARNING)\n",
    "# with mlflow.start_run(experiment_id=exp.experiment_id) as run:\n",
    "\n",
    "#     MODEL_TYPE = 'naive_ens'\n",
    "\n",
    "#     all_models = models_tsmixer + models_tide + models_tft\n",
    "#     # fit model with best params from study\n",
    "#     model = NaiveEnsembleModel(\n",
    "#         forecasting_models=all_models, \n",
    "#         train_forecasting_models=False\n",
    "#     )\n",
    "\n",
    "#     model.MODEL_TYPE = MODEL_TYPE\n",
    "#     model.TRAIN_TIMESTAMP = pd.Timestamp.utcnow()\n",
    "    \n",
    "#     log.info(f'run.info: \\n{run.info}')\n",
    "#     artifact_path = \"model_artifacts\"\n",
    "    \n",
    "#     metrics = {}\n",
    "#     model_params = model.model_params\n",
    "    \n",
    "#     # final model back test on validation data\n",
    "#     acc = model.backtest(\n",
    "#             series=test_series,\n",
    "#             past_covariates=past_cov,\n",
    "#             future_covariates=futr_cov,\n",
    "#             retrain=False,\n",
    "#             forecast_horizon=parameters.FORECAST_HORIZON,\n",
    "#             stride=49,\n",
    "#             metric=[mae, rmse, get_ci_err],\n",
    "#             verbose=False,\n",
    "#             num_samples=200,\n",
    "#         )\n",
    "\n",
    "#     mean_acc = np.mean(acc, axis=0)\n",
    "#     log.info(f'FINAL ACC: mae - {mean_acc[0]} | rmse - {mean_acc[1]} | ci_err - {mean_acc[2]}')\n",
    "#     acc_df = pd.DataFrame(\n",
    "#         mean_acc.reshape(1,-1),\n",
    "#         columns=['mae', 'rmse', 'ci_error']\n",
    "#     )\n",
    "\n",
    "#     # add and log metrics\n",
    "#     metrics['final_mae'] = acc_df.mae[0]\n",
    "#     metrics['final_rmse'] = acc_df.rmse[0]\n",
    "#     metrics['final_ci_error'] = acc_df.ci_error[0]\n",
    "#     mlflow.log_metrics(metrics)\n",
    "\n",
    "#     # set up path to save model\n",
    "#     model_path = '/'.join([artifact_path, model.MODEL_TYPE])\n",
    "#     model_path = '/'.join([artifact_path, 'ens_models'])\n",
    "\n",
    "#     shutil.rmtree(artifact_path, ignore_errors=True)\n",
    "#     os.makedirs(model_path)\n",
    "\n",
    "#     # log params\n",
    "#     mlflow.log_params(model_params)\n",
    "\n",
    "#     # save model files (model, model.ckpt) \n",
    "#     # and load them to artifacts when logging the model\n",
    "#     # model.save(model_path)\n",
    "    \n",
    "#     for i, m in enumerate(all_models):\n",
    "#         m.save(f'{model_path}/{m.MODEL_TYPE}_{i}')\n",
    "\n",
    "#     # save MODEL_TYPE to artifacts\n",
    "#     # this will be used to load the model from the artifacts\n",
    "#     model_type_path = '/'.join([artifact_path, 'MODEL_TYPE.pkl'])\n",
    "#     with open(model_type_path, 'wb') as handle:\n",
    "#         pickle.dump(model.MODEL_TYPE, handle)\n",
    "\n",
    "#     model_timestamp = '/'.join([artifact_path, 'TRAIN_TIMESTAMP.pkl'])\n",
    "#     with open(model_timestamp, 'wb') as handle:\n",
    "#         pickle.dump(model.TRAIN_TIMESTAMP, handle)\n",
    "    \n",
    "#     # map model artififacts in dictionary\n",
    "#     artifacts = {f:f'{artifact_path}/{f}' for f in os.listdir('model_artifacts')}\n",
    "#     artifacts['model'] = model_path\n",
    "    \n",
    "#     # log model\n",
    "#     # https://www.mlflow.org/docs/latest/tutorials-and-examples/tutorial.html#pip-requirements-example\n",
    "#     mlflow.pyfunc.log_model(\n",
    "#         artifact_path='GlobalForecasting',\n",
    "#         code_path=['src/darts_wrapper.py'],\n",
    "#         signature=darts_signature,\n",
    "#         artifacts=artifacts,\n",
    "#         python_model=DartsGlobalModel(), \n",
    "#         pip_requirements=[\"-r notebooks/model_training/requirements.txt\"],\n",
    "#         registered_model_name=parameters.MODEL_NAME,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a42e6de9-a82a-456f-a03d-5e692eabb86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# # test predictions on latest run\n",
    "# print('\\n' + '*' * 40)\n",
    "# log.info('loading model from mlflow for testing')\n",
    "# client = MlflowClient()\n",
    "\n",
    "\n",
    "# def get_latest_registered_model_version(model_name=parameters.MODEL_NAME):\n",
    "#     filter_string = f\"name='{model_name}'\"\n",
    "#     results = client.search_registered_models(filter_string=filter_string)\n",
    "#     return results[0].latest_versions[0].version\n",
    "\n",
    "\n",
    "# client.set_registered_model_alias(parameters.MODEL_NAME, \"champion\", get_latest_registered_model_version())\n",
    "\n",
    "# # model uri for the above model\n",
    "# model_uri = f\"models:/{parameters.MODEL_NAME}@champion\"\n",
    "# model_uri = f\"models:/{parameters.MODEL_NAME}@champion\"\n",
    "\n",
    "# # Load the model and access the custom metadata\n",
    "# loaded_model = mlflow.pyfunc.load_model(model_uri=model_uri)\n",
    "\n",
    "# log.info('test getting predictions')\n",
    "# plot_ind = 3\n",
    "# plot_series = all_series[plot_ind]\n",
    "\n",
    "# plot_end_time = plot_series.end_time() - pd.Timedelta(f'{parameters.INPUT_CHUNK_LENGTH + 1}h')\n",
    "# log.info(f'plot_end_time: {plot_end_time}')\n",
    "\n",
    "# plot_node_name = plot_series.static_covariates.unique_id.LMP\n",
    "# node_series = plot_series.drop_after(plot_end_time)\n",
    "# log.info(f'plot_end_time: {plot_end_time}')\n",
    "# log.info(f'node_series.end_time(): {node_series.end_time()}')\n",
    "# future_cov_series = futr_cov[0]\n",
    "# past_cov_series = past_cov[0]\n",
    "\n",
    "# data = {\n",
    "#     'series': [node_series.to_json()],\n",
    "#     'past_covariates': [past_cov_series.to_json()],\n",
    "#     'future_covariates': [future_cov_series.to_json()],\n",
    "#     'n': 5,\n",
    "#     'num_samples': 2\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# df['num_samples'] = 2\n",
    "# pred = loaded_model.predict(df)\n",
    "\n",
    "# print('\\n' + '*' * 40)\n",
    "# log.info(f'pred: {pred}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spp_weis",
   "language": "python",
   "name": "spp_weis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
