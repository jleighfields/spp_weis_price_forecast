{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9662e0-d4e2-411a-a2af-124e1fbbcae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ibis\n",
    "import boto3\n",
    "import torch\n",
    "\n",
    "ibis.options.interactive = True\n",
    "\n",
    "from darts.metrics import mae, rmse\n",
    "from darts.models import (\n",
    "    TFTModel,\n",
    "    TiDEModel,\n",
    "    TSMixerModel,\n",
    "    NaiveEnsembleModel,\n",
    ")\n",
    "\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# define log\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# adding module folder to system path\n",
    "# needed for running scripts as jobs\n",
    "os.chdir('..')\n",
    "home = os.getenv('HOME')\n",
    "module_paths = [\n",
    "    f'{home}/spp_weis_price_forecast/src',\n",
    "    f'{home}/Documents/spp_weis_price_forecast/src',\n",
    "]\n",
    "for module_path in module_paths:\n",
    "    if os.path.isdir(module_path):\n",
    "        log.info('adding module path')\n",
    "        sys.path.insert(0, module_path)\n",
    "\n",
    "log.info(f'os.getcwd(): {os.getcwd()}')\n",
    "log.info(f'os.listdir(): {os.listdir()}')\n",
    "\n",
    "# from module path\n",
    "import data_engineering as de\n",
    "import parameters\n",
    "from modeling import get_ci_err, build_fit_tsmixerx, build_fit_tft, build_fit_tide, log_pretty\n",
    "\n",
    "# will be loaded from root when deployed\n",
    "from darts_wrapper import DartsGlobalModel\n",
    "\n",
    "# client for uploading model weights\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# check parameters\n",
    "log.info(f'FORECAST_HORIZON: {parameters.FORECAST_HORIZON}')\n",
    "log.info(f'INPUT_CHUNK_LENGTH: {parameters.INPUT_CHUNK_LENGTH}')\n",
    "log.info(f'MODEL_NAME: {parameters.MODEL_NAME}')\n",
    "\n",
    "# connect to database and prepare data\n",
    "print('\\n' + '*' * 40)\n",
    "con = de.create_database()\n",
    "\n",
    "\n",
    "log.info('preparing lmp data')\n",
    "lmp = de.prep_lmp(con)\n",
    "lmp_df = lmp.to_pandas().rename(\n",
    "    columns={\n",
    "        'LMP': 'LMP_HOURLY',\n",
    "        'unique_id': 'node',\n",
    "        'timestamp_mst': 'time'\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "log.info('preparing covariate data')\n",
    "# all_df = de.prep_all_df(con)\n",
    "all_df_pd = de.all_df_to_pandas(de.prep_all_df(con))\n",
    "all_df_pd.info()\n",
    "\n",
    "lmp_all, train_all, test_all, train_test_all = de.get_train_test_all(con)\n",
    "con.disconnect()\n",
    "\n",
    "all_series = de.get_series(lmp_all)\n",
    "train_test_all_series = de.get_series(train_test_all)\n",
    "train_series = de.get_series(train_all)\n",
    "test_series = de.get_series(test_all)\n",
    "\n",
    "futr_cov = de.get_futr_cov(all_df_pd)\n",
    "past_cov = de.get_past_cov(all_df_pd)\n",
    "\n",
    "print('\\n' + '*' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cd103d-00e3-485e-8413-695dea0c1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pretrained models\n",
    "models_tsmixer = []\n",
    "if parameters.USE_TSMIXER:\n",
    "    for i, param in enumerate(parameters.TSMIXER_PARAMS[:parameters.TOP_N]):\n",
    "        print(f'\\ni: {i} \\t' + '*' * 25, flush=True)\n",
    "        model_tsmixer = build_fit_tsmixerx(\n",
    "            series=train_test_all_series,\n",
    "            val_series=test_series,\n",
    "            future_covariates=futr_cov,\n",
    "            past_covariates=past_cov,\n",
    "            **param\n",
    "        )\n",
    "        models_tsmixer += [model_tsmixer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e1747a-cdb5-4fa7-bba4-712e7b31b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_tide = []\n",
    "if parameters.USE_TIDE:\n",
    "    for i, param in enumerate(parameters.TIDE_PARAMS[:parameters.TOP_N]):\n",
    "        print(f'\\ni: {i} \\t' + '*' * 25, flush=True)\n",
    "        model_tide = build_fit_tide(\n",
    "            series=train_test_all_series,\n",
    "            val_series=test_series,\n",
    "            future_covariates=futr_cov,\n",
    "            past_covariates=past_cov,\n",
    "            **param\n",
    "        )\n",
    "        models_tide += [model_tide]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd7563-7dc3-40c2-8062-16c96aa42290",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_tft = []\n",
    "if parameters.USE_TFT:\n",
    "    for i, param in enumerate(parameters.TFT_PARAMS[:parameters.TOP_N]):\n",
    "        print(f'\\ni: {i} \\t' + '*' * 25, flush=True)\n",
    "        model_tft = build_fit_tft(\n",
    "            series=train_test_all_series,\n",
    "            val_series=test_series,\n",
    "            future_covariates=futr_cov,\n",
    "            past_covariates=past_cov,\n",
    "            **param\n",
    "        )\n",
    "        models_tft += [model_tft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af01ccc-9615-45a7-8abc-d3ee1612a6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "439e768d-719f-4058-a888-ed27cf3b37a2",
   "metadata": {},
   "source": [
    "## Save and upload models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8846efb3-6343-4543-97a3-d1c4793c2610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory to store artifacts\n",
    "if os.path.isdir('saved_models'):\n",
    "    shutil.rmtree('saved_models')\n",
    "os.mkdir('saved_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a21e87-b694-475b-a8b1-cec54018b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_timestamp = '/'.join(['saved_models', 'TRAIN_TIMESTAMP.pkl'])\n",
    "with open(model_timestamp, 'wb') as handle:\n",
    "    pickle.dump(pd.Timestamp.utcnow(), handle)\n",
    "\n",
    "for i, m in enumerate(models_tide):\n",
    "    m.save(f'saved_models/tide_{i}.pt')\n",
    "\n",
    "for i, m in enumerate(models_tsmixer):\n",
    "    m.save(f'saved_models/tsmixer_{i}.pt')\n",
    "\n",
    "for i, m in enumerate(models_tft):\n",
    "    m.save(f'saved_models/tft_{i}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016410c2-0775-403d-9a69-20f22b5cacd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_uploads = [f for f in os.listdir('saved_models') if '.pt' in f or '.ckpt' in f or 'TRAIN_TIMESTAMP.pkl' in f]\n",
    "log.info(f'ckpt_uploads: {ckpt_uploads}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e69763-d540-4cbb-ba43-f29b22bc964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload artifacts\n",
    "for ckpt in ckpt_uploads:\n",
    "    log.info(f'uploading: {ckpt}')\n",
    "    s3.upload_file(f'saved_models/{ckpt}', 'spp-weis', f's3_models/{ckpt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a4fb15-6118-4f17-8a20-1c109143026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_models = [d['Key'] for d in s3.list_objects(Bucket='spp-weis')['Contents'] if 's3_models/' in d['Key']]\n",
    "log.info(f'loaded_models: {loaded_models}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549db87-5fce-41ed-933f-259b22685891",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_delete = [l for l in loaded_models if l.split('/')[-1] not in ckpt_uploads]\n",
    "log.info(f'models_to_delete: {models_to_delete}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38e5fd9-b60a-495d-a90b-c5a89dab0c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for del_model in models_to_delete:\n",
    "    log.info(f'removing: {del_model}')\n",
    "    s3.delete_object(Bucket='spp-weis', Key=del_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0308d4-769f-4452-bbfe-02f4d14b330e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98b59b3d-14e7-4036-bc2e-4ba89147556c",
   "metadata": {},
   "source": [
    "## Test loading models from S3 and doing inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d398c-1acf-4fe4-9491-f58a94a6e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('s3_models'):\n",
    "    shutil.rmtree('s3_models')\n",
    "os.mkdir('s3_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed1ec95-a263-4dea-b034-2b28d01f7df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_models = [d['Key'] for d in s3.list_objects(Bucket='spp-weis')['Contents'] if 's3_models/' in d['Key']]\n",
    "log.info(f'loaded_models: {loaded_models}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22c2b95-69ef-4dc2-a946-e044002c1316",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lm in loaded_models:\n",
    "    log.info(f'downloading: {lm}')\n",
    "    s3.download_file(Bucket='spp-weis', Key=lm, Filename=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b4a4a0-b509-4f57-9de9-7b097a8a9d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af6f681d-d53a-40c2-8c0d-a0e90e047747",
   "metadata": {},
   "source": [
    "### Load models by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25a712-f19e-48cd-b3de-f112b37b3387",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_mixer_ckpts = [f for f in os.listdir('s3_models') if 'tsmixer' in f and '.pt' in f and '.ckpt' not in f and 'TRAIN_TIMESTAMP.pkl' not in f]\n",
    "ts_mixer_ckpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ef0a8-3186-4b15-8dc4-d8936920a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_mixer_forecasting_models = []\n",
    "for m_ckpt in ts_mixer_ckpts:\n",
    "    log.info(f'loading model: {m_ckpt}')\n",
    "    ts_mixer_forecasting_models += [TSMixerModel.load(f's3_models/{m_ckpt}', map_location=torch.device('cpu'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd04b32-266e-4505-9c6d-a0e8c7b4bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tide_ckpts = [f for f in os.listdir('s3_models') if 'tide_' in f and '.pt' in f and '.ckpt' not in f and 'TRAIN_TIMESTAMP.pkl' not in f]\n",
    "tide_ckpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96100e2f-09fd-4954-bbf5-1986b4e6b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tide_forecasting_models = []\n",
    "for m_ckpt in tide_ckpts:\n",
    "    log.info(f'loading model: {m_ckpt}')\n",
    "    tide_forecasting_models += [TiDEModel.load(f's3_models/{m_ckpt}', map_location=torch.device('cpu'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ff28f-436a-4f41-aa4a-9680ad0e6382",
   "metadata": {},
   "outputs": [],
   "source": [
    "tft_ckpts = [f for f in os.listdir('s3_models') if 'tft' in f and '.pt' in f and '.ckpt' not in f and 'TRAIN_TIMESTAMP.pkl' not in f]\n",
    "tft_ckpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227755cb-637f-464d-a63b-e9b29deb28e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tft_forecasting_models = []\n",
    "for m_ckpt in tft_ckpts:\n",
    "    log.info(f'loading model: {m_ckpt}')\n",
    "    tide_forecasting_models += [TFTModel.load(f's3_models/{m_ckpt}', map_location=torch.device('cpu'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d9e7de-6ef7-4b0a-b91b-8b28754ae075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6684892-8699-4c10-bbdb-bdba600d05d4",
   "metadata": {},
   "source": [
    "## Create ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c44597-6e76-4471-aaec-9b5f6bc554a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasting_models = ts_mixer_forecasting_models + tide_forecasting_models + tft_forecasting_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0c24b2-c993-4ca0-b0a5-9c085128a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# test predictions on latest run\n",
    "print('\\n' + '*' * 40)\n",
    "log.info('loading model from checkpoints')\n",
    "loaded_model = NaiveEnsembleModel(\n",
    "        forecasting_models=forecasting_models, \n",
    "        train_forecasting_models=False\n",
    "    )\n",
    "\n",
    "log.info('test getting predictions')\n",
    "plot_ind = 3\n",
    "plot_series = all_series[plot_ind]\n",
    "\n",
    "plot_end_time = plot_series.end_time() - pd.Timedelta(f'{parameters.INPUT_CHUNK_LENGTH + 1}h')\n",
    "log.info(f'plot_end_time: {plot_end_time}')\n",
    "\n",
    "plot_node_name = plot_series.static_covariates.unique_id.LMP\n",
    "node_series = plot_series.drop_after(plot_end_time)\n",
    "log.info(f'plot_end_time: {plot_end_time}')\n",
    "log.info(f'node_series.end_time(): {node_series.end_time()}')\n",
    "future_cov_series = futr_cov[0]\n",
    "past_cov_series = past_cov[0]\n",
    "\n",
    "data = {\n",
    "    'series': [node_series.to_json()],\n",
    "    'past_covariates': [past_cov_series.to_json()],\n",
    "    'future_covariates': [future_cov_series.to_json()],\n",
    "    'n': 5,\n",
    "    'num_samples': 2\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['num_samples'] = 2\n",
    "pred=loaded_model.predict(\n",
    "    series=node_series,\n",
    "    past_covariates=past_cov_series,\n",
    "    future_covariates=future_cov_series,\n",
    "    n=5,\n",
    "    num_samples=2,\n",
    ")\n",
    "\n",
    "print('\\n' + '*' * 40)\n",
    "log.info(f'pred: {pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8069c8b1-11d6-4da1-a5a5-084abda36838",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.pd_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5476a9-d161-4c60-ab02-8ddcff44c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info('finished retraining')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98804f4-8b3a-4318-b2b7-8883d52d35b6",
   "metadata": {},
   "source": [
    "## Load models to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee01ee6d-9d5c-412a-a35f-1565ea6b6aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create directory to store artifacts\n",
    "# if os.path.isdir('saved_models'):\n",
    "#     shutil.rmtree('saved_models')\n",
    "# os.mkdir('saved_models')\n",
    "\n",
    "\n",
    "# model_timestamp = '/'.join(['saved_models', 'TRAIN_TIMESTAMP.pkl'])\n",
    "# with open(model_timestamp, 'wb') as handle:\n",
    "#     pickle.dump(pd.Timestamp.utcnow(), handle)\n",
    "\n",
    "# for i, m in enumerate(models_tide):\n",
    "#     m.save(f'saved_models/tide_{i}.pt')\n",
    "\n",
    "# for i, m in enumerate(models_tsmixer):\n",
    "#     m.save(f'saved_models/tsmixer_{i}.pt')\n",
    "\n",
    "# for i, m in enumerate(models_tft):\n",
    "#     m.save(f'saved_models/tft_{i}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43f8d1-6f60-4839-a969-3e7f74b745a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_uploads = [f for f in os.listdir('saved_models') if '.pt' in f or '.ckpt' in f or 'TRAIN_TIMESTAMP.pkl' in f]\n",
    "# log.info(f'ckpt_uploads: {ckpt_uploads}')\n",
    "\n",
    "\n",
    "# # upload artifacts\n",
    "# for ckpt in ckpt_uploads:\n",
    "#     log.info(f'uploading: {ckpt}')\n",
    "#     s3.upload_file(f'saved_models/{ckpt}', 'spp-weis', f's3_models/{ckpt}')\n",
    "\n",
    "\n",
    "# loaded_models = [d['Key'] for d in s3.list_objects(Bucket='spp-weis')['Contents'] if 's3_models/' in d['Key']]\n",
    "# log.info(f'loaded_models: {loaded_models}')\n",
    "\n",
    "\n",
    "# models_to_delete = [l for l in loaded_models if l.split('/')[-1] not in ckpt_uploads]\n",
    "# log.info(f'models_to_delete: {models_to_delete}')\n",
    "\n",
    "\n",
    "# for del_model in models_to_delete:\n",
    "#     log.info(f'removing: {del_model}')\n",
    "#     s3.delete_object(Bucket='spp-weis', Key=del_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbedd42-e0f9-4996-8303-921ee2936643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a20ff10-b4e8-4e54-b5e7-ee2e15d40318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_models = [d['Key'] for d in s3.list_objects(Bucket='spp-weis')['Contents'] if 's3_models/' in d['Key']]\n",
    "# loaded_models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac402c83-01ff-488f-bad9-a9245138b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lm in loaded_models:\n",
    "#     log.info(f'downloading: {lm}') \n",
    "#     s3.download_file(Bucket='spp-weis', Key=lm, Filename=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d914cc3f-58e8-488e-9e2a-706fdfdbfd93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a32594d-c655-4a28-a5eb-ba83156f1a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_to_remove = [f for f in os.listdir('.') if f.endswith('.pt') or f.endswith('.ckpt') or f.endswith('.pkl')]\n",
    "# for f in files_to_remove:\n",
    "#     log.info(f'removing: {f}')\n",
    "#     os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f2944d-78bc-49ef-b1d5-83ffeba67181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f580c13-0af3-4226-bbab-00acdf0ac433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Refit and log model with best params\n",
    "# log.info('log ensemble model')\n",
    "\n",
    "# # supress training logging\n",
    "# # logging.disable(logging.WARNING)\n",
    "# with mlflow.start_run(experiment_id=exp.experiment_id) as run:\n",
    "\n",
    "#     MODEL_TYPE = 'naive_ens'\n",
    "\n",
    "#     all_models = models_tsmixer + models_tide + models_tft\n",
    "#     # fit model with best params from study\n",
    "#     model = NaiveEnsembleModel(\n",
    "#         forecasting_models=all_models, \n",
    "#         train_forecasting_models=False\n",
    "#     )\n",
    "\n",
    "#     model.MODEL_TYPE = MODEL_TYPE\n",
    "#     model.TRAIN_TIMESTAMP = pd.Timestamp.utcnow()\n",
    "    \n",
    "#     log.info(f'run.info: \\n{run.info}')\n",
    "#     artifact_path = \"model_artifacts\"\n",
    "    \n",
    "#     metrics = {}\n",
    "#     model_params = model.model_params\n",
    "    \n",
    "#     # final model back test on validation data\n",
    "#     acc = model.backtest(\n",
    "#             series=test_series,\n",
    "#             past_covariates=past_cov,\n",
    "#             future_covariates=futr_cov,\n",
    "#             retrain=False,\n",
    "#             forecast_horizon=parameters.FORECAST_HORIZON,\n",
    "#             stride=49,\n",
    "#             metric=[mae, rmse, get_ci_err],\n",
    "#             verbose=False,\n",
    "#             num_samples=200,\n",
    "#         )\n",
    "\n",
    "#     mean_acc = np.mean(acc, axis=0)\n",
    "#     log.info(f'FINAL ACC: mae - {mean_acc[0]} | rmse - {mean_acc[1]} | ci_err - {mean_acc[2]}')\n",
    "#     acc_df = pd.DataFrame(\n",
    "#         mean_acc.reshape(1,-1),\n",
    "#         columns=['mae', 'rmse', 'ci_error']\n",
    "#     )\n",
    "\n",
    "#     # add and log metrics\n",
    "#     metrics['final_mae'] = acc_df.mae[0]\n",
    "#     metrics['final_rmse'] = acc_df.rmse[0]\n",
    "#     metrics['final_ci_error'] = acc_df.ci_error[0]\n",
    "#     mlflow.log_metrics(metrics)\n",
    "\n",
    "#     # set up path to save model\n",
    "#     model_path = '/'.join([artifact_path, model.MODEL_TYPE])\n",
    "#     model_path = '/'.join([artifact_path, 'ens_models'])\n",
    "\n",
    "#     shutil.rmtree(artifact_path, ignore_errors=True)\n",
    "#     os.makedirs(model_path)\n",
    "\n",
    "#     # log params\n",
    "#     mlflow.log_params(model_params)\n",
    "\n",
    "#     # save model files (model, model.ckpt) \n",
    "#     # and load them to artifacts when logging the model\n",
    "#     # model.save(model_path)\n",
    "    \n",
    "#     for i, m in enumerate(all_models):\n",
    "#         m.save(f'{model_path}/{m.MODEL_TYPE}_{i}')\n",
    "\n",
    "#     # save MODEL_TYPE to artifacts\n",
    "#     # this will be used to load the model from the artifacts\n",
    "#     model_type_path = '/'.join([artifact_path, 'MODEL_TYPE.pkl'])\n",
    "#     with open(model_type_path, 'wb') as handle:\n",
    "#         pickle.dump(model.MODEL_TYPE, handle)\n",
    "\n",
    "#     model_timestamp = '/'.join([artifact_path, 'TRAIN_TIMESTAMP.pkl'])\n",
    "#     with open(model_timestamp, 'wb') as handle:\n",
    "#         pickle.dump(model.TRAIN_TIMESTAMP, handle)\n",
    "    \n",
    "#     # map model artififacts in dictionary\n",
    "#     artifacts = {f:f'{artifact_path}/{f}' for f in os.listdir('model_artifacts')}\n",
    "#     artifacts['model'] = model_path\n",
    "    \n",
    "#     # log model\n",
    "#     # https://www.mlflow.org/docs/latest/tutorials-and-examples/tutorial.html#pip-requirements-example\n",
    "#     mlflow.pyfunc.log_model(\n",
    "#         artifact_path='GlobalForecasting',\n",
    "#         code_path=['src/darts_wrapper.py'],\n",
    "#         signature=darts_signature,\n",
    "#         artifacts=artifacts,\n",
    "#         python_model=DartsGlobalModel(), \n",
    "#         pip_requirements=[\"-r notebooks/model_training/requirements.txt\"],\n",
    "#         registered_model_name=parameters.MODEL_NAME,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e6de9-a82a-456f-a03d-5e692eabb86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# # test predictions on latest run\n",
    "# print('\\n' + '*' * 40)\n",
    "# log.info('loading model from mlflow for testing')\n",
    "# client = MlflowClient()\n",
    "\n",
    "\n",
    "# def get_latest_registered_model_version(model_name=parameters.MODEL_NAME):\n",
    "#     filter_string = f\"name='{model_name}'\"\n",
    "#     results = client.search_registered_models(filter_string=filter_string)\n",
    "#     return results[0].latest_versions[0].version\n",
    "\n",
    "\n",
    "# client.set_registered_model_alias(parameters.MODEL_NAME, \"champion\", get_latest_registered_model_version())\n",
    "\n",
    "# # model uri for the above model\n",
    "# model_uri = f\"models:/{parameters.MODEL_NAME}@champion\"\n",
    "# model_uri = f\"models:/{parameters.MODEL_NAME}@champion\"\n",
    "\n",
    "# # Load the model and access the custom metadata\n",
    "# loaded_model = mlflow.pyfunc.load_model(model_uri=model_uri)\n",
    "\n",
    "# log.info('test getting predictions')\n",
    "# plot_ind = 3\n",
    "# plot_series = all_series[plot_ind]\n",
    "\n",
    "# plot_end_time = plot_series.end_time() - pd.Timedelta(f'{parameters.INPUT_CHUNK_LENGTH + 1}h')\n",
    "# log.info(f'plot_end_time: {plot_end_time}')\n",
    "\n",
    "# plot_node_name = plot_series.static_covariates.unique_id.LMP\n",
    "# node_series = plot_series.drop_after(plot_end_time)\n",
    "# log.info(f'plot_end_time: {plot_end_time}')\n",
    "# log.info(f'node_series.end_time(): {node_series.end_time()}')\n",
    "# future_cov_series = futr_cov[0]\n",
    "# past_cov_series = past_cov[0]\n",
    "\n",
    "# data = {\n",
    "#     'series': [node_series.to_json()],\n",
    "#     'past_covariates': [past_cov_series.to_json()],\n",
    "#     'future_covariates': [future_cov_series.to_json()],\n",
    "#     'n': 5,\n",
    "#     'num_samples': 2\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# df['num_samples'] = 2\n",
    "# pred = loaded_model.predict(df)\n",
    "\n",
    "# print('\\n' + '*' * 40)\n",
    "# log.info(f'pred: {pred}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spp_weis",
   "language": "python",
   "name": "spp_weis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
