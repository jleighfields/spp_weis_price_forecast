bundle:
  name: spp-weis

targets:
  dev:
    workspace:
      host: https://dbc-5cfb7418-cc9c.cloud.databricks.com

variables:
  AWS_DEFAULT_REGION:
    default: "us-west-2"
  AWS_S3_BUCKET:
    default: "databricks-storage-7474645306723306"
  AWS_S3_FOLDER:
    default: "unity-catalog/7474645306723306/spp-weis/"
  workspace_path:
    default: "/Workspace/Users/jleighfields@gmail.com/spp_weis_price_forecast"

# YAML anchors for reusable cluster configurations
# x-job-cluster-sm: &job_cluster_sm
#   job_cluster_key: Job_cluster_sm
#   new_cluster:
#     spark_version: 17.3.x-scala2.13
#     aws_attributes:
#       first_on_demand: 0
#       spot_bid_price_percent: 100
#     node_type_id: r5d.large
#     spark_env_vars:
#       PYSPARK_PYTHON: /databricks/python3/bin/python3
#     data_security_mode: DATA_SECURITY_MODE_DEDICATED
#     runtime_engine: STANDARD
#     kind: CLASSIC_PREVIEW
#     is_single_node: true

x-job-cluster-med: &job_cluster_med
  job_cluster_key: Job_cluster_med
  new_cluster:
    spark_version: 17.3.x-scala2.13
    aws_attributes:
      first_on_demand: 0
      spot_bid_price_percent: 100
    node_type_id: r5d.xlarge
    spark_env_vars:
      PYSPARK_PYTHON: /databricks/python3/bin/python3
    data_security_mode: DATA_SECURITY_MODE_DEDICATED
    runtime_engine: STANDARD
    kind: CLASSIC_PREVIEW
    is_single_node: true

x-job-cluster-ml: &job_cluster_ml
  job_cluster_key: Job_cluster_ml
  new_cluster:
    spark_version: 17.3.x-scala2.13
    aws_attributes:
      first_on_demand: 0
      spot_bid_price_percent: 100
    node_type_id: g4dn.2xlarge
    spark_env_vars:
      PYSPARK_PYTHON: /databricks/python3/bin/python3
    data_security_mode: DATA_SECURITY_MODE_DEDICATED
    runtime_engine: STANDARD
    kind: CLASSIC_PREVIEW
    is_single_node: true

# YAML anchor for shared libraries
x-libraries: &libraries
  - pypi:
      package: polars==1.37.1
  - pypi:
      package: pyarrow==19.0.1
  - pypi:
      package: python-dotenv==1.2.1
  - pypi:
      package: boto3==1.35.92
  - pypi:
      package: duckdb==1.4.3
  - pypi:
      package: tqdm==4.67.1
  - pypi:
      package: polars-xdt==0.17.1
  - pypi:
      package: marimo==0.19.7

x-libraries-ml: &libraries_ml
  - pypi:
      package: polars==1.37.1
  - pypi:
      package: pyarrow==19.0.1
  - pypi:
      package: python-dotenv==1.2.1
  - pypi:
      package: boto3==1.35.92
  - pypi:
      package: duckdb==1.4.3
  - pypi:
      package: tqdm==4.67.1
  - pypi:
      package: polars-xdt==0.17.1
  - pypi:
      package: torch==2.5.1
  - pypi:
      package: darts==0.31.0


resources:
  jobs:
    data_collection_hourly:
      name: data_collection_hourly
      email_notifications:
        on_failure:
          - "jleighfields@gmail.com" # Job-level failure notifications
      job_clusters:
        - *job_cluster_med
      trigger:
        pause_status: UNPAUSED
        periodic:
          interval: 2
          unit: HOURS
      tasks:
        - task_key: data_collection_hourly
          notebook_task:
            notebook_path: ${var.workspace_path}/notebooks/data_collection/data_collection_hourly
            source: WORKSPACE
          job_cluster_key: Job_cluster_med
          libraries: *libraries

    data_collection_daily:
      name: data_collection_daily
      email_notifications:
        on_failure:
          - "jleighfields@gmail.com" # Job-level failure notifications
      job_clusters:
        - *job_cluster_med
      trigger:
        pause_status: UNPAUSED
        periodic:
          interval: 2
          unit: DAYS
      tasks:
        - task_key: data_collection_daily
          notebook_task:
            notebook_path: ${var.workspace_path}/notebooks/data_collection/data_collection_daily
            source: WORKSPACE
          job_cluster_key: Job_cluster_med
          libraries: *libraries

    model_retrain_weekly:
      name: model_retrain_weekly
      email_notifications:
        on_failure:
          - "jleighfields@gmail.com"
      job_clusters:
        - *job_cluster_ml
      schedule:
        pause_status: UNPAUSED
        quartz_cron_expression: "0 0 20 ? * SUN"
        timezone_id: "America/Denver"
      tasks:
        - task_key: model_retrain
          notebook_task:
            notebook_path: ${var.workspace_path}/notebooks/model_training/model_retrain
            source: WORKSPACE
          job_cluster_key: Job_cluster_ml
          libraries: *libraries_ml

